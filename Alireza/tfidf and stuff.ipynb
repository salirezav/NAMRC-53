{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCO_csv = \"./Scopus/scopus.csv\"\n",
    "SD_csv = \"./ScienceDirect/ScienceDirect.csv\"\n",
    "WOS_csv = \"./WOS/wos.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "# Import TfidfVectorizer from sklearn for keyword extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Import the summarization pipeline from transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Niloofar/WOS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the filtered dataset: ['Article Title', 'Abstract', 'Author Keywords', 'Keywords Plus', 'Authors', 'Source Title', 'Publication Year', 'Document Type', 'DOI', 'Times Cited, WoS Core', 'Research Areas']\n"
     ]
    }
   ],
   "source": [
    "# Define a list of essential columns to retain\n",
    "# This focuses on the columns most relevant for systematic review and data analysis\n",
    "essential_columns = [\n",
    "    \"Article Title\",  # Title of the paper\n",
    "    \"Abstract\",  # Abstract text\n",
    "    \"Author Keywords\",  # Keywords provided by the authors\n",
    "    \"Keywords Plus\",  # Additional keywords provided by Web of Science\n",
    "    \"Authors\",  # Names of authors\n",
    "    \"Source Title\",  # Journal or source title\n",
    "    \"Publication Year\",  # Year of publication\n",
    "    \"Document Type\",  # Type of document (e.g., research article, review)\n",
    "    \"DOI\",  # DOI for unique identification\n",
    "    \"Times Cited, WoS Core\",  # Number of times cited\n",
    "    \"Research Areas\",  # Areas of research (e.g., manufacturing, engineering)\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with only the essential columns\n",
    "filtered_data = data[essential_columns]\n",
    "\n",
    "# Display the first few rows of the new DataFrame to verify selected columns\n",
    "filtered_data.head()\n",
    "\n",
    "# Check the column names to ensure only essential columns are included\n",
    "print(\"Columns in the filtered dataset:\", filtered_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alireza Vaezi\\AppData\\Local\\Temp\\ipykernel_25432\\1485246078.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[\"combined_text\"] = filtered_data[\"Article Title\"] + \" \" + filtered_data[\"Abstract\"]\n",
      "C:\\Users\\Alireza Vaezi\\AppData\\Local\\Temp\\ipykernel_25432\\1485246078.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[\"keyword_score\"] = [calculate_keyword_score(tfidf_matrix[i], priority_keywords) for i in range(tfidf_matrix.shape[0])]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article Title</th>\n",
       "      <th>keyword_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A theoretical framework for evaluating mental ...</td>\n",
       "      <td>0.377296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Profiling cognitive workload in an unmanned ve...</td>\n",
       "      <td>0.366028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Towards the Integration and Evaluation of Onli...</td>\n",
       "      <td>0.340310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Determining Cognitive Workload Using Physiolog...</td>\n",
       "      <td>0.334163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Using Past and Present Indicators of Human Wor...</td>\n",
       "      <td>0.316948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Article Title  keyword_score\n",
       "0  A theoretical framework for evaluating mental ...       0.377296\n",
       "1  Profiling cognitive workload in an unmanned ve...       0.366028\n",
       "2  Towards the Integration and Evaluation of Onli...       0.340310\n",
       "3  Determining Cognitive Workload Using Physiolog...       0.334163\n",
       "4  Using Past and Present Indicators of Human Wor...       0.316948"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define priority keywords that are relevant to cognitive load in manufacturing\n",
    "priority_keywords = [\"cognitive load\", \"workload\", \"assembly line\", \"industry 4.0\", \"manufacturing\", \"human-robot interaction\"]\n",
    "\n",
    "# Combine 'Title' and 'Abstract' columns into a single text field for analysis\n",
    "filtered_data[\"combined_text\"] = filtered_data[\"Article Title\"] + \" \" + filtered_data[\"Abstract\"]\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Fit and transform the combined text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(filtered_data[\"combined_text\"])\n",
    "\n",
    "# Get feature names (terms) from the vectorizer\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "# Function to calculate relevance score based on priority keywords\n",
    "def calculate_keyword_score(tfidf_vector, keywords):\n",
    "    score = 0\n",
    "    for keyword in keywords:\n",
    "        # Check if the keyword is in the feature names\n",
    "        if keyword in feature_names:\n",
    "            # Add the TF-IDF score of the keyword to the score\n",
    "            score += tfidf_vector[0, feature_names.tolist().index(keyword)]\n",
    "    return score\n",
    "\n",
    "\n",
    "# Apply the function to calculate scores for each article\n",
    "filtered_data[\"keyword_score\"] = [calculate_keyword_score(tfidf_matrix[i], priority_keywords) for i in range(tfidf_matrix.shape[0])]\n",
    "\n",
    "# Sort the DataFrame by 'keyword_score' in descending order\n",
    "filtered_data = filtered_data.sort_values(by=\"keyword_score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the top 5 articles by relevance\n",
    "filtered_data[[\"Article Title\", \"keyword_score\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the summarization model\n",
    "# The summarizer will generate concise summaries of each abstract\n",
    "summarizer = pipeline(\"summarization\", device=\"cuda\")\n",
    "\n",
    "\n",
    "# Function to summarize abstract text\n",
    "def summarize_text(text):\n",
    "    try:\n",
    "        # Generate summary for the text with specified length constraints\n",
    "        summary = summarizer(text, max_length=50, min_length=25, do_sample=False)[0][\"summary_text\"]\n",
    "    except Exception as e:\n",
    "        # In case of an error (e.g., if text is too short), return original text as a fallback\n",
    "        summary = text\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Apply the summarization function to the 'Abstract' column\n",
    "# Store the summaries in a new column called 'summary'\n",
    "filtered_data[\"summary\"] = filtered_data[\"Abstract\"].apply(summarize_text)\n",
    "\n",
    "# Display the top 5 articles with their titles, keyword scores, and summaries\n",
    "filtered_data[[\"Article Title\", \"keyword_score\", \"summary\"]].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAMRC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
