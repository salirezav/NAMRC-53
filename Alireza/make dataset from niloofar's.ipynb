{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import rispy\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_csv = \"../Niloofar/wos_final.csv\"\n",
    "SD_csv = \"../Niloofar/sciencedirect_final.csv\"\n",
    "SCO_csv = \"../Niloofar/scopus_final.csv\"\n",
    "\n",
    "\n",
    "WOS_df = pd.read_csv(WOS_csv)\n",
    "SD_df = pd.read_csv(SD_csv)\n",
    "SCO_df = pd.read_csv(SCO_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match the common fields in all dataframes\n",
    "WOS_df = WOS_df.rename(columns={\"Article Title\": \"Title\", \"Abstract\": \"Abstract\", \"Authors\": \"Authors\", \"DOI\": \"DOI\", \"ISSN\": \"ISSN\", \"Publication Year\": \"Publication Year\"})\n",
    "\n",
    "SCO_df = SCO_df.rename(columns={\"Article Title\": \"Title\", \"Abstract\": \"Abstract\", \"Authors\": \"Authors\", \"DOI\": \"DOI\", \"ISSN\": \"ISSN\", \"Publication Year\": \"Publication Year\"})\n",
    "\n",
    "SD_df = SD_df.rename(columns={\"primary_title\": \"Title\", \"abstract\": \"Abstract\", \"authors\": \"Authors\", \"doi\": \"DOI\", \"issn\": \"ISSN\", \"year\": \"Publication Year\", \"keywords\": \"Keywords\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For WOS_papers\n",
    "WOS_df[\"Keywords\"] = WOS_df[\"Author Keywords\"].fillna(\"\") + \"; \" + WOS_df[\"Keywords Plus\"].fillna(\"\")\n",
    "# Clean and convert to set format\n",
    "WOS_df[\"Keywords\"] = WOS_df[\"Keywords\"].str.strip(\"; \").str.lower().apply(lambda x: {kw.strip() for kw in x.split(\";\") if kw.strip()} if isinstance(x, str) and x else set())\n",
    "\n",
    "# For SCO_papers\n",
    "SCO_df[\"Keywords\"] = SCO_df[\"Author Keywords\"].fillna(\"\") + \"; \" + SCO_df[\"Index Keywords\"].fillna(\"\")\n",
    "# Clean and convert to set format\n",
    "SCO_df[\"Keywords\"] = SCO_df[\"Keywords\"].str.strip(\"; \").str.lower().apply(lambda x: {kw.strip() for kw in x.split(\";\") if kw.strip()} if isinstance(x, str) and x else set())\n",
    "\n",
    "# For SD_papers\n",
    "# Ensure only valid lists are processed and convert to sets\n",
    "SD_df[\"Keywords\"] = SD_df[\"Keywords\"].apply(lambda lst: {kw.lower().strip() for kw in lst if kw.strip()} if isinstance(lst, list) else set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Publication Year'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m common_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbstract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeywords\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDOI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mISSN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPublication Year\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m WOS_papers_common \u001b[38;5;241m=\u001b[39m WOS_df[common_columns]\n\u001b[1;32m----> 4\u001b[0m SCO_papers_common \u001b[38;5;241m=\u001b[39m \u001b[43mSCO_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcommon_columns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m SD_papers_common \u001b[38;5;241m=\u001b[39m SD_df[common_columns]\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\NAMRC\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\NAMRC\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\NAMRC\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Publication Year'] not in index\""
     ]
    }
   ],
   "source": [
    "common_columns = [\"Title\", \"Abstract\", \"Authors\", \"Keywords\", \"DOI\", \"ISSN\", \"Publication Year\"]\n",
    "\n",
    "WOS_papers_common = WOS_df[common_columns]\n",
    "SCO_papers_common = SCO_df[common_columns]\n",
    "SD_papers_common = SD_df[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type_of_reference</th>\n",
       "      <th>primary_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal_name</th>\n",
       "      <th>volume</th>\n",
       "      <th>number</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>secondary_title</th>\n",
       "      <th>issn</th>\n",
       "      <th>doi</th>\n",
       "      <th>urls</th>\n",
       "      <th>keywords</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>JOUR</td>\n",
       "      <td>How does the application of augmented reality ...</td>\n",
       "      <td>['Maretto, Leonardo', 'Battini, Daria', 'Facci...</td>\n",
       "      <td>IFAC-PapersOnLine</td>\n",
       "      <td>58</td>\n",
       "      <td>19.0</td>\n",
       "      <td>760</td>\n",
       "      <td>765.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/01/01/</td>\n",
       "      <td>18th IFAC Symposium on Information Control Pro...</td>\n",
       "      <td>2405-8963</td>\n",
       "      <td>https://doi.org/10.1016/j.ifacol.2024.09.210</td>\n",
       "      <td>['https://www.sciencedirect.com/science/articl...</td>\n",
       "      <td>['augmented reality', 'Industry 5.0', 'mental ...</td>\n",
       "      <td>Digitalisation and the introduction of smart m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 type_of_reference  \\\n",
       "0           0              JOUR   \n",
       "\n",
       "                                       primary_title  \\\n",
       "0  How does the application of augmented reality ...   \n",
       "\n",
       "                                             authors       journal_name  \\\n",
       "0  ['Maretto, Leonardo', 'Battini, Daria', 'Facci...  IFAC-PapersOnLine   \n",
       "\n",
       "  volume  number  start_page  end_page  year         date  \\\n",
       "0     58    19.0         760     765.0  2024  2024/01/01/   \n",
       "\n",
       "                                     secondary_title       issn  \\\n",
       "0  18th IFAC Symposium on Information Control Pro...  2405-8963   \n",
       "\n",
       "                                            doi  \\\n",
       "0  https://doi.org/10.1016/j.ifacol.2024.09.210   \n",
       "\n",
       "                                                urls  \\\n",
       "0  ['https://www.sciencedirect.com/science/articl...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  ['augmented reality', 'Industry 5.0', 'mental ...   \n",
       "\n",
       "                                            abstract  \n",
       "0  Digitalisation and the introduction of smart m...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SD_df.head(1)\n",
    "WOS_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For WOS_papers\n",
    "WOS_df[\"Keywords\"] = WOS_df[\"Author Keywords\"].fillna(\"\") + \"; \" + WOS_df[\"Keywords Plus\"].fillna(\"\")\n",
    "# Clean and convert to set format\n",
    "WOS_df[\"Keywords\"] = WOS_df[\"Keywords\"].str.strip(\"; \").str.lower().apply(lambda x: {kw.strip() for kw in x.split(\";\") if kw.strip()} if isinstance(x, str) and x else set())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For SCO_papers\n",
    "SCO_df[\"Keywords\"] = SCO_df[\"Author Keywords\"].fillna(\"\") + \"; \" + SCO_df[\"Index Keywords\"].fillna(\"\")\n",
    "# Clean and convert to set format\n",
    "SCO_df[\"Keywords\"] = SCO_df[\"Keywords\"].str.strip(\"; \").str.lower().apply(lambda x: {kw.strip() for kw in x.split(\";\") if kw.strip()} if isinstance(x, str) and x else set())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For SD_papers\n",
    "# Ensure only valid lists are processed and convert to sets\n",
    "SD_df[\"Keywords\"] = SD_df[\"keywords\"].apply(lambda lst: {kw.lower().strip() for kw in lst if kw.strip()} if isinstance(lst, list) else set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2250\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "print(WOS_df.shape[0])\n",
    "print(SCO_df.shape[0])\n",
    "print(SD_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m SD_df_standardized \u001b[38;5;241m=\u001b[39m SD_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprimary_title\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbstract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeywords\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeywords\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoi\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDOI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthors\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m})[essential_columns]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Concatenate the three DataFrames\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m concatenated_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mWOS_df_standardized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCO_df_standardized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSD_df_standardized\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\NAMRC\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\NAMRC\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    686\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\NAMRC\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "essential_columns = [\"Title\", \"Abstract\", \"Keywords\", \"DOI\", \"Authors\", \"Year\"]\n",
    "# Standardize column names for WOS_df\n",
    "WOS_df_standardized = WOS_df.rename(columns={\"Article Title\": \"Title\", \"Abstract\": \"Abstract\", \"Author Keywords\": \"Keywords\", \"DOI\": \"DOI\", \"Authors\": \"Authors\", \"Publication Year\": \"Year\"})[essential_columns]\n",
    "\n",
    "# Standardize column names for SCO_df\n",
    "SCO_df_standardized = SCO_df.rename(columns={\"Title\": \"Title\", \"Abstract\": \"Abstract\", \"Author Keywords\": \"Keywords\", \"DOI\": \"DOI\", \"Authors\": \"Authors\", \"Year\": \"Year\"})[essential_columns]\n",
    "\n",
    "# Standardize column names for SD_df\n",
    "SD_df_standardized = SD_df.rename(columns={\"primary_title\": \"Title\", \"abstract\": \"Abstract\", \"keywords\": \"Keywords\", \"doi\": \"DOI\", \"authors\": \"Authors\", \"year\": \"Year\"})[essential_columns]\n",
    "\n",
    "# Concatenate the three DataFrames\n",
    "concatenated_df = pd.concat([WOS_df_standardized, SCO_df_standardized, SD_df_standardized], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cognitive Manufacturing in Industry 4.0 toward...</td>\n",
       "      <td>Cognitive manufacturing utilizes cognitive com...</td>\n",
       "      <td>Industry 4.0; cognitive manufacturing; cogniti...</td>\n",
       "      <td>{cognitive load, system, industry 4.0, cogniti...</td>\n",
       "      <td>10.3390/asi3040055</td>\n",
       "      <td>Carvalho, AV; Chouchene, A; Lima, TM; Charrua-...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An Online Framework for Cognitive Load Assessm...</td>\n",
       "      <td>The ongoing trend toward Industry 4.0 has revo...</td>\n",
       "      <td>Cognitive ergonomics; Cognitive manufacturing;...</td>\n",
       "      <td>{attention, workload, cognitive ergonomics, co...</td>\n",
       "      <td>10.1016/j.rcim.2022.102380</td>\n",
       "      <td>Lagomarsino, M; Lorenzini, M; De Momi, E; Ajou...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Cognitive Manufacturing in Industry 4.0 toward...   \n",
       "1  An Online Framework for Cognitive Load Assessm...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Cognitive manufacturing utilizes cognitive com...   \n",
       "1  The ongoing trend toward Industry 4.0 has revo...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  Industry 4.0; cognitive manufacturing; cogniti...   \n",
       "1  Cognitive ergonomics; Cognitive manufacturing;...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  {cognitive load, system, industry 4.0, cogniti...   \n",
       "1  {attention, workload, cognitive ergonomics, co...   \n",
       "\n",
       "                          DOI  \\\n",
       "0          10.3390/asi3040055   \n",
       "1  10.1016/j.rcim.2022.102380   \n",
       "\n",
       "                                             Authors  Year  \n",
       "0  Carvalho, AV; Chouchene, A; Lima, TM; Charrua-...  2020  \n",
       "1  Lagomarsino, M; Lorenzini, M; De Momi, E; Ajou...  2022  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.to_csv(\"./Niloofars data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_counts = {}\n",
    "for i, element in enumerate(concatenated_df[concatenated_df[\"Keywords\"].notnull()][\"Keywords\"]):\n",
    "    # split = element.split(\";\") if type(element) is str else print(\"FUCK FUCK\", element)\n",
    "    # print(split)\n",
    "    for kw in element:\n",
    "        kw = kw.strip().lower()\n",
    "        if kw not in keyword_counts:\n",
    "            keyword_counts[kw] = 1\n",
    "        else:\n",
    "            keyword_counts[kw] += 1\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "keywords_df = pd.DataFrame(list(keyword_counts.items()), columns=[\"keyword\", \"count\"])\n",
    "\n",
    "# Sort the DataFrame by count in descending order (optional)\n",
    "keywords_df = keywords_df.sort_values(by=\"count\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(keywords_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAMRC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
