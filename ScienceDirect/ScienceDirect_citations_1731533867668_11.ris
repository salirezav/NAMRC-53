TY  - JOUR
T1  - Cognisance as a Human Factor in Military Cyber Defence Education
AU  - Knox, Benjamin J.
AU  - Lugo, Ricardo G.
AU  - Sütterlin, Stefan
JO  - IFAC-PapersOnLine
VL  - 52
IS  - 19
SP  - 163
EP  - 168
PY  - 2019
DA  - 2019/01/01/
T2  - 14th IFAC Symposium on Analysis, Design, and Evaluation of Human Machine Systems HMS 2019
SN  - 2405-8963
DO  - https://doi.org/10.1016/j.ifacol.2019.12.168
UR  - https://www.sciencedirect.com/science/article/pii/S2405896319320191
KW  - Cyber Security
KW  - Human Factor
KW  - Education
KW  - Mentoring
KW  - Performance
KW  - Cognisance
AB  - Cyber Defence Exercises (CDX) are common training and learning tools. A recently discussed challenge in cyber defence teaching and training is the gap between the fast technological advancement accompanied by rapidly changing demands on future cyber defence operators, and the lack of science-based teaching and training methods. A growing body of evidence suggests a crucial role of human factors as a central predictor for human performance in sociotechnical systems. While this has been acknowledged in a wide range of safety-critical applied fields, there is still a lack of knowledge about the impact of human factors on cyber defence performance. The lack of conventional metrics of performance and learning progress contribute to this deficit. To address this gap, the Norwegian Defence Cyber Academy (NDCA) follows a science-based educational approach that identified in a series of empirical studies cognitive-psychological predictors for learning success of future cyber defence operators. These predictors and elements of a human factors research program are deeply embedded into educational practice and include processes such as metacognition, self-regulation, coping, communication and shared mental modelling. Slow education methods and mentoring are fundamental to enabling the advancement of human factors cognisance among military cyber cadets. As a tool for efficient training, the NDCA developed and implemented a mentoring concept that involves a cyber defence retrospective timeline analysis involving expert and practitioner level mentors. The timeline differentiates between performance relevant hard- and soft-skills and leads progressively towards an alignment of Security Operation Centre (SOC)- and expert judgments of performance. The NDCA argues that this educational concept facilitates educational benefits based on insight, accurate self-perception, motivation and decreased team workloads following more efficient collaboration.
ER  - 

TY  - JOUR
T1  - Data-driven human driver lateral control models for developing haptic-shared control advanced driver assist systems
AU  - Okamoto, Kazuhide
AU  - Tsiotras, Panagiotis
JO  - Robotics and Autonomous Systems
VL  - 114
SP  - 155
EP  - 171
PY  - 2019
DA  - 2019/04/01/
SN  - 0921-8890
DO  - https://doi.org/10.1016/j.robot.2019.01.020
UR  - https://www.sciencedirect.com/science/article/pii/S0921889018302008
KW  - Advanced driver assist system
KW  - Human driver control model
KW  - Driving simulator study
KW  - Driver–vehicle interaction
KW  - Unknown parameter and input estimation
AB  - In order to improve road safety, many advanced driver assist systems (ADAS) have been developed to support human-decision making and reduce driver workload. Currently, the majority of ADAS employ a single, often very simple, driver model to predict human-driver interaction in the immediate future (e.g., next few seconds). However, there is tremendous variability in how each individual drives, necessitating personalized driver models, based on data collected from observed actual driver actions. Yet, because we currently lack sufficient knowledge of the high-level cognitive brain functions, traditional control-theoretic driver models have difficulty accurately predicting driver actions. Recently, machine-learning algorithms have been utilized to predict future driver control actions. We compare several of these algorithms used to predict the lateral control actions of human drivers. Specifically, we compare these algorithms in terms of their suitability to develop haptic-shared ADAS, which share the control force with the human driver. To this end, we need to know how the steering torque is provided by the driver. However, low-cost driving simulators typically measure steering angle but not steering torque. Thus, this work also proposes a methodology to estimate the steering-wheel torque. Using the estimated steering torque, we train several machine learning driver control models and compare the performance using both simulated and real human-driving data sets.
ER  - 

TY  - JOUR
T1  - Assessment of operator's situation awareness for smart operation of mobile cranes
AU  - Fang, Yihai
AU  - Cho, Yong K.
AU  - Durso, Frank
AU  - Seo, Jongwon
JO  - Automation in Construction
VL  - 85
SP  - 65
EP  - 75
PY  - 2018
DA  - 2018/01/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2017.10.007
UR  - https://www.sciencedirect.com/science/article/pii/S0926580517303473
KW  - Crane operator
KW  - Situation awareness
KW  - Workload
KW  - Lift performance
KW  - Real-time lift assistance
AB  - Equipment operators play an integral role in the safe and efficient operation of heavy equipment. They observe the environment, understand the situation, and make decisions and actions accordingly. Compared with other types of equipment, operating a crane is more sophisticated and mentally demanding, and thus crane operators are more vulnerable to human errors. Therefore, special considerations to mitigate operator errors should be taken when designing an operator-assistance system for construction cranes. With the goal of improving the operators' situation awareness (SA) of safety risks, this research presents a novel framework and practical system architecture for an operator-assistance system by leveraging real-time motion sensing and 3D modeling of dynamic workspaces. An approach for evaluating operators' SA was proposed to validate the effectiveness of the assistance system in actual lifting operations. Results in a series of field tests indicated that the prototype system improved the operators' SA which resulted in an improved lift performance.
ER  - 

TY  - JOUR
T1  - A transformer-based deep-learning approach for classifying brain metastases into primary organ sites using clinical whole-brain MRI images
AU  - Lyu, Qing
AU  - Namjoshi, Sanjeev V.
AU  - McTyre, Emory
AU  - Topaloglu, Umit
AU  - Barcus, Richard
AU  - Chan, Michael D.
AU  - Cramer, Christina K.
AU  - Debinski, Waldemar
AU  - Gurcan, Metin N.
AU  - Lesser, Glenn J.
AU  - Lin, Hui-Kuan
AU  - Munden, Reginald F.
AU  - Pasche, Boris C.
AU  - Sai, Kiran K.S.
AU  - Strowd, Roy E.
AU  - Tatter, Stephen B.
AU  - Watabe, Kounosuke
AU  - Zhang, Wei
AU  - Wang, Ge
AU  - Whitlow, Christopher T.
JO  - Patterns
VL  - 3
IS  - 11
SP  - 100613
PY  - 2022
DA  - 2022/11/11/
SN  - 2666-3899
DO  - https://doi.org/10.1016/j.patter.2022.100613
UR  - https://www.sciencedirect.com/science/article/pii/S2666389922002380
KW  - deep learning
KW  - vision transformer
KW  - MRI
KW  - brain metastasis
KW  - primary organ site
KW  - classification
AB  - Summary
Treatment decisions for brain metastatic disease rely on knowledge of the primary organ site and are currently made with biopsy and histology. Here, we develop a deep-learning approach for accurate non-invasive digital histology with whole-brain magnetic resonance imaging (MRI) data. Contrast-enhanced T1-weighted and fast spoiled gradient echo brain MRI exams (n = 1,582) were preprocessed and input to the proposed deep-learning workflow for tumor segmentation, modality transfer, and primary site classification into one of five classes. Tenfold cross-validation generated an overall area under the receiver operating characteristic curve (AUC) of 0.878 (95% confidence interval [CI]: 0.873,0.883). These data establish that whole-brain imaging features are discriminative enough to allow accurate diagnosis of the primary organ site of malignancy. Our end-to-end deep radiomic approach has great potential for classifying metastatic tumor types from whole-brain MRI images. Further refinement may offer an invaluable clinical tool to expedite primary cancer site identification for precision treatment and improved outcomes.
ER  - 

TY  - JOUR
T1  - Towards energy-efficient scheduling for real-time tasks under uncertain cloud computing environment
AU  - Chen, Huangke
AU  - Zhu, Xiaomin
AU  - Guo, Hui
AU  - Zhu, Jianghan
AU  - Qin, Xiao
AU  - Wu, Jianhong
JO  - Journal of Systems and Software
VL  - 99
SP  - 20
EP  - 35
PY  - 2015
DA  - 2015/01/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2014.08.065
UR  - https://www.sciencedirect.com/science/article/pii/S0164121214001903
KW  - Green cloud computing
KW  - Uncertain scheduling
KW  - Proactive and reactive
AB  - Green cloud computing has become a major concern in both industry and academia, and efficient scheduling approaches show promising ways to reduce the energy consumption of cloud computing platforms while guaranteeing QoS requirements of tasks. Existing scheduling approaches are inadequate for real-time tasks running in uncertain cloud environments, because those approaches assume that cloud computing environments are deterministic and pre-computed schedule decisions will be statically followed during schedule execution. In this paper, we address this issue. We introduce an interval number theory to describe the uncertainty of the computing environment and a scheduling architecture to mitigate the impact of uncertainty on the task scheduling quality for a cloud data center. Based on this architecture, we present a novel scheduling algorithm (PRS11Proactive and Reactive Scheduling.) that dynamically exploits proactive and reactive scheduling methods, for scheduling real-time, aperiodic, independent tasks. To improve energy efficiency, we propose three strategies to scale up and down the system's computing resources according to workload to improve resource utilization and to reduce energy consumption for the cloud data center. We conduct extensive experiments to compare PRS with four typical baseline scheduling algorithms. The experimental results show that PRS performs better than those algorithms, and can effectively improve the performance of a cloud data center.
ER  - 

TY  - JOUR
T1  - Fully-functional semi-automated microfluidic immunoassay platform for quantitation of multiple samples
AU  - Dai, Bo
AU  - Chen, Shujing
AU  - Li, Wei
AU  - Zheng, Lulu
AU  - Han, Xiaodian
AU  - Fu, Yongfeng
AU  - Wu, Jiandong
AU  - Lin, Francis
AU  - Zhang, Dawei
AU  - Zhuang, Songlin
JO  - Sensors and Actuators B: Chemical
VL  - 300
SP  - 127017
PY  - 2019
DA  - 2019/12/01/
SN  - 0925-4005
DO  - https://doi.org/10.1016/j.snb.2019.127017
UR  - https://www.sciencedirect.com/science/article/pii/S092540051931216X
KW  - Microfluidic device
KW  - Semi-automated assay
KW  - Microfluidic immunoassay chip
KW  - Colorimetric detection
KW  - Interleukin-6
AB  - Microfluidic based enzyme-linked immunosorbent assay (ELISA) has been recognized as an advanced diagnosis tool due to the reduced sample consumption and fast reaction; but it often suffers from limited throughput and requires specialized operation skills. In this paper, we developed a microfluidic chip for multi-sample ELISA and an associated instrument for fluidic delivery and colorimetric detection. Eleven different samples can be assayed simultaneously using the developed platform in a straightforward, user-friendly, and low manual workload manner. Human interleukin-6 (IL-6) was used as the model protein biomarker to validate the platform and the estimated limit of detection (LOD) is 1.262 pg/ml. The entire assay took about 35 min, which is about six-fold shorter than the assay conducted in the traditional 96-well plate. Furthermore, we validated this platform using serum samples from 89 patients with ovarian cancer. The IL-6 concentrations in the clinical samples measured by the microfluidic platform were in good agreement with the traditional well-plate measurements. High accuracy, sensitivity and specificity of 95.5%, 96.2% and 90.9% are achieved in the testing of early-stage ovarian cancer. The semi-automated microfluidic immunoassay provides a convenient, rapid and reliable method for biomedical diagnosis.
ER  - 

TY  - JOUR
T1  - Integrating GitLab metrics into coursework consultation sessions in a software engineering course
AU  - Eraslan, Sukru
AU  - Kopec-Harding, Kamilla
AU  - Jay, Caroline
AU  - Embury, Suzanne M.
AU  - Haines, Robert
AU  - Cortés Ríos, Julio César
AU  - Crowther, Peter
JO  - Journal of Systems and Software
VL  - 167
SP  - 110613
PY  - 2020
DA  - 2020/09/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2020.110613
UR  - https://www.sciencedirect.com/science/article/pii/S0164121220300911
KW  - Software engineering education
KW  - Undergraduate education
KW  - Collaborative software development
KW  - Version control system
KW  - Git
AB  - Software developers use version control systems for collaborative coding. These systems are integrated into several software development platforms (including GitLab and GitHub) which support additional software engineering functionalities. Using these platforms in an educational context allows students to gain skills relevant to industry, whilst providing a means of keeping track of their activities. In this paper, we investigate the effect of presenting teams of students with GitLab metrics about their performance at coursework consultation sessions (checkpoint sessions), with a particular focus on the number of issues assigned and completed, and the number of commits made to the repository. A comparative analysis of project marks in two consecutive academic years indicates that these checkpoint sessions may lead to better student outcomes. An interview study with students and teaching assistants identified viewing the GitLab metrics in the checkpoints as an opportunity to see the relative contributions of team members and address resulting issues, and as a catalyst for improving engagement with the team project. The study also identified drawbacks of using the metrics too simplistically, and suggested that it was important to consider the quality and amount of written code, as well as the number of times someone committed to the repository.
ER  - 

TY  - JOUR
T1  - Time optimization of the step loading technique in hydrogen embrittlement small punch tests
AU  - Arroyo, B.
AU  - Andrea, L.
AU  - Gutiérrez-Solana, F.
AU  - Álvarez, J.A.
JO  - Theoretical and Applied Fracture Mechanics
VL  - 117
SP  - 103206
PY  - 2022
DA  - 2022/02/01/
SN  - 0167-8442
DO  - https://doi.org/10.1016/j.tafmec.2021.103206
UR  - https://www.sciencedirect.com/science/article/pii/S0167844221003025
KW  - Small Punch test
KW  - Step loading technique
KW  - ASTM F1624
KW  - Threshold stress
KW  - Hydrogen embrittlement
KW  - Test time optimization
AB  - The small punch tests consists of punching a plane small specimen until it breaks. This technique is very interesting in situations where there is a shortage of material. In recent works, it has been used with steel employed in aggressive environments, to estimate the threshold stress under which subcritical cracking will never occur. It has been presented in previous papers in combination with standard ASTM 1624, applying gradually increasing constant loads until the sample fails, to reduce the duration of the test and the results dispersión. In the present paper, a further optimization is performed on the steps durations for SPT, simplifying the test and therefore helping to reduce the lab workload while at the same time saving costs and resources and increasing productivity. The present work is carried out on an X80 medium-strength rolled steel in hydrogen embrittlement environments under three different levels of cathodic polarization in an acid electrolyte; the chosen steel belongs to the lowest hardness range (33 ≤ HRC < 45) according to the ASTM 1624 standard. Different steps duration from 10 to 60 mintures had been analyzied, cocluding that 20–40 min for 1st to 10th and 11th to 20th steps respectivley are proposed as the minimum ones to reach accurate results. The proposed optimization allows to reduce the total test duration, being for sure of great interest for the metal industry as well as for the scientific comunity.
ER  - 

TY  - JOUR
T1  - Energy efficiency for cloud computing system based on predictive optimization
AU  - Bui, Dinh-Mao
AU  - Yoon, YongIk
AU  - Huh, Eui-Nam
AU  - Jun, SungIk
AU  - Lee, Sungyoung
JO  - Journal of Parallel and Distributed Computing
VL  - 102
SP  - 103
EP  - 114
PY  - 2017
DA  - 2017/04/01/
SN  - 0743-7315
DO  - https://doi.org/10.1016/j.jpdc.2016.11.011
UR  - https://www.sciencedirect.com/science/article/pii/S0743731516301708
KW  - Energy efficiency
KW  - IaaS cloud computing
KW  - Predictive analysis
KW  - Convex optimization
KW  - Gaussian process
AB  - In recent years, power consumption has become one of the hottest research trends in computer science and industry. Most of the reasons are related to the operational budget and the environmental issues. In this paper, we would like to propose an energy-efficient solution for orchestrating the resource in cloud computing. In nature, the proposed approach firstly predicts the resource utilization of the upcoming period based on the Gaussian process regression method. Subsequently, the convex optimization technique is engaged to compute an appropriate quantity of physical servers for each monitoring window. This quantity of interest is calculated to ensure that a minimum number of servers can still provide an acceptable quality of service. Finally, a corresponding migrating instruction is issued to stack the virtual machines and turn off the idle physical servers to achieve the objective of energy savings. In order to evaluate the proposed method, we conduct the experiments using synthetic data from 29-day period of Google traces and real workload from the Montage open-source toolkit. Through the evaluation, we show that the proposed approach can achieve a significant result in reducing the energy consumption as well as maintaining the system performance.
ER  - 

TY  - JOUR
T1  - Probabilistic model for 3D interactive segmentation
AU  - Hershkovich, Tsachi
AU  - Shalmon, Tamar
AU  - Shitrit, Ohad
AU  - Halay, Nir
AU  - Menze, Bjoern H.
AU  - Dolgopyat, Irit
AU  - Kahn, Itamar
AU  - Shelef, Ilan
AU  - Riklin Raviv, Tammy
JO  - Computer Vision and Image Understanding
VL  - 151
SP  - 47
EP  - 60
PY  - 2016
DA  - 2016/10/01/
T2  - Probabilistic Models for Biomedical Image Analysis
SN  - 1077-3142
DO  - https://doi.org/10.1016/j.cviu.2016.03.007
UR  - https://www.sciencedirect.com/science/article/pii/S1077314216300017
KW  - Image segmentation
KW  - User interaction
KW  - Probabilistic model
KW  - MR & CT Brain imaging
KW  - Modality fusion
AB  - Fully-automated segmentation algorithms offer fast, objective, and reproducible results for large data collections. However, these techniques cannot handle tasks that require contextual knowledge not readily available in the images alone. Thus, the supervision of an expert is necessary. We present a generative model for image segmentation, based on a Bayesian inference. Not only does our approach support an intuitive and convenient user interaction subject to the bottom-up constraints introduced by the image intensities, it also circumvents the main limitations of a human observer—3D visualization and modality fusion. The user “dialogue” with the segmentation algorithm via several mouse clicks in regions of disagreement, is formulated as a continuous probability map, that represents the user’s certainty to whether the current segmentation should be modified. Considering this probability map as the voxel-vise Bernoulli priors on the image labels allows spatial encoding of the user-provided input. The method is exemplified for the segmentation of cerebral hemorrhages (CH) in human brain CT scans; ventricles in degenerative mice brain MRIs, and tumors in multi-modal human brain MRIs and is shown to outperform three interactive, state-of-the-art segmentation methods in terms of accuracy, efficiency and user-workload.
ER  - 

TY  - JOUR
T1  - An abnormal situation modeling method to assist operators in safety-critical systems
AU  - Naderpour, Mohsen
AU  - Lu, Jie
AU  - Zhang, Guangquan
JO  - Reliability Engineering & System Safety
VL  - 133
SP  - 33
EP  - 47
PY  - 2015
DA  - 2015/01/01/
SN  - 0951-8320
DO  - https://doi.org/10.1016/j.ress.2014.08.003
UR  - https://www.sciencedirect.com/science/article/pii/S0951832014001963
KW  - Situation awareness
KW  - Situation assessment
KW  - Safety-critical systems
KW  - Bayesian networks
KW  - Fuzzy logic systems
KW  - Risk assessment
AB  - One of the main causes of accidents in safety-critical systems is human error. In order to reduce human errors in the process of handling abnormal situations that are highly complex and mentally taxing activities, operators need to be supported, from a cognitive perspective, in order to reduce their workload, stress, and the consequent error rate. Of the various cognitive activities, a correct understanding of the situation, i.e. situation awareness (SA), is a crucial factor in improving performance and reducing errors. Despite the importance of SA in decision-making in time- and safety-critical situations, the difficulty of SA modeling and assessment means that very few methods have as yet been developed. This study confronts this challenge, and develops an innovative abnormal situation modeling (ASM) method that exploits the capabilities of risk indicators, Bayesian networks and fuzzy logic systems. The risk indicators are used to identify abnormal situations, Bayesian networks are utilized to model them and a fuzzy logic system is developed to assess them. The ASM method can be used in the development of situation assessment decision support systems that underlie the achievement of SA. The performance of the ASM method is tested through a real case study at a chemical plant.
ER  - 

TY  - JOUR
T1  - Physiological Workload of Hill Farm Women of Meghalaya, India Involved in Firewood Collection
AU  - Borah, Swapnali
JO  - Procedia Manufacturing
VL  - 3
SP  - 4984
EP  - 4990
PY  - 2015
DA  - 2015/01/01/
T2  - 6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015
SN  - 2351-9789
DO  - https://doi.org/10.1016/j.promfg.2015.07.648
UR  - https://www.sciencedirect.com/science/article/pii/S2351978915006496
KW  - Drudgery
KW  - Physiological responses
KW  - Musculoskeletal problem
AB  - Women are not only carriers of human race but civilization and sustainable development rest on them. Their role is quietly appreciated without economic recognition, regard and accountability. The household activities farm women of Meghalaya do are labour intensive, time consuming, arduous, monotonous, repetitive, manual and within economic return resulting in fatigue and drudgery. This study was conducted to determine the perceived physiological exertion, physiological responses and musculoskeletal problem while doing the activity of firewood collection. The subject included forty tribal women of West Garo Hill of Meghalaya within the age group of 20 to 50 years having the average BMI of 21.74, Lean body mass 31.99kg., fat weight 12.59kg., VO2 max. 25.59ml/kg/min and grip strength of 28.59kg. While doing the activity average heart rate, energy expenditure, total cardiac cost of work and physiological cost of work were 129.67 bpm, 11.90 kj/min, 8529.59 beats and 47.92ppm, respectively. The cardiovascular stress index was quite high (47.25) in comparison to many workers involved in factory activities. Perceived physical exertion was rated by farm women as “heavy to very heavy”. Incidences of musculoskeletal problem were also very high as farm women reported that they had severe to very severe pain in upper and lower back, neck, head, arm, wrist and fingers.
ER  - 

TY  - JOUR
T1  - A dynamic execution time estimation model to save energy in heterogeneous multicores running periodic tasks
AU  - Sahuquillo, Julio
AU  - Hassan, Houcine
AU  - Petit, Salvador
AU  - March, José Luis
AU  - Duato, José
JO  - Future Generation Computer Systems
VL  - 56
SP  - 211
EP  - 219
PY  - 2016
DA  - 2016/03/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2015.06.011
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X15002216
KW  - Heterogeneous multicore architectures
KW  - Time predictable multicore architectures
KW  - Time aware energy efficiency
KW  - Energy savings
KW  - Real-time embedded systems
AB  - Nowadays, real-time embedded applications have to cope with an increasing demand of functionalities, which require increasing processing capabilities. With this aim real-time systems are being implemented on top of high-performance multicore processors that run multithreaded periodic workloads by allocating threads to individual cores. In addition, to improve both performance and energy savings, the industry is introducing new multicore designs such as ARM’s big.LITTLE that include heterogeneous cores in the same package. A key issue to improve energy savings in multicore embedded real-time systems and reduce the number of deadline misses is to accurately estimate the execution time of the tasks considering the supported processor frequencies. Two main aspects make this estimation difficult. First, the running threads compete among them for shared resources. Second, almost all current microprocessors implement Dynamic Voltage and Frequency Scaling (DVFS) regulators to dynamically adjust the voltage/frequency at run-time according to the workload behavior. Existing execution time estimation models rely on off-line analysis or on the assumption that the task execution time scales linearly with the processor frequency, which can bring important deviations since the memory system uses a different power supply. In contrast, this paper proposes the Processor–Memory (Proc–Mem) model, which dynamically predicts the distinct task execution times depending on the implemented processor frequencies. A power-aware EDF (Earliest Deadline First)-based scheduler using the Proc–Mem approach has been evaluated and compared against the same scheduler using a typical Constant Memory Access Time model, namely CMAT. Results on a heterogeneous multicore processor show that the average deviation of Proc–Mem is only by 5.55% with respect to the actual measured execution time, while the average deviation of the CMAT model is 36.42%. These results turn in important energy savings, by 18% on average and up to 31% in some mixes, in comparison to CMAT for a similar number of deadline misses.
ER  - 

TY  - JOUR
T1  - Fatigue differences between Asian and Western populations in prolonged mentally demanding work-tasks
AU  - Ahmed, Shaheen
AU  - Babski-Reeves, Kari
AU  - DuBien, Janice
AU  - Webb, Heather
AU  - Strawderman, Lesley
JO  - International Journal of Industrial Ergonomics
VL  - 54
SP  - 103
EP  - 112
PY  - 2016
DA  - 2016/07/01/
SN  - 0169-8141
DO  - https://doi.org/10.1016/j.ergon.2016.05.005
UR  - https://www.sciencedirect.com/science/article/pii/S0169814116300403
KW  - Fatigue
KW  - Ethnicity
KW  - Asian
KW  - Western
KW  - Mental
KW  - Work-task
AB  - Introduction
With an increase in the number of mentally demanding jobs, as well as the increase in work performed while sedentary, there is a growing imbalance in the use of body resources. This often results in an increase in fatigue in the working population. The diversity of the workforce is also increasing, whereas physiological differences based on culture are important to consider. The objective of this study was to identify the differences in the levels of fatigue in the workplace experienced by Asian and Western workers in mentally demanding jobs.
Method
Eight Asian and eight Western participants completed an observation-based study. Each participant was observed for four hours in their workplace while they were working on highly mentally demanding work-tasks either computer programming or mathematical simulations. To balance the effect of time, half of the participants from each ethnic group were observed in the morning session and the other half in the afternoon session. Perceived fatigue was measured every 30 min using the single dimensional Borg and multidimensional SOFI scales. Workload was measured using NASA-TLX, and as a change in resting heart rate.
Result
Ethnicity and time interacted to significantly affect the perceived fatigue measured by Borg (F (9,126) = 2.03, p = 0.0412) and SOFI (F(9,126) = 3.28, p = 0.0013) scales. Asian participants reported significantly higher workload measured by NASA-TLX scores (F(1, 14) = 3.68, p = 0.0024) and change in resting heart rate (F(1, 14) = 7.77, p = 0.0145) was measured higher compared to Western participants. Unlike fatigue, no significant interactions were observed between time and ethnicity to affect either NASA-TLX scores or change in resting heart rate. Post-hoc analyses show that the rate of fatigue was higher for Asian participants. Correlations between the dependent variables were significant (p < 0.0001), with a stronger correlation identified for Asian participants.
Conclusion
As compared to the Western participants, Asian participants reported higher values in all dependent measures, including fatigue in both scales, NASA-TLX scores, and change in resting heart rate.
Relevance to industry
The significant growth in white-collar as well as mentally demanding jobs requires more cognitive resources, while reducing physical activities. The consequences of the imbalances in the use of body resources have yet to be studied. This study has been designed to investigate the issues of imbalance in the workplace.
ER  - 

TY  - JOUR
T1  - Quantifying the physical intensity of construction workers, a mechanical energy approach
AU  - Kong, Liulin
AU  - Li, Heng
AU  - Yu, Yantao
AU  - Luo, Hanbin
AU  - Skitmore, Martin
AU  - Antwi-Afari, Maxwell Fordjour
JO  - Advanced Engineering Informatics
VL  - 38
SP  - 404
EP  - 419
PY  - 2018
DA  - 2018/10/01/
SN  - 1474-0346
DO  - https://doi.org/10.1016/j.aei.2018.08.005
UR  - https://www.sciencedirect.com/science/article/pii/S147403461830243X
KW  - Construction activity
KW  - Mechanical energy expenditure
KW  - Biomechanical analysis
KW  - Human 3D Pose Estimation
AB  - Construction workers typically undertake highly demanding physical tasks involving various types of stresses from awkward postures, using excessive force, highly repetitive actions, and excessive energy expenditure, which increases the likelihood of unsafe actions, productivity loss, and human errors. Biomechanical models have been developed to estimate joint loadings, which can help avoid strenuous physical exertion, potentially enhancing construction workforce productivity, safety, and well-being. However, the models used are mainly in 2D, or to predict static strength ignored their velocity and acceleration or using marker-based method for dynamic motion data collection. To address this issue, this paper proposes a novel framework for investigating the mechanical energy expenditure (MEE) of workers using a 3D biomechanical model based on computer vision-based techniques. Human 3D Pose Estimation algorithm based on 2D videos is applied to approximate the coordinates of human joints for working postures, and smart insoles are used to collect foot pressures and plantar accelerations, as input data for the biomechanical analyses. The results show a detailed MEE rate for the whole body, at which joints the maximum and minimum values were obtained to avoid excessive physical exertion. The proposed method can approximate the total daily MEE of construction tasks by summing the assumed cost of individual tasks (such as walking, lifting, and stooping), providing suggestions for the design of a daily workload that workers can sustain without developing cumulative fatigue.
ER  - 

TY  - JOUR
T1  - Analysis of changes in coordinate measuring machines accuracy made by different nodes density in geometrical errors correction matrix
AU  - Gąska, A.
AU  - Sładek, J.
AU  - Ostrowska, K.
AU  - Kupiec, R.
AU  - Krawczyk, M.
AU  - Harmatys, W.
AU  - Gąska, P.
AU  - Gruza, M.
AU  - Owczarek, D.
AU  - Knapik, R.
AU  - Kmita, A.
JO  - Measurement
VL  - 68
SP  - 155
EP  - 163
PY  - 2015
DA  - 2015/05/01/
SN  - 0263-2241
DO  - https://doi.org/10.1016/j.measurement.2015.02.056
UR  - https://www.sciencedirect.com/science/article/pii/S0263224115001207
KW  - Geometric compensation
KW  - CAA
KW  - Geometric error
KW  - Machine mapping
KW  - CMM
AB  - Advances in modern manufacturing techniques increase production efficiency but, at the same time, present new tasks and challenges for coordinate metrology and the manufacturers of Coordinate Measuring Machines (CMMs). The main goal of current research efforts is improving measurement accuracy. Seeing as many of the possible solutions regarding CMM construction had already been explored, there seems to be little left for improvement in that field. Further efforts at accuracy improvement rely mostly on using sophisticated mathematical algorithms designed to correct relevant errors. Many types of errors could be compensated using this approach, including: probe head errors, machine dynamics errors and, most importantly, machine geometrical errors. Almost all coordinate measuring machines produced nowadays are equipped with geometrical errors compensation matrix known as the CAA matrix (Computer Aided Accuracy). CAA matrices are based on a grid of reference points (nodes) in which certain values of the components of geometrical errors are determined experimentally. The error values between the nodes are estimated using simple interpolation methods. Theoretically, a higher density of reference points on the grid describing the CAA matrix should improve the accuracy of the machine utilizing the matrix. On the other hand, increasing the number of nodes simultaneously increases the amount of workload, time and money spent on constructing the CAA matrix. This paper presents a number of experiments aimed at creating CAA matrices with different number of matrix nodes using the LaserTracer system. The relations between maximum permissible errors obtained on a machine using matrices with different densities of nodes are also discussed. Additionally, the authors attempt to tackle the question of determining the most optimal density of nodes with regards to the ratio of time spent on matrix creation and the effect on accuracy.
ER  - 

TY  - JOUR
T1  - Moment-rotation model of endplate blind bolted joints with CFST column
AU  - Fan, Junchao
AU  - Zhao, Junhai
AU  - Gao, Weiqi
JO  - Journal of Constructional Steel Research
VL  - 176
SP  - 106446
PY  - 2021
DA  - 2021/01/01/
SN  - 0143-974X
DO  - https://doi.org/10.1016/j.jcsr.2020.106446
UR  - https://www.sciencedirect.com/science/article/pii/S0143974X20309986
KW  - Moment-rotation relation curve
KW  - Ultimate bending moment
KW  - Initial rotational stiffness
KW  - Blind bolted joints with CFST columns
KW  - Component method
AB  - The moment-rotation curves can directly reflect the performance of H-shaped beam to concrete filled steel tube (CFST) column joints, which should be fully considered in structure analysis and design of such joints. However, the current determination of moment-rotation curves is mainly fitting results of experiments or simulations, which results considerable consumption of human and material resources. Hence, this paper proposes a new three-parameter exponential model for this type of joint to forecast the moment-rotation relation curve. Considering possible failure modes, a calculation method of ultimate bending moment for joints is proposed. An analysis model of initial rotational stiffness for joints is established according to component method. Based on the research results of this paper, the ultimate bending moment and initial rotational stiffness can be calculated straight by measurement factors and material properties. The values of the shape parameter for two kinds of the joint are derived by fitting the existing experimental data. Based on the established prediction model of moment-rotation, an accurate calculation method of ultimate bending moment, and analysis model of initial rotational stiffness, the prediction results are in good agreement with experimental results according to the comparison. The established moment-rotation model may be applied to the design of composite frames to predict the behavior of the joint with endplate and blind bolts simply and accurately. Moreover, it can save the workload of experiments and simulations.
ER  - 

TY  - JOUR
T1  - Interaction design for paediatric emergency VR training
AU  - Matthews, Tj
AU  - Tian, Feng
AU  - Dolby, Tom
JO  - Virtual Reality & Intelligent Hardware
VL  - 2
IS  - 4
SP  - 330
EP  - 344
PY  - 2020
DA  - 2020/08/01/
T2  - VR and experiment simulation
SN  - 2096-5796
DO  - https://doi.org/10.1016/j.vrih.2020.07.006
UR  - https://www.sciencedirect.com/science/article/pii/S2096579620300590
KW  - Virtual reality
KW  - Medical training
KW  - Human-Centred design
KW  - Interaction design
AB  - Background
Virtual reality (VR) in healthcare training has increased adoption and support, but efforts are still required to mitigate usability concerns.
Methods
This study conducted a usability study of an in-use emergency medicine VR training application, available on commercially available VR hardware and with a standard interaction design. Nine users without prior VR experience but with relevant medical expertise completed two simulation scenarios for a total of 18 recorded sessions. They completed NASA Task Load Index and System Usability Scale questionnaires after each session, and their performance was recorded for the tracking of user errors.
Results and Conclusion
s Our results showed a medium (and potentially optimal) Workload and an above average System Usability Score. There was significant improvement in several factors between users' first and second sessions, notably increased Performance evaluation. User errors with the strongest correlation to usability were not directly tied to interaction design, however, but to a limited 'possibility space'. Suggestions for closing this 'gulf of execution' were presented, including 'voice control' and 'hand-tracking', which are only feasible for this commercial product now with the availability of the Oculus Quest headset. Moreover, wider implications for VR medical training were outlined, and potential next steps towards a standardized design identified.
ER  - 

TY  - JOUR
T1  - Genetically-modified Multi-objective Particle Swarm Optimization approach for high-performance computing workflow scheduling
AU  - Hafsi, Haithem
AU  - Gharsellaoui, Hamza
AU  - Bouamama, Sadok
JO  - Applied Soft Computing
VL  - 122
SP  - 108791
PY  - 2022
DA  - 2022/06/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2022.108791
UR  - https://www.sciencedirect.com/science/article/pii/S1568494622002113
KW  - Workflow scheduling
KW  - Multi-objective optimization
KW  - High-performance computing
KW  - Hybrid clouds
AB  - Nowadays, scientific research, industry, and many other fields are greedy regarding computing resources. Therefore, Cloud Computing infrastructures are now attracting pervasive interest thanks to their excellent hallmarks such as scalability, high performance, reliability, and the pay-per-use strategy. The execution of these high-performant applications on such kind of computing environments in respect of optimizing many conflicting objectives brings us to a challenging issue commonly known as the multi-objective workflows scheduling on large scale distributed systems. Having this in mind, we outline in the present paper our proposed approach called Genetically-modified Multi-objective Particle Swarm Optimization (GMPSO) for scheduling application workflows on hybrid Clouds in the context of high-performance computing in an attempt to optimize Makespan and Cost. The GMPSO consists of incorporating genetic operations into the Multi-objective Particle Swarm Optimization to enhance the resulting solutions. To achieve this, we have designed a novel solution encoding that represents the task ordering, the task mapping and the resource provisioning processes of the workflow scheduling problem in hybrid Clouds. In addition, a set of particular adaptive evolutionary operators have been designed. Conducted simulations lead to significant results compared with a set of well-performed algorithms such NSGA-II, OMOPSO and SMPSO, especially, for the most-demanding workload of workflows.
ER  - 

TY  - JOUR
T1  - Statistical modeling for visualization evaluation through data fusion
AU  - Chen, Xiaoyu
AU  - Jin, Ran
JO  - Applied Ergonomics
VL  - 65
SP  - 551
EP  - 561
PY  - 2017
DA  - 2017/11/01/
SN  - 0003-6870
DO  - https://doi.org/10.1016/j.apergo.2016.12.016
UR  - https://www.sciencedirect.com/science/article/pii/S0003687016302769
KW  - Data fusion
KW  - Data visualization
KW  - Electroencephalogram (EEG)
KW  - Eye tracking
KW  - User-centered designs
KW  - Visualization evaluation
AB  - There is a high demand of data visualization providing insights to users in various applications. However, a consistent, online visualization evaluation method to quantify mental workload or user preference is lacking, which leads to an inefficient visualization and user interface design process. Recently, the advancement of interactive and sensing technologies makes the electroencephalogram (EEG) signals, eye movements as well as visualization logs available in user-centered evaluation. This paper proposes a data fusion model and the application procedure for quantitative and online visualization evaluation. 15 participants joined the study based on three different visualization designs. The results provide a regularized regression model which can accurately predict the user's evaluation of task complexity, and indicate the significance of all three types of sensing data sets for visualization evaluation. This model can be widely applied to data visualization evaluation, and other user-centered designs evaluation and data analysis in human factors and ergonomics.
ER  - 

TY  - JOUR
T1  - Exploring the benefits of conversing with a digital voice assistant during automated driving: A parametric duration model of takeover time
AU  - Mahajan, Kirti
AU  - Large, David R.
AU  - Burnett, Gary
AU  - Velaga, Nagendra R.
JO  - Transportation Research Part F: Traffic Psychology and Behaviour
VL  - 80
SP  - 104
EP  - 126
PY  - 2021
DA  - 2021/07/01/
SN  - 1369-8478
DO  - https://doi.org/10.1016/j.trf.2021.03.012
UR  - https://www.sciencedirect.com/science/article/pii/S1369847821000668
KW  - Human-machine-interfaces
KW  - Voice-user interfaces (VUI)
KW  - Conditional automation
KW  - SAE level 3
KW  - Passive fatigue
KW  - Driver takeover
AB  - Vehicle automation allows drivers to disengage from driving causing a potential decline in their alertness. One of the major challenges of highly automated vehicles is to ensure a timely (with respect to safety and situation awareness) takeover in such conditions. For this purpose, the current study investigated the role of an in-vehicle digital voice-assistant (VA) in conditionally automated vehicles, offering spoken discourse relating specifically to contextual factors, such as the traffic situation and road environment. The study involved twenty-four participants, each taking two drives (counterbalanced): with VA and without VA, in a driving simulator. Participants were required to takeover vehicle control following the issuance of a takeover request (TOR) near the end of each drive. A parametric duration model was adopted to find the key factors determining takeover time (TOT). Paired comparisons showed higher alertness and higher active workload (mean NASA-TLX rating) during automation when accompanied by the VA. Paired t-test comparison of gaze behavior prior to takeover showed significantly higher instances of checking traffic signal, roadside objects, and the roadway during the drive with VA, indicating higher situation awareness. The parametric model indicated that the VA increased the likelihood of making a timely takeover by 39%. There was also some evidence suggesting that male drivers are likely to resume control 1.21 times earlier than female drivers. The study findings highlight the benefits of adopting a digital voice assistant to keep the drivers alert and aware about the recent traffic environment in partially automated vehicles.
ER  - 

TY  - JOUR
T1  - The Power Line Inspection Software (PoLIS): A versatile system for automating power line inspection
AU  - Martinez, Carol
AU  - Sampedro, Carlos
AU  - Chauhan, Aneesh
AU  - Collumeau, Jean François
AU  - Campoy, Pascual
JO  - Engineering Applications of Artificial Intelligence
VL  - 71
SP  - 293
EP  - 314
PY  - 2018
DA  - 2018/05/01/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2018.02.008
UR  - https://www.sciencedirect.com/science/article/pii/S0952197618300290
KW  - Power line inspection
KW  - Machine learning
KW  - Visual tracking
KW  - Computer vision
AB  - A large amount of data, provided in the form of video data, is acquired during manned inspections flights of electric power lines. This data is analyzed by expert human inspectors to detect faults in the power lines infrastructure and prepare the inspection reports. This process is extremely time consuming, very expensive and prone to human error. In this paper, we present PoLIS: the Power Line Inspection Software, which has been developed with the objective of assisting the analysis of the data acquired during inspection flights. PoLIS is based on the cooperation between computer vision and machine learning techniques to automatically process video sequences acquired during inspection flights, resulting in a set of representative images per electric tower which we call Key Frames. These representative images can then be used for inspection purposes, leading to a drastic reduction of the human operators’ workload. At the core of the strategy lies an electric tower detector, which is in charge of estimating the location of the towers within the images based on the combination of a sliding window search technique and a supervised classifier. The location of the tower is then tracked using a tracking-by-registration algorithm based on direct methods, estimating the position of the tower in different images. Finally, different criteria are applied for defining whether the image corresponds to a Key Frame image or not. Extensive evaluation of the proposed strategy is conducted using videos acquired during manned helicopter inspections. The videos constituting this database contain several thousand frames representing both medium and high voltage power transmission lines in the infra-red (IR) and visible spectra. The obtained results show that the proposed strategy can reduce the large amount of data present in the inspection videos to a few Key Frames for each tower. It is also demonstrated that the learning-based approach proposed in PoLIS is appropriate for detecting electric towers, a process which is made faster and more robust by coupling it with a tower tracking algorithm. A Graphical User Interface allowing the application of PoLIS to user-provided videos is also presented in this paper, illustrating the whole process and the automated generation of an inspection report.
ER  - 

TY  - JOUR
T1  - GPR pattern recognition of shallow subsurface air voids
AU  - Luo, Tess X.H.
AU  - Lai, Wallace W.L.
JO  - Tunnelling and Underground Space Technology
VL  - 99
SP  - 103355
PY  - 2020
DA  - 2020/05/01/
SN  - 0886-7798
DO  - https://doi.org/10.1016/j.tust.2020.103355
UR  - https://www.sciencedirect.com/science/article/pii/S088677981930063X
KW  - Ground penetrating radar
KW  - Subsurface air void
KW  - Pyramid method
KW  - Pattern recognition
AB  - Countless subsurface voids in urban areas of cities threaten people’s lives and property. A workflow for automatically identifying subsurface voids from ground penetrating radar (GPR) data was developed in this study. The workflow consists of 3 stages: locating voids automatically from C-scans, then verifying voids from corresponding B-scans, and finally making judgements based upon the previous 2 sets of results. This study adopted 2 (Lai et al., 2016) approaches: approach 1 quantified the GPR response of air voids using forward modelling, while approach 2 used workflow prototyping and validation with inverse modelling. Forward simulations indicated that different ratios of void size to GPR signal footprint could result in a variety of patterns in B-scans: they can be hyperbolas, cross patterns, bowl shaped patterns and reverberations. With a database of void patterns of both C-scans and B-scans established, in approach 2 the workflow uses a pyramid pattern recognition method – with pixel value or gradient being used for feature identification – to search automatically for air-filled void responses in GPR data. The workflow was tested using 2 laboratory and field experiments and the results were promising. The constraint values proposed by the 2 experiments were validated with another site experiment. Given the huge workload involved in city-scale subsurface health inspections, a standardized workflow can help improve efficiency and effectiveness of subsurface void identification.
ER  - 

TY  - JOUR
T1  - PARMA-CC: A family of parallel multiphase approximate cluster combining algorithms
AU  - Keramatian, Amir
AU  - Gulisano, Vincenzo
AU  - Papatriantafilou, Marina
AU  - Tsigas, Philippas
JO  - Journal of Parallel and Distributed Computing
VL  - 177
SP  - 68
EP  - 88
PY  - 2023
DA  - 2023/07/01/
SN  - 0743-7315
DO  - https://doi.org/10.1016/j.jpdc.2023.02.001
UR  - https://www.sciencedirect.com/science/article/pii/S0743731523000163
KW  - Parallel clustering
KW  - Approximation
KW  - Data structures
KW  - Synchronization
AB  - Clustering is a common task in data analysis applications. Despite the extensive literature, the continuously increasing volumes of data produced by sensors (e.g., rates of several MB/s by 3D scanners such as LIDAR sensors), and the time-sensitivity of the applications leveraging the clustering outcomes (e.g., detecting critical situations such as detecting boundary crossing from a robot arm that could injure human beings) demand for efficient data clustering algorithms that can effectively utilize the increasing computational capacities of modern hardware. To that end, we leverage approximation and parallelization, where the former is to scale down the amount of data, and the latter is to scale up the computation. Regarding parallelization, we explore a design space for synchronization and workload distribution among the threads. As we study different parts of the design space, we propose representative Parallel Multiphase Approximate Cluster Combining, abbreviated as PARMA-CC, algorithms. We show that PARMA-CC algorithms yield equivalent clustering outcomes despite their different approaches. Furthermore, we show that certain PARMA-CC algorithms can achieve higher efficiency with respect to certain properties of the data to be clustered. Generally speaking, in PARMA-CC algorithms, parallel threads compute summaries associated with clusters of data (sub)sets. As the threads concurrently combine the summaries, they construct a comprehensive summary of the sets of clusters. By approximating a cluster with its respective geometrical summaries, PARMA-CC algorithms scale well with increasing data volumes, and, by computing and efficiently combining the summaries in parallel, they enable latency improvements. PARMA-CC algorithms utilize special data structures that enable parallelism through in-place data processing. As we show in our analysis and evaluation, PARMA-CC algorithms can complement and outperform well-established methods, with significantly better timeliness especially when utilizing multiple threads, while still providing highly accurate results in a variety of data sets, even with skewed data distributions, which cause the traditional approaches to exhibit their worst-case behaviour.
ER  - 

TY  - JOUR
T1  - Visual Cryptography Based Multilevel Protection Scheme for Visualization of Network Security Situation
AU  - Hua, Hao
AU  - Liu, Yuling
AU  - Wang, Yongwei
AU  - Chang, Dexian
AU  - Leng, Qiang
JO  - Procedia Computer Science
VL  - 131
SP  - 204
EP  - 212
PY  - 2018
DA  - 2018/01/01/
T2  - Recent Advancement in Information and Communication Technology:
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2018.04.204
UR  - https://www.sciencedirect.com/science/article/pii/S1877050918305799
KW  - multilevel protection
KW  - network security situation
KW  - visualization
KW  - visual cryptography
KW  - region increment
AB  - Visualization technology for network security situation adopts images to present the massive abstract data regarding network events. It reduces the workload of data analysis and benefits the manager to grasp the overall network status and trend. Secret information in the visual image requires confidentiality protection while transmitting. Comparing with some conventional methods realized by complicated encryptions such as DES and AES, we present a novel multilevel protection scheme based on visual cryptography (VC) with the beauty of decryption done only via the human eyes without using more computing devices. Essentially, a region incrementing VC scheme (RIVCS) is proposed in this paper dealing with the encoding of a secret situation image regarding network security. The secret image includes a number of regions, where each region is allocated with a certain secrecy level. Different secrecy levels can be decoded incrementally when different combinations of participants are gained. Firstly, we develop the model called the general AS (GAS) based RIVCS. Secondly, we design the algorithm for allocating secrecy levels. Thirdly, we construct the encoding matrices for sharing the secret pixels. Experimental results show that our method is more suitable to visualization data protection for network security situation with lower cost, higher reliability and richer application scenarios.
ER  - 

TY  - JOUR
T1  - Product sizing with 3D anthropometry and k-medoids clustering
AU  - Lacko, Daniël
AU  - Huysmans, Toon
AU  - Vleugels, Jochen
AU  - De Bruyne, Guido
AU  - Van Hulle, Marc M.
AU  - Sijbers, Jan
AU  - Verwulgen, Stijn
JO  - Computer-Aided Design
VL  - 91
SP  - 60
EP  - 74
PY  - 2017
DA  - 2017/10/01/
SN  - 0010-4485
DO  - https://doi.org/10.1016/j.cad.2017.06.004
UR  - https://www.sciencedirect.com/science/article/pii/S0010448517301173
KW  - 3D anthropometry
KW  - Statistical shape model
KW  - Clustering
KW  - Product sizing
KW  - Human head
AB  - Aside from anthropometric data tables, 3D shape models of the human body are becoming increasingly common and call for new product sizing methods based on 3D anthropometry. Though some shape model-based methods exist, most of them focus on mathematical clustering and do not discuss the usability of the clustering results for product design. In this paper, a new shape-model based clustering method for product sizing is presented that takes into account both shape information and usability for designers. The new method, called constrained k-medoids clustering, is applied on a shape model of 100 human heads. It is compared to a partitioning around medoid (PAM) clustering of anthropometric measurements of the same 100 heads (i.e., feature-based), as well as to PAM clustering of the shape model (i.e., shape based). Results show that both shape-based and constrained clustering perform better than feature-based clustering, with an average size-weighted variance (SWV) of 62×103±16×103 and 66×103±26×103 as compared to 72×103±12×103, respectively. The average point-to-point distances in shape-based and constrained k-medoids were found to be similar to those of feature-based k-medoids, indicating that using 3D-anthropometry for product sizing will not have a negative impact on designer workload and/or a higher cost to implement more sizes. The results suggest that for head-based products, which require accurate shape and size fit, sizing systems should be created using either shape-based or constrained k-medoids, with the latter being slightly less accurate but more intuitive for further design and verification.
ER  - 

TY  - JOUR
T1  - Effects of dataset characteristics on the performance of fatigue detection for crane operators using hybrid deep neural networks
AU  - Liu, Pengkun
AU  - Chi, Hung-Lin
AU  - Li, Xiao
AU  - Guo, Jingjing
JO  - Automation in Construction
VL  - 132
SP  - 103901
PY  - 2021
DA  - 2021/12/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2021.103901
UR  - https://www.sciencedirect.com/science/article/pii/S0926580521003526
KW  - Tower crane operator
KW  - Construction safety
KW  - Fatigue detection
KW  - Multi-sources datasets
KW  - Convolutional neural network (CNN)
KW  - Long short-term memory network (LSTM)
AB  - Fatigue of operators due to intensive workloads and long working time is a significant constraint that leads to inefficient crane operations and increased risk of safety issues. It can be potentially prevented through early warnings of fatigue for further appropriate work shift arrangements. Many deep neural networks have recently been developed for the fatigue detection of vehicle drivers through training and processing the facial image or video data from the public driver's datasets. However, these datasets are difficult to directly use for the fatigue detections under crane operation scenarios due to the variations of facial features and head movement patterns between crane operators and vehicle drivers. Furthermore, there is no representative and public dataset with the facial information of crane operators under construction scenarios. Therefore, this study aims to explore and analyse the features of multi-sources datasets and the corresponding data acquisition methods which are suitable for crane operators' fatigue detection, further providing collection guidelines of crane operators dataset. Variations on public datasets such as real or pretend facial expression, the segment level of human-verified labelling, camera positions, acquisition scenarios, and illumination conditions are analysed. A hybrid learning architecture is proposed by combining convolutional neural networks (CNN) and long short-term memory (LSTM) for fatigue detection. In order to establish a unified evaluation criterion, the effort of the study includes relabelling three public vehicle drivers datasets, NTHU-DDD, UTA-RLDD, and YawnDD, with human-verified labels at the frame and minute segment levels, and training the corresponding hybrid fatigue detection models accordingly. The average detection accuracies and losses are identified for the trained models of UTA-RLDD, NTHU-DDD, and YawnDD individually. The trained models are used to evaluate the fatigue status of facial videos from licensed crane operators under simulated crane operation scenarios. The results suggest the necessary considerations of different influential factors for establishing a large and public fatigue dataset for crane operators.
ER  - 

TY  - JOUR
T1  - Enhancing a Rule-based Event Coder with Semantic Vectors
AU  - Guo, Jinhong K.
AU  - Van Brackle, David
AU  - Hofmann, Martin O.
JO  - Procedia Computer Science
VL  - 36
SP  - 168
EP  - 174
PY  - 2014
DA  - 2014/01/01/
T2  - Complex Adaptive Systems Philadelphia, PA November 3-5, 2014
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2014.09.074
UR  - https://www.sciencedirect.com/science/article/pii/S1877050914013234
KW  - NLP
KW  - semantic vectors
KW  - Random Indexing
KW  - event coding
KW  - rule-based system
KW  - machine learning
AB  - Rule based systems have achieved success in applications such as information retrieval and Natural Language Processing. However, due to the rigidity of pattern matching, these systems typically require a large number of rules to adequately cover the variations of expression in unstructured text. Consequently, knowledge engineering for a new domain and knowledge maintenance for a fielded system are labor intensive and expensive. In this paper, we present our research on enhancing a rule-based event coding system by relaxing the rigidity of pattern matching with a technique that formulates and matches patterns of the semantics of words instead of literal words. Our technique pairs literal words with semantic vectors that accumulate word meaning from the context of use of the word found in dictionaries, ontologies, and domain corpora. Our method improves the speed, accuracy, and coverage of the event coding algorithm without additional knowledge engineering effort. Operating on semantics instead of syntax, the improved system eases the workload of human analysts who screen input text for critical events. Our algorithms are based on high-dimensional distributed representations, and their effectiveness and versatility derive from the unintuitive properties of such representations---from the mathematical properties of high-dimensional spaces. Our current implementation encodes words, phrases, and rule patterns as semantic vectors using WordNet, We have started experimental evaluation using a large newswire dataset.
ER  - 

TY  - JOUR
T1  - Neural malware analysis with attention mechanism
AU  - Yakura, Hiromu
AU  - Shinozaki, Shinnosuke
AU  - Nishimura, Reon
AU  - Oyama, Yoshihiro
AU  - Sakuma, Jun
JO  - Computers & Security
VL  - 87
SP  - 101592
PY  - 2019
DA  - 2019/11/01/
SN  - 0167-4048
DO  - https://doi.org/10.1016/j.cose.2019.101592
UR  - https://www.sciencedirect.com/science/article/pii/S0167404819300264
KW  - Malware analysis
KW  - Convolutional neural network
KW  - Attention mechanism
KW  - Static analysis
KW  - Machine learning
AB  - Objectives: In order to confront diverse types of malware that evolve from moment to moment, it is important to instantly acquire deep knowledge related to the characteristics of malware samples. This paper proposes a method by which to extract important byte sequences of a given malware sample that characterize the functionality of the sample, which reduces the workload of human analysts who investigate the functionality of the sample. Design & methods: By applying a convolutional neural network (CNN) with an attention mechanism to an image converted from binary data, the proposed method enables calculation of an attention map, which is expected to specify regions having higher importance for classification. This distinction of regions enables the extraction of characteristic byte sequences peculiar to the malware family from the binary data and can provide useful information for human analysts without a priori knowledge. Results: The results of an evaluation experiment using a malware dataset reveal that the sequences extracted by the proposed method provide useful information for manual analysis. For example, in the case of Backdoor.Win32.Agobot.lt, the region with the highest importance in the attention map points at a function to receive commands from a remote server via IRC. This result characterizes the behavior of its family, Worm:Win32/Gaobot, which executes commands sent via IRC to construct a botnet. Conclusions: By taking advantage of a CNN with the attention mechanism, the proposed method is shown to provide important regions in the binaries selectively for manual analysis of malware samples.
ER  - 

TY  - JOUR
T1  - An automatic and rapid system for grading palm bunch using a Kinect camera
AU  - Pamornnak, Burawich
AU  - Limsiroratana, Somchai
AU  - Khaorapapong, Thanate
AU  - Chongcheawchamnan, Mitchai
AU  - Ruckelshausen, Arno
JO  - Computers and Electronics in Agriculture
VL  - 143
SP  - 227
EP  - 237
PY  - 2017
DA  - 2017/12/01/
SN  - 0168-1699
DO  - https://doi.org/10.1016/j.compag.2017.10.020
UR  - https://www.sciencedirect.com/science/article/pii/S0168169917303150
KW  - Depth image
KW  - NIR reflectance
KW  - Multi-sensing
KW  - Field work
KW  - Phenotyping
AB  - In a trading market, price of oil palm (Elaeis guineensis) is negotiated depending some key parameters of the fresh fruit bunch (FFB). Inspectors have been hired by a buyer to grade FFB to accept or reject. The classification results made by human inspection are skeptical and not very reliable if workload is high. We have developed a system to grade FFB depending on its quality. Several palm features are extracted from RGB, near infrared, and depth images, captured with a Microsoft Kinect camera version 2.0 installed in a light-controlled environment on the conveyor line. Two main algorithms for classification have been developed. The first algorithm is called a volume integration scheme (SVIS), which measures the relative volume of palm bunch. The second developed algorithm classifies palm bunch into three grades (L-Grade, M-Grade and H-Grade) based on oil content from Soxhlet extraction. The system achieves 83% accuracy for grading palm bunch within 6 s per one sample, which shows the possibility of using the system in a trading market.
ER  - 

TY  - JOUR
T1  - A renewable energy-aware power allocation for cloud data centers: A game theory approach
AU  - Benblidia, Mohammed Anis
AU  - Brik, Bouziane
AU  - Esseghir, Moez
AU  - Merghem-Boulahia, Leila
JO  - Computer Communications
VL  - 179
SP  - 102
EP  - 111
PY  - 2021
DA  - 2021/11/01/
SN  - 0140-3664
DO  - https://doi.org/10.1016/j.comcom.2021.08.001
UR  - https://www.sciencedirect.com/science/article/pii/S0140366421002954
KW  - Cloud data centers
KW  - Green networking
KW  - Game theory
KW  - Renewable energy
KW  - Smart grid
KW  - Power dispatching
AB  - With the rapid emerging of Internet of Things (IoT) devices and the proliferation of cloud-based applications, the cloud computing industry is becoming a vital element for ensuring our daily services. However, cloud computing uses large scale data centers equipped with energy-hungry servers and huge power facilities that massively consume power. This presents a real challenge which can negatively influence the power grid, while exposing the environment to global warming issues. Therefore, minimizing cloud data center power consumption is a challenging problem and has to be addressed. In this paper, we look at renewable energy in the context of a smart grid–cloud architecture and investigate the issue of grid power dispatching to cloud data centers. Since cloud data centers have a non-cooperative nature regarding power demand from the power stations, we model our power allocation problem as a non-cooperative game. Afterwards, we prove the existence and the uniqueness of Nash equilibrium. Moreover, we formulate the payoff function of our game as a non-linear optimization problem before resolving it using Lagrange multipliers and Karush–Kuhn–Tucker (KKT) conditions. Thus, we determine the assigned optimal quantity to each data center based on three main criteria : renewable energy usage, number of critical running applications and workload charge. Extensive simulations are performed by comparing our scheme with an existing work. Results show that our scheme outperforms the comparing approach with a percentage of 31.2% in terms of power load rate and significantly reduces emissions of carbon dioxide.
ER  - 

TY  - JOUR
T1  - CLPKM: A checkpoint-based preemptive multitasking framework for OpenCL kernels
AU  - Chiu, Ming-Tsung
AU  - You, Yi-Ping
JO  - Journal of Systems Architecture
VL  - 98
SP  - 53
EP  - 62
PY  - 2019
DA  - 2019/09/01/
SN  - 1383-7621
DO  - https://doi.org/10.1016/j.sysarc.2019.06.008
UR  - https://www.sciencedirect.com/science/article/pii/S138376211830626X
KW  - GPGPU
KW  - OpenCL
KW  - Preemption
KW  - Software checkpointing
AB  - Heterogeneous computing has become popular in the past decade. Many frameworks have been proposed to provide a uniform way to program for accelerators, such as GPUs, DSPs, and FPGAs. Among them, an open and royalty-free standard, OpenCL, is widely adopted by the industry. However, many OpenCL-enabled accelerators and the standard itself do not support preemptive multitasking. To the best of our knowledge, previously proposed techniques are not portable or cannot handle ill-designed kernels (the codes that are executed on the accelerators), which will never ever finish. This paper presents a framework (called CLPKM) that provides an abstraction layer between OpenCL applications and the underlying OpenCL runtime to enable preemption of a kernel execution instance based on a software checkpointing mechanism. CLPKM includes (1) an OpenCL runtime library that intercepts OpenCL API calls, (2) a source-to-source compiler that performs the preemption-enabling transformation, and (3) a daemon that schedules OpenCL tasks using priority-based preemptive scheduling techniques. Experiments demonstrated that CLPKM reduced the slowdown of high-priority processes from 4.66x to 1.52–2.23x under up to 16 low-priority, heavy-workload processes running in the background and caused an average of 3.02–6.08x slowdown for low-priority processes.
ER  - 

TY  - JOUR
T1  - Machine learning methods to improve the operations of 3PL logistics
AU  - Tufano, Alessandro
AU  - Accorsi, Riccardo
AU  - Manzini, Riccardo
JO  - Procedia Manufacturing
VL  - 42
SP  - 62
EP  - 69
PY  - 2020
DA  - 2020/01/01/
T2  - International Conference on Industry 4.0 and Smart Manufacturing (ISM 2019)
SN  - 2351-9789
DO  - https://doi.org/10.1016/j.promfg.2020.02.023
UR  - https://www.sciencedirect.com/science/article/pii/S235197892030562X
KW  - Automotive
KW  - 3PL
KW  - machine learning
KW  - clustering
KW  - family grouping
KW  - logistics
AB  - Nowadays, the variety in the product mix, unpredictable customer demand and the need for a high level of service are crucial challenges in the management of a supply chain. Flexible processes are needed to gain competitive advantage and economic edges. This paper presents a data-driven application of unsupervised machine learning clustering algorithms to a real-world case study in the automotive industry. The clustering input dataset collects the data available to a third-party logistics (3PL) provider. Clustering algorithms are used to define product families for the assignment of the workload to the processing resources. Several clustering algorithms (k-means, Gaussian mixture models and hierarchical clustering) define different product families scenarios using different tuning parameters. The impact of each clustering scenario on the operations is assessed via a dashboard of logistics KPIs to identify the best performing clustering algorithm. The performance of each clustering is, then, compared to a logistic benchmark given by a capacitated clustering to identify the best compromise between a logistic-constrained algorithm with a long runtime and fast data-driven uncapacitated algorithm.
ER  - 

TY  - JOUR
T1  - An automated cluster surface scanning method for exploring reaction paths on metal-cluster surfaces
AU  - Tacey, Sean A.
AU  - Chen, Benjamin W.J.
AU  - Szilvási, Tibor
AU  - Mavrikakis, Manos
JO  - Computational Materials Science
VL  - 186
SP  - 110010
PY  - 2021
DA  - 2021/01/01/
SN  - 0927-0256
DO  - https://doi.org/10.1016/j.commatsci.2020.110010
UR  - https://www.sciencedirect.com/science/article/pii/S0927025620305012
KW  - Automated reaction path search
KW  - Density functional theory
KW  - Potential energy surface
KW  - Diffusion barriers
KW  - Activation energies
AB  - Metal-cluster surfaces present a wide variety of unique coordination environments. This complexity makes it difficult to manually probe the surface reactivity of such clusters. Here, we present a simple and automated method to systematically discover reaction pathways on cluster surfaces, based on the automated cluster surface scanning (ACSS) technique for mapping out potential energy surfaces. We showcase our method on 55-atom icosahedral Cu and Ag clusters, where we determine the activation energies of four elementary steps common in heterogeneous catalysis – hydrogen recombination (H* + H* → H2* + *), oxygen recombination (O* + O* → O2* + *), water formation (OH* + H* → H2O* + *), and CO oxidation (CO* + O* → CO2* + *) – with density functional theory calculations (DFT-PBE + D3). We show that the ACSS method requires significantly less human effort than the established manually performed climbing-image nudged elastic band (MP + CI-NEB) technique and locates transition states with comparable accuracy (root-mean-squared error of 0.10 eV) and similar computational cost. Rigorous sampling of the potential energy surface with the ACSS method allows one to locate all lowest-energy reaction pathways obtained via the MP+CI-NEB approach, as well as alternative pathways that one may have missed with the MP+CI-NEB approach due to the many possible pathways available on these clusters. The accuracy and efficiency afforded by the ACSS method could enable high-throughput exploration of the diverse reactivity of metal clusters.
ER  - 

TY  - JOUR
T1  - A generic learning simulation framework to assess security strategies in cyber-physical production systems
AU  - Koïta, Moussa
AU  - Diagana, Youssouf M.
AU  - Maïga, Oumar Y.
AU  - Traore, Mamadou K.
JO  - Computer Networks
VL  - 218
SP  - 109381
PY  - 2022
DA  - 2022/12/09/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2022.109381
UR  - https://www.sciencedirect.com/science/article/pii/S1389128622004157
KW  - Cyber-physical production system
KW  - Cybersecurity
KW  - Denial of service
KW  - Modeling and simulation
KW  - High-level language for systems specification (HiLLS)
KW  - Machine learning
KW  - Anylogic
AB  - Connected systems through computerized networks are at the heart of the Industry of the future. As they merge physical entities with cyber spaces, they fall under the paradigm of cyber-physical production systems. Cybersecurity is a key challenge for such systems, as they are subject to daily attempts of intruders to gain unauthorized access to their internal resources or to compromise their integrity. The fast increase of new attack strategies requires the rapid design and assessment of new defense strategies. It entails a complex, error-prone and time-consuming process, including the clear specification of the attack and defense strategies involved, and the design and implementation of the simulation model allowing to evaluate the performances of the defense strategy. This work intends to make such a process transparent to cybersecurity managers by limiting their workload to the sole specification of the characteristics of the system and the logic of the attack and the defense. It provides a generic hybrid simulation framework for flexible evaluation of cybersecurity policies, which is demonstrated on a SYN flooding application. Therefore, the contribution is twofold: (1) The proposed framework offers a high-level environment allowing various experts to collaborate by graphically modeling a given attack strategy and the envisioned defense strategy, without engaging in heavy implementation efforts. Then the framework's executable infrastructure, which combines simulation with machine learning to understanding the interactions between the attackers & the defender, will allow them assessing the performances of these strategies. The proposed framework differs from state-of-the-art cybersecurity simulation environments in its uniqueness to combining the expressive power of a universal simulation modeling formalism with the user-friendliness of a visual simulation tool. Therefore, it offers at one side, a very high modeling flexibility for easy exploration of various cybersecurity strategies, and at the other side, integrated learning capabilities for allowing self-adaptive user-based cybersecurity strategy design. (2) The application demonstrating the framework focuses on the most encountered and still uncontrolled threats in cybersecurity, i.e. the SYN-Flooding based Denial of Service (DoS) attack. The application targeted is not meant to propose yet another SYN flood detection algorithm or to improve the state-of-the-art in that domain, but to prove the framework operationality. The experimental results obtained showcase the ability of the framework to support learning simulation-based SYN flood defense algorithm design and validation.
ER  - 

TY  - JOUR
T1  - Multi-resolution cell orientation congruence descriptors for epithelium segmentation in endometrial histology images
AU  - Li, Guannan
AU  - Raza, Shan E Ahmed
AU  - Rajpoot, Nasir M.
JO  - Medical Image Analysis
VL  - 37
SP  - 91
EP  - 100
PY  - 2017
DA  - 2017/04/01/
SN  - 1361-8415
DO  - https://doi.org/10.1016/j.media.2017.01.006
UR  - https://www.sciencedirect.com/science/article/pii/S1361841517300154
KW  - Histology image analysis
KW  - Epithelium segmentation
KW  - Recurrent miscarriages
KW  - Digital pathology
AB  - It has been recently shown that recurrent miscarriage can be caused by abnormally high ratio of number of uterine natural killer (UNK) cells to the number of stromal cells in human female uterus lining. Due to high workload, the counting of UNK and stromal cells needs to be automated using computer algorithms. However, stromal cells are very similar in appearance to epithelial cells which must be excluded in the counting process. To exclude the epithelial cells from the counting process it is necessary to identify epithelial regions. There are two types of epithelial layers that can be encountered in the endometrium: luminal epithelium and glandular epithelium. To the best of our knowledge, there is no existing method that addresses the segmentation of both types of epithelium simultaneously in endometrial histology images. In this paper, we propose a multi-resolution Cell Orientation Congruence (COCo) descriptor which exploits the fact that neighbouring epithelial cells exhibit similarity in terms of their orientations. Our experimental results show that the proposed descriptors yield accurate results in simultaneously segmenting both luminal and glandular epithelium.
ER  - 

TY  - JOUR
T1  - Joint optimization of social interactivity and server provisioning for interactive games in edge computing
AU  - Tsipis, Athanasios
AU  - Oikonomou, Konstantinos
JO  - Computer Networks
VL  - 212
SP  - 109028
PY  - 2022
DA  - 2022/07/20/
SN  - 1389-1286
DO  - https://doi.org/10.1016/j.comnet.2022.109028
UR  - https://www.sciencedirect.com/science/article/pii/S1389128622001840
KW  - Cost optimization
KW  - Facility location
KW  - Mobile edge computing
KW  - Player assignment
KW  - Server provisioning
KW  - Social interactivity
AB  - Distributed interactive applications (DIAs), like immersive virtual reality and multiplayer cloud games, where players team-up and form social communities to participate in collaborative virtual events, dominate the modern cloud multimedia industry. Still, due to the massive workload, intensive graphics processing and delay intolerance, conventional cloud-only models are increasingly becoming ineffective. Thankfully, with the shift towards Mobile Edge Computing, game providers can leverage existing cellular infrastructure to deploy edge servers that supply gaming services in a highly accessible fashion. One fundamental challenge, that naturally arises, is the discovery of the most suitable player-to-edge server assignment strategy, that achieves a balanced trade-off between conflicting objectives that refer to high social interactivity on the one hand and low-cost server provisioning on the other. In this article, the core properties of social interactivity for gaming DIAs are investigated through formal formulation under diverse social aspects and strict assignment rules, respecting, in the meantime, the provisioning cost and constraints of the edge servers. We call this the “Social Interactivity-oriented Edge Allocation” (SIEA) problem and prove its NP-hardness. Based on our theoretical analysis, we present SIEA-H, a two-phase heuristic algorithm to efficiently assign players to servers and then iteratively refine the edge allocation strategy. SIEA-H is evaluated using comprehensive trace-driven simulations. The results demonstrate how it surpasses the baseline and state-of-the-art assignment alternatives in reducing the total cost, especially as the number of servers and their capacity grows, or the coverage area expands, while for players it exhibits the highest admission rate and the best overall resource management.
ER  - 

TY  - JOUR
T1  - Industrial-size job shop scheduling with constraint programming
AU  - Da Col, Giacomo
AU  - Teppan, Erich C.
JO  - Operations Research Perspectives
VL  - 9
SP  - 100249
PY  - 2022
DA  - 2022/01/01/
SN  - 2214-7160
DO  - https://doi.org/10.1016/j.orp.2022.100249
UR  - https://www.sciencedirect.com/science/article/pii/S2214716022000215
KW  - Large scale optimization
KW  - Job shop scheduling problem
KW  - Constraint programming
KW  - CP Optimizer
KW  - OR-Tools
AB  - The job shop scheduling problem is one of the most studied optimization problems to this day and it becomes more and more important in the light of the fourth industrial revolution (Industry 4.0) that aims at fully automated production processes. For a long time exact methods like constraint programming had problems to solve real large-scale problem instances and methods of choice were to be found in the area of (meta-) heuristics. However, developments during the last decade improved the performance of state-of-the-art constraint solvers dramatically, to the point that they can be applied also on large-scale instances. The presented work’s main target is to elaborate the performance of state-of-the-art constraint solvers with respect to industrial-size job shop scheduling problem instances. To this end, we analyze and compare the performance of two cutting-edge constraint solvers: OR-Tools, an open-source solver developed by Google and recurrent winner of the MiniZinc Challenge, and CP Optimizer, a proprietary constraint solver from IBM targeted at industrial optimization problems. In order to reflect real-world industrial scenarios with heavy workloads like found in the semi-conductor domain, we use novel benchmarks that comprise up to one million operations to be scheduled on up to one thousand machines. The comparison is based on the best makespan (i.e. completion time) achieved and the time required to solve the problem instances. We test the solvers on single-core and quad-core configurations.
ER  - 

TY  - JOUR
T1  - Residential building facade segmentation in the urban environment
AU  - Dai, Menglin
AU  - Ward, Wil O.C.
AU  - Meyers, Gregory
AU  - Densley Tingley, Danielle
AU  - Mayfield, Martin
JO  - Building and Environment
VL  - 199
SP  - 107921
PY  - 2021
DA  - 2021/07/15/
SN  - 0360-1323
DO  - https://doi.org/10.1016/j.buildenv.2021.107921
UR  - https://www.sciencedirect.com/science/article/pii/S0360132321003243
KW  - Building retrofit
KW  - Building facade
KW  - Deep learning
KW  - Environmental modelling
AB  - Building retrofit is an important facet in the drive to reduce global greenhouse gas emissions. However, delivering building retrofit at scale is a significant challenge, especially in how to automate the process of building surveying. On-site survey by expert surveyors is the main approach in the industry. This can lead to a high workload if planning retrofit at a large-scale. An advanced vehicle-mounted data capturing system has been built to collect urban environmental multi-spectral data. The data contains substantial information that is essential in identifying building retrofit needs. Although the data capturing system is able to collect data in a highly-efficient manner, the data analysis is still a big data challenge to apply the system into delivering building retrofit plans. In this paper, a street-view building facade image segmentation model is designed as the foundation of the holistic data analysis framework. The model is developed on the deep learning-based semantic segmentation technology and uses an ensemble learning strategy. The object detection technology is fused into the model as an magnifier to improve the model performance on small objects and boundary predictions. The model has achieved state-of-the-art levels of accuracy on a built street-view building facade image dataset.
ER  - 

TY  - JOUR
T1  - Decision support from local data: Creating adaptive order menus from past clinician behavior
AU  - Klann, Jeffrey G.
AU  - Szolovits, Peter
AU  - Downs, Stephen M.
AU  - Schadow, Gunther
JO  - Journal of Biomedical Informatics
VL  - 48
SP  - 84
EP  - 93
PY  - 2014
DA  - 2014/04/01/
SN  - 1532-0464
DO  - https://doi.org/10.1016/j.jbi.2013.12.005
UR  - https://www.sciencedirect.com/science/article/pii/S1532046413001962
KW  - Clinical Decision Support
KW  - Data mining
KW  - Bayesian analysis
AB  - Objective
Reducing care variability through guidelines has significantly benefited patients. Nonetheless, guideline-based Clinical Decision Support (CDS) systems are not widely implemented or used, are frequently out-of-date, and cannot address complex care for which guidelines do not exist. Here, we develop and evaluate a complementary approach – using Bayesian Network (BN) learning to generate adaptive, context-specific treatment menus based on local order-entry data. These menus can be used as a draft for expert review, in order to minimize development time for local decision support content. This is in keeping with the vision outlined in the US Health Information Technology Strategic Plan, which describes a healthcare system that learns from itself.
Materials and methods
We used the Greedy Equivalence Search algorithm to learn four 50-node domain-specific BNs from 11,344 encounters: abdominal pain in the emergency department, inpatient pregnancy, hypertension in the Urgent Visit Clinic, and altered mental state in the intensive care unit. We developed a system to produce situation-specific, rank-ordered treatment menus from these networks. We evaluated this system with a hospital-simulation methodology and computed Area Under the Receiver–Operator Curve (AUC) and average menu position at time of selection. We also compared this system with a similar association-rule-mining approach.
Results
A short order menu on average contained the next order (weighted average length 3.91–5.83 items). Overall predictive ability was good: average AUC above 0.9 for 25% of order types and overall average AUC .714–.844 (depending on domain). However, AUC had high variance (.50–.99). Higher AUC correlated with tighter clusters and more connections in the graphs, indicating importance of appropriate contextual data. Comparison with an Association Rule Mining approach showed similar performance for only the most common orders with dramatic divergence as orders are less frequent.
Discussion and conclusion
This study demonstrates that local clinical knowledge can be extracted from treatment data for decision support. This approach is appealing because: it reflects local standards; it uses data already being captured; and it produces human-readable treatment-diagnosis networks that could be curated by a human expert to reduce workload in developing localized CDS content. The BN methodology captured transitive associations and co-varying relationships, which existing approaches do not. It also performs better as orders become less frequent and require more context. This system is a step forward in harnessing local, empirical data to enhance decision support.
ER  - 

TY  - JOUR
T1  - An empirical comparison of relocation strategies in real-time ambulance fleet management
AU  - Bélanger, V.
AU  - Kergosien, Y.
AU  - Ruiz, A.
AU  - Soriano, P.
JO  - Computers & Industrial Engineering
VL  - 94
SP  - 216
EP  - 229
PY  - 2016
DA  - 2016/04/01/
SN  - 0360-8352
DO  - https://doi.org/10.1016/j.cie.2016.01.023
UR  - https://www.sciencedirect.com/science/article/pii/S036083521630016X
KW  - Emergency medical services
KW  - Location
KW  - Simulation
KW  - Fleet management strategies
AB  - In order to ensure an adequate service to the population, Emergency Medical Services (EMS) rely on a given number of ambulances strategically located over the territory they serve. The arrival of calls to EMS being highly uncertain and dynamic, it may happen that at some point, the vehicles available to respond to these calls no longer cover properly all regions, even if the coverage was carefully planned initially. Relocation of ambulances may therefore be required during the day in order to achieve better performances. Some models tackling relocation have been proposed in the literature and it has been shown that using such strategies can help to improve overall performances. However, relocation generates movements that produce undesirable consequences from both economical and human resources management standpoints. Questions therefore arise: Is the relocation worth the effort? And if so, what form should it take? Unfortunately, this issue has not been investigated much up to now. This study thus focuses on evaluating and analyzing relocation strategies, and reports extensive simulation experiments allowing to analyze the performance of these strategies when the system faces different levels of workload. Our empirical study confirms that dynamic strategies dominate static ones and quantifies the improvements achieved with respect to service level, but also shows that such improvements are obtained at the expense of significant relocation costs.
ER  - 

TY  - JOUR
T1  - Developing base domain ontology from a reference collection to aid information retrieval
AU  - Chi, Nai-Wen
AU  - Jin, Yu-Huei
AU  - Hsieh, Shang-Hsien
JO  - Automation in Construction
VL  - 100
SP  - 180
EP  - 189
PY  - 2019
DA  - 2019/04/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2019.01.001
UR  - https://www.sciencedirect.com/science/article/pii/S0926580517310713
KW  - Ontology
KW  - Information retrieval
KW  - Earthquake engineering
AB  - Information Retrieval (IR) is a common technique used to manage a growing technical document collection. Owing to the complexity of technical documents, the direct application of IR often leads to unsatisfactory results. Therefore, many semantic approaches, such as ontology, are applied to enhance IR performance. However, ontology development is often a labor-intensive process and the availability of ontologies significantly influences the applicability of IR. Consequently, many efforts are dedicated to the automation of the ontology development process for reducing the human labors. In addition, reference collections, which are developed as the golden standards to evaluate IR performance in many IR research, can be regarded as an available resource for ontology development. To ease domain ontology development for supporting IR, this research proposes a semi-automated approach to develop a base domain ontology from a reference collection. This research also validates the base ontology on an Earthquake Engineering reference collection, called the NCREE (National Center for Research on Earthquake Engineering) collection. The results reveal that the human workload of the proposed approach is affordable. Furthermore, the base domain ontology can help achieve a satisfactory IR performance.
ER  - 

TY  - JOUR
T1  - HRI usability evaluation of interaction modes for a teleoperated agricultural robotic sprayer
AU  - Adamides, George
AU  - Katsanos, Christos
AU  - Parmet, Yisrael
AU  - Christou, Georgios
AU  - Xenos, Michalis
AU  - Hadzilacos, Thanasis
AU  - Edan, Yael
JO  - Applied Ergonomics
VL  - 62
SP  - 237
EP  - 246
PY  - 2017
DA  - 2017/07/01/
SN  - 0003-6870
DO  - https://doi.org/10.1016/j.apergo.2017.03.008
UR  - https://www.sciencedirect.com/science/article/pii/S0003687017300674
KW  - Human-robot interaction
KW  - Usability
KW  - Agricultural robot
KW  - Teleoperation
AB  - Teleoperation of an agricultural robotic system requires effective and efficient human-robot interaction. This paper investigates the usability of different interaction modes for agricultural robot teleoperation. Specifically, we examined the overall influence of two types of output devices (PC screen, head mounted display), two types of peripheral vision support mechanisms (single view, multiple views), and two types of control input devices (PC keyboard, PS3 gamepad) on observed and perceived usability of a teleoperated agricultural sprayer. A modular user interface for teleoperating an agricultural robot sprayer was constructed and field-tested. Evaluation included eight interaction modes: the different combinations of the 3 factors. Thirty representative participants used each interaction mode to navigate the robot along a vineyard and spray grape clusters based on a 2 × 2 × 2 repeated measures experimental design. Objective metrics of the effectiveness and efficiency of the human-robot collaboration were collected. Participants also completed questionnaires related to their user experience with the system in each interaction mode. Results show that the most important factor for human-robot interface usability is the number and placement of views. The type of robot control input device was also a significant factor in certain dependents, whereas the effect of the screen output type was only significant on the participants’ perceived workload index. Specific recommendations for mobile field robot teleoperation to improve HRI awareness for the agricultural spraying task are presented.
ER  - 

TY  - JOUR
T1  - “It's a Frightful Scenario”: A Study of Tram Collisions on a Mixed-traffic Environment in an Australian Metropolitan Setting
AU  - Naweed, Anjum
AU  - Rose, Janette
JO  - Procedia Manufacturing
VL  - 3
SP  - 2706
EP  - 2713
PY  - 2015
DA  - 2015/01/01/
T2  - 6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015
SN  - 2351-9789
DO  - https://doi.org/10.1016/j.promfg.2015.07.666
UR  - https://www.sciencedirect.com/science/article/pii/S2351978915006678
KW  - Trams
KW  - Safety
KW  - Accident analysis
KW  - Situation awareness
AB  - Tram driving is a complex task, requiring high levels of workload, route knowledge, and divided attention. Although similar to train driving, tram driving has its own unique skills requirements as well as higher demands on divided attention and decision-making in relation to operating in an environment with multiple road users. Due to the significant differences between the two tasks, research findings relating to train driving may not necessarily be applicable to tram driving. Despite this, very little research has been conducted on the tram-driving task in general and even less so relating to accidents and near misses. Australia has experienced a high incidence of tram collisions over the past decade and with new networks being planned for several cities and expansion of existing networks there is a potential for an increase in accidents. It is therefore timely to examine the tram-driving task and consider the human factors implications of tram collisions. This study incorporated reviews of accident reports, on-site observations, focus group exercises, and individual driver discussions. Results of the analysis revealed three major themes relating to causes of accidents: situation awareness, time pressure, and organizational behaviour. Interaction between these three themes was noted. This preliminary identified cultural issues and hinted at problems associated with normalization of deviance. Further analysis and research is needed to explore and unpack the themes with a view to determining effective strategies for tram organisations to implement to improve safety and minimize the risk of collisions.
ER  - 

TY  - JOUR
T1  - Simultaneous monitoring of physical and mental stress for construction tasks using physiological measures
AU  - Umer, Waleed
JO  - Journal of Building Engineering
VL  - 46
SP  - 103777
PY  - 2022
DA  - 2022/04/01/
SN  - 2352-7102
DO  - https://doi.org/10.1016/j.jobe.2021.103777
UR  - https://www.sciencedirect.com/science/article/pii/S2352710221016351
KW  - Construction safety
KW  - Physical stress
KW  - Mental stress
KW  - Safety monitoring
KW  - Machine learning
AB  - Construction workers are prone to physical and mental stress because of the characteristics of the construction industry. Researchers and practitioners agree that physical and mental stress should be proactively managed to mitigate their ill-effects which range from making errors to causing accidents and short term to long term illnesses. Accordingly, numerous research endeavors have pursued automated solutions for their monitoring to replace manual and subjective physical and mental stress monitoring. While these studies have been successful, they attempted to monitor either physical stress or mental stress at a time. Studies have shown that many times, construction workers are simultaneously exposed to both, physical and mental stress, necessitating automated simultaneous monitoring of physical and mental stress for more comprehensive workload evaluation. Therefore, the aim of the current study is to assess the possibility of accurately monitoring physical and mental stress simultaneously using physiological measures and machine learning algorithms. For the purpose, experiments were conducted that comprised of physical and mental stress scenarios. The results showed that using 56 features derived from heart rate, skin temperature, breathing rate and skin conductance, an accuracy of 94.7% was achieved for simultaneous physical and mental stress monitoring. Additionally, the study further investigated the impact of varying the features and physiological measures and discussed the potential future work in this direction. Overall, this study for the first time, demonstrated that it is possible to simultaneously monitor physical and mental stress with high accuracy. Moreover, it has laid the foundation for future studies to enable simultaneous physical and mental stress monitoring on actual job sites.
ER  - 

TY  - JOUR
T1  - Enhancing dual-task performance with verbal and spatial working memory training: Continuous monitoring of cerebral hemodynamics with NIRS
AU  - McKendrick, Ryan
AU  - Ayaz, Hasan
AU  - Olmstead, Ryan
AU  - Parasuraman, Raja
JO  - NeuroImage
VL  - 85
SP  - 1014
EP  - 1026
PY  - 2014
DA  - 2014/01/15/
T2  - Neuro-enhancement
SN  - 1053-8119
DO  - https://doi.org/10.1016/j.neuroimage.2013.05.103
UR  - https://www.sciencedirect.com/science/article/pii/S1053811913006058
KW  - Working memory training
KW  - Near infrared spectroscopy
KW  - Dorsolateral prefrontal cortex
KW  - Ventrolateral prefrontal cortex
KW  - Hemodynamics
AB  - To better understand the mechanisms by which working memory training can augment human performance we continuously monitored trainees with near infrared spectroscopy (NIRS) while they performed a dual verbal–spatial working memory task. Linear mixed effects models were used to model the changes in cerebral hemodynamic response as a result of time spent training working memory. Nonlinear increases in left dorsolateral prefrontal cortex (DLPFC) and right ventrolateral prefrontal cortex (VLPFC) were observed with increased exposure to working memory training. Adaptive and yoked training groups also showed differential effects in rostral prefrontal cortex with increased exposure to working memory training. There was also a significant negative relationship between verbal working memory performance and bilateral VLPFC activation. These results are interpreted in terms of decreased proactive interference, increased neural efficiency, reduced mental workload for stimulus processing, and increased working memory capacity with training.
ER  - 

TY  - JOUR
T1  - A Novel Kernel-based Extreme Learning Machine with Incremental Hidden Layer Nodes
AU  - Min, Mengcan
AU  - Chen, Xiaofang
AU  - Lei, Yongxiang
AU  - Chen, Zhiwen
AU  - Xie, Yongfang
JO  - IFAC-PapersOnLine
VL  - 53
IS  - 2
SP  - 11836
EP  - 11841
PY  - 2020
DA  - 2020/01/01/
T2  - 21st IFAC World Congress
SN  - 2405-8963
DO  - https://doi.org/10.1016/j.ifacol.2020.12.695
UR  - https://www.sciencedirect.com/science/article/pii/S2405896320310089
KW  - ELM
KW  - I-ELM
KW  - Kernel function
KW  - SD classification
AB  - Extreme learning machine (ELM) is widely used in various fields because of its advantages such as short training time and good generalization performance. The input weights and bias of hidden layer of traditional ELM are generated randomly, and the number of hidden layer nodes is determined by artificial experience. Only by adjusting parameters manually can an appropriate network structure be found. This training method is complex and time-consuming, which increases the workload of workers. To solve this problem, the incremental extreme learning machine (I-ELM) is used to determine the appropriate number of hidden layer nodes and construct a compact network structure in this paper. At the same time, a new hidden layer activation function STR is proposed, which avoids the disadvantages of incomplete output information of hidden layer due to uneven distribution of sample data. The proposed algorithm is evaluated by public data sets and applied to the classification of superheat degree (SD) in aluminum electrolysis industry. The experimental results show that STR activation function has a good learning speed, and the proposed algorithm is superior to the existing SD identification algorithm in terms of accuracy and robustness.
ER  - 

TY  - JOUR
T1  - Second order conic approximation for disassembly line design with joint probabilistic constraints
AU  - Bentaha, Mohand Lounes
AU  - Battaïa, Olga
AU  - Dolgui, Alexandre
AU  - Hu, S. Jack
JO  - European Journal of Operational Research
VL  - 247
IS  - 3
SP  - 957
EP  - 967
PY  - 2015
DA  - 2015/12/16/
SN  - 0377-2217
DO  - https://doi.org/10.1016/j.ejor.2015.06.019
UR  - https://www.sciencedirect.com/science/article/pii/S0377221715005330
KW  - Assembly and disassembly
KW  - Line design and balancing
KW  - Stochastic programming
KW  - Joint probabilistic constraints
KW  - Piecewise linear approximation
AB  - A problem of profit oriented disassembly line design and balancing with possible partial disassembly and presence of hazardous parts is studied. The objective is to design a production line providing a maximal revenue with balanced workload. Task times are assumed to be random variables with known normal probability distributions. The cycle time constraints are to be jointly satisfied with at least a predetermined probability level. An AND/OR graph is used to model the precedence relationships among tasks. Several lower and upper–bounding schemes are developed using second order cone programming and convex piecewise linear approximation. To show the relevance and applicability of the proposed approach, a set of instances from the literature are solved to optimality.
ER  - 

TY  - JOUR
T1  - MhURI:A Supervised Segmentation Approach to Leverage Salient Brain Tissues in Magnetic Resonance Images
AU  - Ghosal, Palash
AU  - Chowdhury, Tamal
AU  - Kumar, Amish
AU  - Bhadra, Ashok Kumar
AU  - Chakraborty, Jayasree
AU  - Nandi, Debashis
JO  - Computer Methods and Programs in Biomedicine
VL  - 200
SP  - 105841
PY  - 2021
DA  - 2021/03/01/
SN  - 0169-2607
DO  - https://doi.org/10.1016/j.cmpb.2020.105841
UR  - https://www.sciencedirect.com/science/article/pii/S0169260720316746
KW  - Brain
KW  - Convolutional Neural Network
KW  - Inception module
KW  - MRI
KW  - Morphological gradient
KW  - Segmentation
AB  - Background and objectives: Accurate segmentation of critical tissues from a brain MRI is pivotal for characterization and quantitative pattern analysis of the human brain and thereby, identifies the earliest signs of various neurodegenerative diseases. To date, in most cases, it is done manually by the radiologists. The overwhelming workload in some of the thickly populated nations may cause exhaustion leading to interruption for the doctors, which may pose a continuing threat to patient safety. A novel fusion method called U-Net inception based on 3D convolutions and transition layers is proposed to address this issue. Methods: A 3D deep learning method called Multi headed U-Net with Residual Inception (MhURI) accompanied by Morphological Gradient channel for brain tissue segmentation is proposed, which incorporates Residual Inception 2-Residual (RI2R) module as the basic building block. The model exploits the benefits of morphological pre-processing for structural enhancement of MR images. A multi-path data encoding pipeline is introduced on top of the U-Net backbone, which encapsulates initial global features and captures the information from each MRI modality. Results: The proposed model has accomplished encouraging outcomes, which appreciates the adequacy in terms of some of the established quality metrices when compared with some of the state-of-the-art methods while evaluating with respect to two popular publicly available data sets. Conclusion: The model is entirely automatic and able to segment gray matter (GM), white matter (WM), and cerebrospinal fluid (CSF) from brain MRI effectively with sufficient accuracy. Hence, it may be considered to be a potential computer-aided diagnostic (CAD) tool for radiologists and other medical practitioners in their clinical diagnosis workflow.
ER  - 

TY  - JOUR
T1  - Sensory discrimination by consumers of multiple stimuli from a reference: Stimulus configuration in A-Not AR and constant-ref. duo-trio superior to triangle and unspecified tetrad?
AU  - Jeong, Yu-Na
AU  - Kang, Bi-A
AU  - Jeong, Min-Ju
AU  - Song, Min-Jeong
AU  - Hautus, Michael J.
AU  - Lee, Hye-Seong
JO  - Food Quality and Preference
VL  - 47
SP  - 10
EP  - 22
PY  - 2016
DA  - 2016/01/01/
T2  - Sensometric 2014: Data That Works In The City That Works
SN  - 0950-3293
DO  - https://doi.org/10.1016/j.foodqual.2015.06.021
UR  - https://www.sciencedirect.com/science/article/pii/S0950329315001627
KW  - Consumer discrimination test
KW  - Reminder design
KW  - Constant-reference duo-trio
KW  - A-Not AR
KW  - 2-AFCR
KW  - Triangle
KW  - Unspecified tetrad
KW  - Cognitive load
AB  - In the food industry, overall discrimination tests are used with untrained/naïve consumer subjects to compare multiple test stimuli against a fixed reference, such as a company’s gold standard or a stimulus familiar to the consumer. Such tests are used for various objectives, including reformulation and cost reduction. Yet, studies on relative discrimination power and efficiency have been limited to experimental designs with a fixed pair of stimuli and method comparisons based on the same numbers of tests. In the present study, two reminder methods, A-Not A with Reminder (A-Not AR) and 2-AFC with Reminder (2-AFCR), were investigated as potentially better methods for experimental designs including comparisons of multiple pairs of stimuli for consumer discrimination. 2-AFCR is procedurally equivalent to a constant-reference duo-trio test with the reference presented first (DTF) and thus this test is referred to as the constant-ref. DTF/2-AFCR test in this paper. The practical efficiency of these two reminder methods, attributed to their effective stimulus configurations in replicated tests (i.e. using a fixed reference and lower number of different stimuli required in a test), was tested in comparison with the two most commonly used balanced reference classification methods, the triangle test and the unspecified tetrad test, by equalizing the number of stimuli required for the different methods. Namely the relative operational discrimination power was studied based on the same number of stimuli rather than the same number of tests. 180 naïve consumers performed a set of 12 replicated triangle tests and, based on the results, were divided into one of three equally-performing groups. A related-samples design was implemented for comparison between the triangle and the other three methods. An independent-samples design was implemented across the three groups to compare the A-Not AR, constant-ref. DTF/2-AFCR, and unspecified tetrad methods. Statistical ratio comparisons of d′ estimates obtained from different methods revealed that discrimination performance in the reminder methods was better than in both the tetrad and triangle methods. No discrimination difference was found between the triangle and tetrad tests having all possible test sequences, although the triangle test considering only the optimal test sequences, which were the same as those in the constant-ref. DTF/2-AFCR, resulted in superior discrimination than the tetrad test. Collectively, these results suggest that when assessing the discriminability of multiple stimuli from a fixed reference, the reminder scheme is the superior research design.
ER  - 

TY  - JOUR
T1  - Multi-output efficiency and operational safety: An analysis of railway traffic control centre performance
AU  - Roets, Bart
AU  - Verschelde, Marijn
AU  - Christiaens, Johan
JO  - European Journal of Operational Research
VL  - 271
IS  - 1
SP  - 224
EP  - 237
PY  - 2018
DA  - 2018/11/16/
SN  - 0377-2217
DO  - https://doi.org/10.1016/j.ejor.2018.04.045
UR  - https://www.sciencedirect.com/science/article/pii/S0377221718303722
KW  - Data Envelopment Analysis
KW  - Output-specific metafrontier
KW  - Operational safety
KW  - Input–output allocations
KW  - Railways
AB  - Transportation service providers are under increasing pressure to raise cost efficiency without sacrificing safety. We show the usefulness of a nonparametric multi-output framework to both monitor staff efficiency and detect operational safety concerns. To realistically model input–output relations at an hourly rate of Belgian computerized railway traffic control centres, we apply a Data Envelopment Analysis (DEA)-based framework with proportional cost allocation restrictions and introduce output-specific metafrontiers. Our analysis (covering each single hour of the complete year 2015) shows that production tasks with a highly variable work load, when characterized by binding cost allocation restrictions and high within-traffic-control-centre efficiency, are more prone to human error. Further, we show how DEA combined with disaggregated data can be used to a priori assess staff schedule changes.
ER  - 

TY  - JOUR
T1  - Automatic epileptic EEG classification based on differential entropy and attention model
AU  - Zhang, Jian
AU  - Wei, Zuochen
AU  - Zou, Junzhong
AU  - Fu, Hao
JO  - Engineering Applications of Artificial Intelligence
VL  - 96
SP  - 103975
PY  - 2020
DA  - 2020/11/01/
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2020.103975
UR  - https://www.sciencedirect.com/science/article/pii/S0952197620302815
KW  - Electroencephalography
KW  - Epilepsy
KW  - Differential entropy
KW  - Attention mechanism
AB  - In epilepsy electroencephalogram (EEG) analysis, clinicians usually interpret EEG page by page, which is time-consuming and brings heavy workload. This paper proposes a novel automatic epileptic EEG classification approach based on differential entropy and attention mechanism, aiming at designing a short-term epileptic EEG classification model with high accuracy and good generalization performance. Firstly, the original EEG recordings are decomposed into five sub-frequency bands which approximately obey the Gaussian distribution. Afterward, a improved attention model framework considering both row and column attention with a shallower VGGNet (AttVGGNet-RC) is put forward as the classifier. Finally, non-patient specific method is employed to evaluate the performance with pre-tuned hypermeters. With 8-fold data, the proposed model yielded 77.33 ± 2.91% sensitivity, 86.67 ± 3.70% specificity and 82.00 ± 1.43% accuracy, and accuracy was increased by 5.34%, 8.99%, 26.24% and 4.47% respectively compared with multi-layer perceptron (MLP), extreme learning machine (ELM), support vector machine (SVM) and Long Short-Term Memory (LSTM). With 10-fold shuffled data, the improved attention model yielded 93.84 ± 0.63% sensitivity, 95.84 ± 0.74% specificity and 95.12 ± 0.20% accuracy, and the accuracy was 1.34%, 16.29%, 27.12% and 8.24% higher than MLP, ELM, SVM and LSTM respectively. The experimental result showed that the attention model achieved high classification accuracy with low standard deviation as well as good generalization performance. Furthermore, compared with state-of-art epilepsy analysis system, the proposed approach also show better performance. Therefore, this study has significant clinical application value in epilepsy analysis.
ER  - 

TY  - JOUR
T1  - A Decision Support System for predictive police patrolling
AU  - Camacho-Collados, M.
AU  - Liberatore, F.
JO  - Decision Support Systems
VL  - 75
SP  - 25
EP  - 37
PY  - 2015
DA  - 2015/07/01/
SN  - 0167-9236
DO  - https://doi.org/10.1016/j.dss.2015.04.012
UR  - https://www.sciencedirect.com/science/article/pii/S0167923615000834
KW  - Predictive policing
KW  - Time series forecasting
KW  - Police Districting Problem
KW  - Multi-criteria decision-making
KW  - Decision Support Systems
AB  - In the current economic climate, many police agencies have reduced resources, especially personnel, with a consequential increase in workload and deterioration in public safety. A Decision Support System (DSS) can help to optimize effective use of the scarce human resources available. In this paper we present a DSS that merges predictive policing capabilities with a patrolling districting model, for the design of predictive patrolling areas. The proposed DSS, developed in close collaboration with the Spanish National Police Corps (SNPC), defines partitions of the territory under the jurisdiction of a district that are efficient and balanced at the same time, according to the preferences of a decision maker. To analyze the crime records provided by the SNPC, a methodology for the description of spatially and temporally indeterminate crime events has been developed. The DSS has been tested with a case study in the Central District of Madrid. The results of the experiments show that the proposed DSS clearly outperforms the patrolling area definitions currently in use by the SNPC. To compare the solutions in terms of efficiency loss, we discuss how to build an operational envelope for the problem considered, which can be used to identify the range of performances associated with different patrolling strategies.
ER  - 

TY  - JOUR
T1  - Active Disturbance Rejection Control for Selecting and Shifting Motor of Automated Mechanical Transmission
AU  - Zhang, Guohui
AU  - Xie, Hui
AU  - Chen, Tao
AU  - Ruan, Diwang
AU  - Zhang, Ruichang
AU  - Tong, Qiang
JO  - IFAC-PapersOnLine
VL  - 51
IS  - 31
SP  - 759
EP  - 764
PY  - 2018
DA  - 2018/01/01/
T2  - 5th IFAC Conference on Engine and Powertrain Control, Simulation and Modeling E-COSM 2018
SN  - 2405-8963
DO  - https://doi.org/10.1016/j.ifacol.2018.10.134
UR  - https://www.sciencedirect.com/science/article/pii/S2405896318325989
KW  - automated mechanical transmission
KW  - shifting motor
KW  - extended state observer
KW  - active disturbance rejection control
AB  - The control strategy of shifting actuators is the most crucial part in the development of automated mechanical transmission (AMT) system. To solve problems such as large workload of parameters tuning and worse disturbance-rejecting ability under traditional PID for selecting and shifting gear in present industry, a new strategy based on active disturbance rejection control (ADRC) was proposed. The extended state observer (ESO) was used to observe and compensate total disturbances in real time to achieve precise closed-loop control for shifting motor position. The Hardware-In-the-Loop (HIL) experiments show that the speed of selecting actuator moving to target position under ADRC is 14.3% faster than that of PID, and the position deviation of selecting actuator is 0.9mm under ADRC with an external disturbance of 1N·m added, which is 59.1% less than that under PID. And the target gear tracking test indicates that the total shifting time under ADRC can be reduced by 2.37% to 5.08% compared with PID. This strategy has better control accuracy and robustness under load mutation condition compared to traditional PID.
ER  - 

TY  - JOUR
T1  - Every apprentice needs a master: Feedback-based effectiveness improvements for process model matching
AU  - Klinkmüller, Christopher
AU  - Weber, Ingo
JO  - Information Systems
VL  - 95
SP  - 101612
PY  - 2021
DA  - 2021/01/01/
SN  - 0306-4379
DO  - https://doi.org/10.1016/j.is.2020.101612
UR  - https://www.sciencedirect.com/science/article/pii/S0306437920300892
KW  - Process model matching
KW  - Process model collection management
KW  - Mixed-initiative systems
KW  - BPM
AB  - Process models are a central element of modern business process management technology. When adopting such technology, organizations inevitably establish process model collections which, depending on the degree of adoption, can reach sizes of thousands of models. Process model matching techniques are intended to assist experts in the management of such large collections, e.g., in querying the collections and in comparing process models. Yet, as demonstrated in comparative evaluations, existing techniques struggle to achieve a high effectiveness on real-world datasets, limiting their practical applicability. This is partly due to these techniques being fully automated and relying on universal knowledge bases that insufficiently represent the domain semantics of model collections. To increase effectiveness and to progress on the path to practical applicability, we pursue the idea of integrating expert feedback into the matching process, so as to continuously update the knowledge base and achieve a better domain adaptation. In particular, we present ADBOT, a matching technique that relies on expert feedback in terms of corrected matching results. Our contributions are twofold. First, we introduce different strategies to utilize expert feedback in the matching process and to improve its effectiveness. Second, we provide heuristics for guiding experts through a model collection intended to reduce the amount of collected feedback while still maximizing the gains of learning from it. Based on five separate real-world datasets we provide empirical evidence towards the feasibility of our matcher. In the experiments, ADBOT (i) achieves high f-measures of up to .90, (ii) improves the effectiveness of baseline matchers by up to 88%, (iii) yields high recall values due to the detection of correspondences that automated matchers fail to achieve, and (iv) still increases effectiveness when the feedback contains errors. We also discuss evidence that substantiates ADBOT’s individual components, amongst others demonstrating that the guidance heuristics can maximize effectiveness, while minimizing human effort.
ER  - 

TY  - JOUR
T1  - Attribute annotation on large-scale image database by active knowledge transfer
AU  - Jiang, Huajie
AU  - Wang, Ruiping
AU  - Li, Yan
AU  - Liu, Haomiao
AU  - Shan, Shiguang
AU  - Chen, Xilin
JO  - Image and Vision Computing
VL  - 78
SP  - 1
EP  - 13
PY  - 2018
DA  - 2018/10/01/
SN  - 0262-8856
DO  - https://doi.org/10.1016/j.imavis.2018.06.012
UR  - https://www.sciencedirect.com/science/article/pii/S0262885618301173
KW  - Attribute
KW  - Annotation
KW  - Relationship
KW  - Active learning
KW  - Transfer learning
AB  - Attributes are widely used in different vision tasks. However, existing attribute resources are quite limited and most of them are not in large scale. Current attribute annotation process is generally done by human, which is expensive and time-consuming. In this paper, we propose a novel framework to perform effective attribute annotations. Based on the common knowledge that attributes can be shared among different classes, we leverage the benefits of transfer learning and active learning together to transfer knowledge from some existing small attribute databases to large-scale target databases. In order to learn more robust attribute models, attribute relationships are incorporated to assist the learning process. Using the proposed framework, we conduct extensive experiments on two large-scale image databases, i.e. ImageNet and SUN Attribute, where high quality automatic attribute annotations are obtained.
ER  - 

TY  - JOUR
T1  - Human Performance Factors in Cyber Security Forensic Analysis
AU  - McClain, Jonathan
AU  - Silva, Austin
AU  - Emmanuel, Glory
AU  - Anderson, Benjamin
AU  - Nauer, Kevin
AU  - Abbott, Robert
AU  - Forsythe, Chris
JO  - Procedia Manufacturing
VL  - 3
SP  - 5301
EP  - 5307
PY  - 2015
DA  - 2015/01/01/
T2  - 6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015
SN  - 2351-9789
DO  - https://doi.org/10.1016/j.promfg.2015.07.621
UR  - https://www.sciencedirect.com/science/article/pii/S2351978915006228
AB  - Human performance has become a pertinent issue within cyber security. However, this research has been stymied by the limited availability of expert cyber security professionals. This is partly attributable to the ongoing workload faced by cyber security professionals, which is compounded by the limited number of qualified personnel and turnover of personnel across organizations. Additionally, it is difficult to conduct research, and particularly, openly published research, due to the sensitivity inherent to cyber operations at most organizations. As an alternative, the current research has focused on data collection during cyber security training exercises. These events draw individuals with a range of knowledge and experience extending from seasoned professionals to recent college graduates to college students. The current paper describes research involving data collection at two separate cyber security exercises. This data collection involved multiple measures which included behavioral performance based on human-machine transactions and a questionnaire-based assessments of cyber security experience. It was found that participants reporting more experience with cyber security topics and cyber security software tools made greater use of general purpose software tools, combining the use of general purpose tools with specialized cyber security software applications. Given that organizations make substantial investments in cyber security software tools, it is important to recognize that while these tools enable specialized analyses that would not be possible otherwise, they are not sufficient. Instead, effective cyber security operations involve a range of activities that extends from the highly general (e.g., taking notes, Internet search) to domain specific (e.g., disk forensics) and the accompanying work environment should accommodates this range of activities.
ER  - 

TY  - JOUR
T1  - Psychophysical assessment of a driver’s mental state in autonomous vehicles
AU  - Arakawa, Toshiya
AU  - Hibi, Ryosuke
AU  - Fujishiro, Taka-aki
JO  - Transportation Research Part A: Policy and Practice
VL  - 124
SP  - 587
EP  - 610
PY  - 2019
DA  - 2019/06/01/
SN  - 0965-8564
DO  - https://doi.org/10.1016/j.tra.2018.05.003
UR  - https://www.sciencedirect.com/science/article/pii/S0965856417309849
KW  - Human factors
KW  - Autonomous vehicle
KW  - Dependency
KW  - System failure
KW  - Driving simulator
AB  - Recently, there has been an increasing interest in the development of autonomous vehicles. However, some of the challenges that are associated with autonomous vehicles are yet to be resolved. Here, we investigate the user dependence on autonomous control in autopilot vehicles. Further, we verify whether drivers can control the vehicles in an appropriate manner after a system failure based on the range of biometric data. The participants in this study experienced three scenarios in a driving simulator: manual-driving, autonomous-driving, and system-failure scenarios, which forced the participants to resume manual control. The data obtained from salivary amylase depict that drivers tend to be anxious while performing the transition from the manual-driving scenario to the autonomous-driving scenario; however, all drivers have to be accustomed with the system in order to drive using a driving simulator. Thus, the difference of anxiety between various drivers is observed to be suppressed. The seat pressure data illustrate that an area having a value equal to 95% of the probability-deviation ellipse during the second day of the manual-driving and autonomous-driving scenarios is observed to have the largest value from among each driving scenario, which seems to be caused due to the driver’s concentration or fatigue. Further, the systolic blood pressures of all the drivers increased with time. However, in the autonomous-driving scenario, the average relative systolic blood pressure is, on the whole, higher than that in the manual-driving scenario. It is suggested that the drivers had never previously used an autonomous-driving system and that he/she may be uncomfortable or uneasy to autonomously control the brake, accelerator, and steering wheel. Additionally, after a system failure during the manual-driving scenario, the behavior is observed to be similar to that in the initial manual-driving scenario, and the totally average relative systolic blood pressure is higher than that during the initial manual-driving scenario. This indicates that the drivers’ mental workload is relatively low during the autonomous-driving scenario because they do not experience any stress from driving. However, the drivers’ systolic blood pressure increased because of the transition from autonomous driving to manual control and because of the mental workload to control the vehicle on their own just after using an autonomous-driving system. From the viewpoint of the brain activity in the left frontal lobe, the data indicates that the drivers’ cognition level during autonomous driving is lower than that during manual driving and that the declining tendency of the average relative hemoglobin concentration is remarkable during the manual-driving scenario after encountering a system failure. This is because the driver feels that he/she may commit mistakes during manual driving. Additionally, if he/she is driving an autonomous vehicle and if the autonomous-driving system failed, he/she does not need to pay attention to the surrounding subjects and control the vehicle. The eye-gaze data indicate that “mind distraction” occurred in the participants while resuming control after a system failure because their brain activity at this instance was relatively low. Our results indicate that drivers who depend on autonomous control systems experience stress upon switching to manual control after a system failure.
ER  - 

TY  - JOUR
T1  - Combining ergometer exercise and artificial gravity in a compact-radius centrifuge
AU  - Diaz, Ana
AU  - Trigg, Chris
AU  - Young, Laurence R.
JO  - Acta Astronautica
VL  - 113
SP  - 80
EP  - 88
PY  - 2015
DA  - 2015/08/01/
SN  - 0094-5765
DO  - https://doi.org/10.1016/j.actaastro.2015.03.034
UR  - https://www.sciencedirect.com/science/article/pii/S0094576515001344
KW  - Artificial gravity
KW  - Human centrifuge
KW  - Human spaceflight countermeasure
KW  - Ergometer exercise
KW  - Spaceflight deconditioning
AB  - Humans experience physiological deconditioning during space missions, primarily attributable to weightlessness. Some of these adverse consequences include bone loss, muscle atrophy, sensory-motor deconditioning, and cardiovascular alteration, which may lead to orthostatic intolerance when astronauts return to Earth. Artificial gravity could provide a comprehensive countermeasure capable of challenging all the physiological systems at once, particularly if combined with exercise, thereby maintaining overall health during extended exposure to weightlessness. A new Compact Radius Centrifuge (CRC) platform was designed and built on the existing Short Radius Centrifuge (SRC) at the Massachusetts Institute of Technology (MIT). The centrifuge has been constrained to a radius of 1.4 m, the upper radial limit for a centrifuge to fit within an International Space Station (ISS) module without extensive structural alterations. In addition, a cycle ergometer has been added for exercise during centrifugation. The CRC now includes sensors of foot forces, cardiovascular parameters, and leg muscle electromyography. An initial human experiment was conducted on 12 subjects to analyze the effects of different artificial gravity levels (0g, 1g, and 1.4g, measured at the feet) and ergometer exercise intensities (25W warm-up, 50W moderate and 100W vigorous) on the musculoskeletal function as well as motion sickness and comfort. Foot forces were measured during the centrifuge runs, and subjective comfort and motion sickness data were gathered after each session. Preliminary results indicate that ergometer exercise on a centrifuge may be effective in improving musculoskeletal function. The combination is well tolerated and motion sickness is minimal. The MIT CRC is a novel platform for future studies of exercise combined with artificial gravity. This combination may be effective as a countermeasure to space physiological deconditioning.
ER  - 

TY  - JOUR
T1  - Estimating the Relationship between Heart Rate and Power Output for Short Term Cycling Exercises
AU  - Meyer, Daniel
AU  - Dungs, Carolin
AU  - Senner, Veit
JO  - Procedia Engineering
VL  - 112
SP  - 237
EP  - 243
PY  - 2015
DA  - 2015/01/01/
T2  - 'The Impact of Technology on Sport VI' 7th Asia-Pacific Congress on Sports Technology, APCST2015
SN  - 1877-7058
DO  - https://doi.org/10.1016/j.proeng.2015.07.206
UR  - https://www.sciencedirect.com/science/article/pii/S1877705815014551
KW  - electric bicycles
KW  - power output estimation
KW  - heart rate modeling
KW  - human physiology
AB  - In this paper, we statistically analyze a dataset of performance diagnostics of 1940 subjects to examine the influence of different physical characteristics on the relationship between heart rate and power output. Five characteristics - the cyclist's height, weight, age, sex and fitness level – were identified as parameters for the model. Next, we divide the dataset into different subsets according to the statistical analysis and modify formulas found in the literature to estimate the maximum heart rate as well as the maximum power output for each group. Then, we derive formulas from the dataset to estimate the heart rate and power output at the individual anaerobic threshold (IAT) as well as the heart rate at low workload. A linear curve between these points describes the immediate relationship between heart rate and power. We compared the results of the adapted formulas to the results of the original formulas for experimental data of 15 subjects. The adapted formulas show better results in terms of mean absolute error (MAE) and sum of squared residuals (SSR) for estimating the maximum power output, but no improvement in estimating the maximum heart rate. The heart rate at IAT is predicted with a MAE of 9 beats per minute (bpm) and heart rate for low intensity with a MAE of 13 bpm. Power at the IAT is predicted with a MAE of 22 Watts.
ER  - 

TY  - JOUR
T1  - The cumulative effects of work-related factors increase the heart rate of cabin field machine operators
AU  - Jankovský, Martin
AU  - Merganič, Ján
AU  - Allman, Michal
AU  - Ferenčík, Michal
AU  - Messingerová, Valéria
JO  - International Journal of Industrial Ergonomics
VL  - 65
SP  - 173
EP  - 178
PY  - 2018
DA  - 2018/05/01/
SN  - 0169-8141
DO  - https://doi.org/10.1016/j.ergon.2017.08.003
UR  - https://www.sciencedirect.com/science/article/pii/S0169814116301779
KW  - Work environment
KW  - Multi-factor assessment
KW  - Biofeedback
KW  - Shiftwork
AB  - Operating field machines causes little physical exertion. However, the combined effects of work-related factors strain the cardiovascular system, elevating the heart rate of the operator. Our goal was to determine what work-related factors increased the risk of cardiovascular disease of cut-to-length machine operators. We created two generalized linear models. A model consisting of 678 cases, explained 32% of the heart rate variability through the operators' height and weight, machine types, parts of the shifts, lighting, and whole-body vibrations. To identify which factors actually increased the risk of cardiovascular diseases, we assessed a subset (193 cases) of heart rates elevated above 90 beats per minute. We found that the operators’ height, machine types, parts of the shifts, equivalent noise, lighting, and whole-body vibrations explained about 72% of the elevated heart rate variability. The elevated heart rate depended on variables, which can be optimized to decrease the risk of cardiovascular diseases.
Relevance to industry
Cabin field machines are widely used in various industries. Our findings show that factors of the work environment affect the circulatory systems of the operators less than shiftwork. In order to further reduce the effects of work on operators, we should put more focus on improving the work organization.
ER  - 

TY  - JOUR
T1  - SIRONA: Sustainable Integration of Regenerative Outer-space Nature and Agriculture. Part 2 — Design Development and Projected Performance
AU  - Hava, Heather
AU  - Zhou, H. Larissa
AU  - Mehlenbeck, Chad
AU  - King, Abby
AU  - Lombardi, Elizabeth M.
AU  - Baker, Kyri
AU  - Kaufman, Andy
AU  - Correll, Nikolaus
JO  - Acta Astronautica
VL  - 196
SP  - 350
EP  - 368
PY  - 2022
DA  - 2022/07/01/
SN  - 0094-5765
DO  - https://doi.org/10.1016/j.actaastro.2020.07.001
UR  - https://www.sciencedirect.com/science/article/pii/S0094576520304185
KW  - Bioregenerative Life Support Systems (BLiSS)
KW  - Mars greenhouse
KW  - Living Systems Centered Design (LSCD)
KW  - Biomimicry
KW  - Biophilic design
KW  - Robotic gardening
AB  - A comprehensive Bioregenerative Life Support System (BLiSS) for human Long-duration Space Exploration Missions (LDSEMs) requires an innovative design philosophy and novel technical solutions. SIRONA: Sustainable Integration of Regenerative Outer-space Nature and Agriculture is a greenhouse design that produces a wide variety of food sources and provides life support functions, including access to nature to improve astronaut restoration, relaxation, and recreation. In a previous paper (Hava et al., 2019), risk analyses, technologies, and system architecture were outlined, while this paper describes the foundational Living Systems Centered Design (LSCD) principles that informed the development of the greenhouse. Analyses on projected performance are also carried out to validate design assumptions and constraints.
ER  - 

TY  - JOUR
T1  - Customization of user interfaces to reduce errors and enhance user acceptance
AU  - Burkolter, Dina
AU  - Weyers, Benjamin
AU  - Kluge, Annette
AU  - Luther, Wolfram
JO  - Applied Ergonomics
VL  - 45
IS  - 2, Part B
SP  - 346
EP  - 353
PY  - 2014
DA  - 2014/03/01/
SN  - 0003-6870
DO  - https://doi.org/10.1016/j.apergo.2013.04.017
UR  - https://www.sciencedirect.com/science/article/pii/S0003687013000902
KW  - Reconfiguration
KW  - Customization
KW  - Process control
KW  - User acceptance
AB  - Customization is assumed to reduce error and increase user acceptance in the human–machine relation. Reconfiguration gives the operator the option to customize a user interface according to his or her own preferences. An experimental study with 72 computer science students using a simulated process control task was conducted. The reconfiguration group (RG) interactively reconfigured their user interfaces and used the reconfigured user interface in the subsequent test whereas the control group (CG) used a default user interface. Results showed significantly lower error rates and higher acceptance of the RG compared to the CG while there were no significant differences between the groups regarding situation awareness and mental workload. Reconfiguration seems to be promising and therefore warrants further exploration.
ER  - 

TY  - JOUR
T1  - Mechanization status based on machinery utilization and workers’ workload in sweet corn cultivation in Malaysia
AU  - Isaak, Momtaz
AU  - Yahya, Azmi
AU  - Razif, Muhammad
AU  - Mat, Nazmi
JO  - Computers and Electronics in Agriculture
VL  - 169
SP  - 105208
PY  - 2020
DA  - 2020/02/01/
SN  - 0168-1699
DO  - https://doi.org/10.1016/j.compag.2019.105208
UR  - https://www.sciencedirect.com/science/article/pii/S0168169919306234
KW  - Mechanization status
KW  - Machinery energy
KW  - Production capacity
KW  - Sweet corn
AB  - Agricultural machinery utilization in Malaysia still very low, especially in sweet corn cultivation, compared with the other crop production systems. In this study was estimated two methods to evaluate the mechanization status of the respective field operations in sweet corn cultivation in Malaysia. The first method was used the PCL-HRL-EGL Cartesian plot based on Production capacity, Heartbeat rate, and Energy expenditures of human labor. The second method was used mechanization index based on energy expenditures of machinery and human labor. The study aim of was to assess the mechanization status in sweet corn cultivation in Malaysia. This paper described the overall mechanization status in the cultivation of sweet corn in Malaysia, and the machinery energy, worker’s energy expenditure, and heart rate for various field operations that were involved in cultivation. The field operations include tillage, planting, fertilizing, spraying, harvesting, and cutting plants. Field capacity, and machinery energy for each of the operations were calculated. The calculated mechanization index was used in the study to describe the mechanization status in sweet corn cultivation. A mean overall mechanization index of 36.49% and aggregate machinery energy of 340.67 ± 41.99 MJ/ha were registered for the crop. Highest mechanization index, and machinery energy were acquired in the tillage operation of 94.09% and 105.35 ± 9.37 MJ/ha while the lowest mechanization index, and machinery energy were in the harvesting operation with bags of 0.83%, and 0.42 ± 0.09 MJ/ha. These calculated mechanization indexes, and PCL-HRL-EGL Cartesian Plot were used for ranking the field operations based on their priority for mechanization. The outcome of this research could be contributed to lightening human energy expenditures and improving the mechanization status ultimately.
ER  - 

TY  - JOUR
T1  - How We Can Improve the Quality of Care for Patients Requesting Medical Assistance in Dying: A Qualitative Study of Health Care Providers
AU  - Oczkowski, Simon J.W.
AU  - Crawshaw, Diane
AU  - Austin, Peggy
AU  - Versluis, Donald
AU  - Kalles-Chan, Gaelen
AU  - Kekewich, Mike
AU  - Curran, Dorothyann
AU  - Miller, Paul Q.
AU  - Kelly, Michaela
AU  - Wiebe, Ellen
AU  - Dees, Marianne
AU  - Frolic, Andrea
JO  - Journal of Pain and Symptom Management
VL  - 61
IS  - 3
SP  - 513
EP  - 521.e8
PY  - 2021
DA  - 2021/03/01/
SN  - 0885-3924
DO  - https://doi.org/10.1016/j.jpainsymman.2020.08.018
UR  - https://www.sciencedirect.com/science/article/pii/S088539242030693X
KW  - Medical assistance in dying
KW  - euthanasia
KW  - assisted suicide
KW  - quality of care
AB  - Context
Since Canada decriminalized medical assistance in dying (MAID) in 2015, clinicians and organizations have developed policies and protocols to implement assisted dying in clinical practice. Five years on, there is little consensus as to what constitutes high-quality care in MAID.
Objectives
To describe MAID clinicians' perspectives on quality of care in MAID, including challenges, successes, and clinical practice suggestions.
Methods
We conducted an exploratory, multicenter, and qualitative study at four Canadian centers. Using a semistructured interview guide, we conducted interviews with 20 health care providers. Interviews were transcribed and deidentified before analysis. Adopting a qualitative descriptive approach, we used a thematic analysis to identify primary and secondary themes in the interviews and practice suggestions to improve quality of care to patients who request MAID.
Results
We identified three major themes. 1) Improving access and patient experience: clinicians described struggles in ensuring equitable access to MAID and supporting MAID patients and their families. 2) Supporting providers and sustainability: clinicians described managing MAID workload, remuneration, educational needs, and the emotional impact of participating in assisted dying. 3) Institutional support: descriptions of MAID communication tools and training, use of standardized care pathways, interprofessional collaboration, and human resource planning. Clinicians also described suggestions for clinical practice to improve quality of care.
Conclusion
Canadian health care providers described unique challenges in caring for patients who request MAID, along with practices to improve the quality of care.
ER  - 

TY  - JOUR
T1  - Complexity Evolution Across Dissimilar System Components
AU  - Cox, Amy
AU  - Szajnfarber, Zoe
JO  - Procedia Computer Science
VL  - 44
SP  - 52
EP  - 65
PY  - 2015
DA  - 2015/01/01/
T2  - 2015 Conference on Systems Engineering Research
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2015.03.049
UR  - https://www.sciencedirect.com/science/article/pii/S1877050915002859
KW  - complexity growth
KW  - human-in-the-loop systems
KW  - multi-domain matrices
AB  - This work is motivated by a prior case study of user driven changes to combat aircraft that was researched by the authors. The study found that the initial changes were of seemingly low complexity, yet, follow-on integration required significantly more schedule (years versus months) and cost to implement. Focusing solely on the hardware and its functions revealed a disproportionate increase in complexity for minimal functional gain. However, expanding the system to consider the user revealed a trade-off between user workload and system complexity. The initial system functional gain was achieved by a combination of low complexity hardware modifications and an increase in the aircrew from 6 to 11; the subsequent generation involved extensive hardware integration and reduced aircrew requirements to 7. The existing design literature is quite extensive on the measurement of system complexity, particularly to better control design schedule and cost, with a tight focus on single types of system components (e.g. hardware or software). The literature does not provide a good means to capture this observed exchange that occurred between dissimilar components. In this paper, we present a method for considering the interactions amongst dissimilar system components and the changes in complexity as the system evolves. This method leverages existing Multi-Domain-Matrices (MDM) techniques, but unlike previous work, treats humans-in-the-loop as components that accomplish system functions. To illustrate the utility of this method, it is applied to a toy example, the making of egg foam with culinary hardware of varying complexity. In holding the overall function constant, the analysis method clearly demonstrates an exchange between human and hardware functions as the hardware grew in complexity. Future application of this method will consider more complex systems, specifically the case that drove this line of thought. It is anticipated that application of this method to the case in question will clarify the mechanisms that drove system complexity increases in the second generation aircraft technology. It is also anticipated that this method will aid in the consideration of the trades that occur between dissimilar system components, thus enabling better management of overall system complexity.
ER  - 

TY  - JOUR
T1  - Establishment of Next-Generation Neurosurgery Research and Training Laboratory with Integrated Human Performance Monitoring
AU  - Bernardo, Antonio
JO  - World Neurosurgery
VL  - 106
SP  - 991
EP  - 1000
PY  - 2017
DA  - 2017/10/01/
SN  - 1878-8750
DO  - https://doi.org/10.1016/j.wneu.2017.06.160
UR  - https://www.sciencedirect.com/science/article/pii/S1878875017310574
KW  - Education
KW  - Laboratory
KW  - Neurosurgery
KW  - Training
AB  - Quality of neurosurgical care and patient outcomes are inextricably linked to surgical and technical proficiency and a thorough working knowledge of microsurgical anatomy. Neurosurgical laboratory-based cadaveric training is essential for the development and refinement of technical skills before their use on a living patient. Recent biotechnological advances including 3-dimensional (3D) microscopy and endoscopy, 3D printing, virtual reality, surgical simulation, surgical robotics, and advanced neuroimaging have proved to reduce the learning curve, improve conceptual understanding of complex anatomy, and enhance visuospatial skills in neurosurgical training. Until recently, few means have allowed surgeons to obtain integrated surgical and technological training in an operating room setting. We report on a new model, currently in use at our institution, for technologically integrated surgical training and innovation using a next-generation microneurosurgery skull base laboratory designed to recreate the setting of a working operating room. Each workstation is equipped with a 3D surgical microscope, 3D endoscope, surgical drills, operating table with a Mayfield head holder, and a complete set of microsurgical tools. The laboratory also houses a neuronavigation system, a surgical robotic, a surgical planning system, 3D visualization, virtual reality, and computerized simulation for training of surgical procedures and visuospatial skills. In addition, the laboratory is equipped with neurophysiological monitoring equipment in order to conduct research into human factors in surgery and the respective roles of workload and fatigue on surgeons' performance.
ER  - 

TY  - JOUR
T1  - A fuzzy logic control in adjustable autonomy of a multi-agent system for an automated elderly movement monitoring application
AU  - Mostafa, Salama A.
AU  - Mustapha, Aida
AU  - Mohammed, Mazin Abed
AU  - Ahmad, Mohd Sharifuddin
AU  - Mahmoud, Moamin A.
JO  - International Journal of Medical Informatics
VL  - 112
SP  - 173
EP  - 184
PY  - 2018
DA  - 2018/04/01/
SN  - 1386-5056
DO  - https://doi.org/10.1016/j.ijmedinf.2018.02.001
UR  - https://www.sciencedirect.com/science/article/pii/S1386505618300297
KW  - Autonomous agent
KW  - Multi-agent system
KW  - Adjustable autonomy
KW  - Fuzzy logic
KW  - Elderly remote care
AB  - Autonomous agents are being widely used in many systems, such as ambient assisted-living systems, to perform tasks on behalf of humans. However, these systems usually operate in complex environments that entail uncertain, highly dynamic, or irregular workload. In such environments, autonomous agents tend to make decisions that lead to undesirable outcomes. In this paper, we propose a fuzzy-logic-based adjustable autonomy (FLAA) model to manage the autonomy of multi-agent systems that are operating in complex environments. This model aims to facilitate the autonomy management of agents and help them make competent autonomous decisions. The FLAA model employs fuzzy logic to quantitatively measure and distribute autonomy among several agents based on their performance. We implement and test this model in the Automated Elderly Movements Monitoring (AEMM-Care) system, which uses agents to monitor the daily movement activities of elderly users and perform fall detection and prevention tasks in a complex environment. The test results show that the FLAA model improves the accuracy and performance of these agents in detecting and preventing falls.
ER  - 

TY  - JOUR
T1  - Automation and the situation awareness of drivers in agricultural semi-autonomous vehicles
AU  - Bashiri, Behzad
AU  - Mann, Danny D.
JO  - Biosystems Engineering
VL  - 124
SP  - 8
EP  - 15
PY  - 2014
DA  - 2014/08/01/
SN  - 1537-5110
DO  - https://doi.org/10.1016/j.biosystemseng.2014.06.002
UR  - https://www.sciencedirect.com/science/article/pii/S153751101400083X
KW  - Automation design
KW  - Situation awareness
KW  - Agricultural vehicle
KW  - Situation awareness rating technique
AB  - The effects of in-vehicle automation and driving assistant systems on the situation awareness of drivers have been the subject of much research with the implications of automation in such man-machine systems being identified. With the introduction of advanced automated systems in agricultural machinery, farmers are now working with semi-autonomous vehicles. A human factors perspective is needed to ensure the safe and efficient operation of such systems. This simulator study investigated the effects of automating vehicle steering and implement control and monitoring task automation on the situation awareness of drivers. Experiments were conducted using a tractor driving simulator located in the Agricultural Ergonomics Laboratory at the University of Manitoba. Thirty young, experienced tractor drivers participated in this study. It was found that implement control and monitoring task automation significantly affected the situation awareness of operators. Situation awareness increased as the level of automation support increased although the highest level of automation, where the participants were removed from the task loop, resulted in low situation awareness at a level similar to the condition with no automation support. The highest level of situation awareness was observed when the simulator suggested the required action to be taken by the operator. Vehicle steering task automation reduced the attentional demand of the task.
ER  - 

TY  - JOUR
T1  - User experience and interaction performance in 2D/3D telecollaboration
AU  - Anton, David
AU  - Kurillo, Gregorij
AU  - Bajcsy, Ruzena
JO  - Future Generation Computer Systems
VL  - 82
SP  - 77
EP  - 88
PY  - 2018
DA  - 2018/05/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2017.12.055
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X17323385
KW  - Telecollaboration
KW  - Remote interaction
KW  - 3D interaction
KW  - Augmented reality
KW  - Virtual reality
KW  - Telepresence
AB  - Affordable 3D cameras, mixed reality headsets, and 3D displays have recently pushed the Augmented Reality (AR) and Virtual Reality (VR) technologies into the consumer market. While these technologies have been adopted in video-game and entertainment industry, the adoption for professional use, such as in industrial and business environment, health-care, and education is still lagging behind. In light of recent advances in mobile communications, AR/VR could pave the way for novel interaction and collaboration of geographically distributed users. Despite the technology being available, majority of communication is still accomplished using traditional video conferencing technology which lacks interactivity, depth perception, and ability to convey non-verbal cues in communication. 3D systems for communication have been proposed to overcome these limitations; however, very few studies looked into the performance and interaction with such technologies. In this paper, we report on a study that examined telecollaboration scenario with three different modalities: 2D video-conferencing, 3D stereoscopic interface, and 3D stereoscopic interface with augmented visual feedback. Twenty participants worked in pairs, assuming the roles of instructor and worker, to remotely interact and perform a set of assembly tasks.
ER  - 

TY  - JOUR
T1  - Health care professionals’ perspectives on physical activity within the Ugandan mental health care system
AU  - Mugisha, James
AU  - De Hert, Marc
AU  - Knizek, Birthe Loa
AU  - Kwiringira, Japheth
AU  - Kinyanda, Eugene
AU  - Byansi, William
AU  - van Winkel, Ruud
AU  - Myin-Germeys, Inez
AU  - Stubbs, Brendon
AU  - Vancampfort, Davy
JO  - Mental Health and Physical Activity
VL  - 16
SP  - 1
EP  - 7
PY  - 2019
DA  - 2019/03/01/
SN  - 1755-2966
DO  - https://doi.org/10.1016/j.mhpa.2019.02.001
UR  - https://www.sciencedirect.com/science/article/pii/S1755296618301789
KW  - Physical activity
KW  - Exercise
KW  - Stigma
KW  - Community
AB  - Background
Mental health care systems in Africa are faced with a high burden of mental disorders. There is need to explore evidence-based, scalable interventions to compliment the “traditional” health care system. Physical activity (PA) can augment the effectiveness of existing programs. However, little is known about the perspectives of health care professionals on PA. Understanding this is key to implementation.
Methods
This was a qualitative exploratory study based on 13 key informant interviews among experienced health care professionals working at Butabika National Referral and Teaching Hospital, Uganda. Data was analyzed through content thematic analysis.
Results
Participants reported PA benefits were: improved individual competences and engagement, social reintegration and reduced family and community burden. Self-stigma, lack of community support, lack of infrastructure and equipment, lack of monitoring capacity, human resource challenges and a focus solely on pharmacotherapy were among the most reported barriers to application of PA in management of mental health problems.
Conclusion
Despite the high level of understanding of PA among health care professionals, PA promotion largely depends on implementation of strategies to deal with community and health systems barriers. Although patients need to be empowered to deal with their individual barriers, greater support and action is needed by policy makers. Public health programs should support PA through community engagement and social re-integration programs. The government should promote a holistic mental health care perspective and provide adequate infrastructural and human resources to support PA in the existing primary and mental health care systems.
ER  - 

TY  - JOUR
T1  - Visualizing distances as a function of speed: Design and evaluation of a distance-speedometer
AU  - Schewe, Frederik
AU  - Vollrath, Mark
JO  - Transportation Research Part F: Traffic Psychology and Behaviour
VL  - 64
SP  - 260
EP  - 273
PY  - 2019
DA  - 2019/07/01/
SN  - 1369-8478
DO  - https://doi.org/10.1016/j.trf.2019.05.012
UR  - https://www.sciencedirect.com/science/article/pii/S1369847818308283
KW  - Interface evaluation
KW  - Ecological interface design
KW  - Driver behaviour
AB  - This paper contributes to the research on transportation and human factors by designing and evaluating an ecological human-machine interface for speed and distance control. In the future, traffic management will determine optima for speed and safety distances. Wirelessly broadcasted, the question remains how to present this information to drivers in a way that is easily understood and intuitively followed. To this end, a human-machine interface, called distance-speedometer, was first developed according to the principles of ecological interface design and then evaluated in a driving simulator study with forty-nine participants. It presents augmented distances derived from speed in a head-up display. Using a within-subject design, the distance-speedometer and standard speedometer were compared against each other in two scenarios (car-following & sign-following). Each scenario triggered several speed changes. When reacting to speed signs, driving performance did not differ between the two interfaces. However, with the distance-speedometer, visual workload was reduced as more secondary tasks could be completed. When reacting to speed changes of a car ahead, the engagement in the secondary task did not differ significantly between the two interfaces. However, the variance of speed deviations was significantly lower with the distance-speedometer. Results can be explained by the ability to process the distance-speedometer in a skill-based manner, whereas the normal speedometer demands rule-based behaviour to control the speed. With regard to traffic management, the distance-speedometer might be used to unconsciously influence the driver’s choice of speed in order to increase traffic safety and efficiency.
ER  - 

TY  - JOUR
T1  - Automatic recognition of chewing noises in epileptic EEG based on period segmentation
AU  - Wei, Zuochen
AU  - Zou, Junzhong
AU  - Zhang, Jian
JO  - Neurocomputing
VL  - 190
SP  - 107
EP  - 116
PY  - 2016
DA  - 2016/05/19/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.01.029
UR  - https://www.sciencedirect.com/science/article/pii/S092523121600076X
KW  - Automatic recognition
KW  - Epileptic EEG
KW  - Period segmentation
KW  - Superimposed wave
KW  - Chewing noise
AB  - Automatic detection of Interictal Epileptiform Discharges (IED) has the great significance in diagnosis of epilepsy and relieves the heavy workload of inspecting electroencephalogram (EEG). The artifacts in epileptic EEG strongly affect the detection results, especially in the form of chewing noises. This paper proposes a novel time-domain approach to process chewing noises in epileptic EEG signals based on period segmentation. Firstly, merger of increasing and decreasing sequences (MIDS) is employed to segment EEG periods. This period segmentation approach considers information of waveform rather than a single sample point and applies human vision principle. Experimental results show that the performance of merger and period segmentation is close to clinical visual detection. Secondly, chewing noises are recognized in epilepsy patients׳ EEG following period segmentation. To reduce the false recognition rate, classification results of four channels F3, F4, F7 and F8, which acquire high sensitivity and low false recognition rate, are fused to determine fragments׳ classification by weighting. With this method, EEG recordings of 20 epilepsy patients were analyzed. The results showed that a sensitivity of 98.10% and a false recognition rate of 0.01375/s were achieved. It demonstrates that the proposed approach performs well in automatic recognition of chewing noises in epileptic EEG, which is of crucial importance to automatic detection of IED.
ER  - 

TY  - JOUR
T1  - A Cooperative Automation Concept for User-oriented Support of Air Target Identification
AU  - Özyurt, Emre
AU  - Flemisch, Frank
AU  - Döring, Bernhard
JO  - Procedia Manufacturing
VL  - 3
SP  - 1918
EP  - 1925
PY  - 2015
DA  - 2015/01/01/
T2  - 6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015
SN  - 2351-9789
DO  - https://doi.org/10.1016/j.promfg.2015.07.235
UR  - https://www.sciencedirect.com/science/article/pii/S235197891500236X
KW  - Assistance and automation
KW  - Cooperative automation
KW  - Decision ladder
KW  - Command and control systems
KW  - Decision support
AB  - For over 40 years science in a variety of domains has conducted an impressive amount of research in the field of assistance and automation concepts, which apply human factors and needs in the design stage of cooperative and cognitive technical systems. Cooperative automation is an approach that tries to keep the user in the control loop by means of a continuous interaction during task execution. Cooperative automation aims to support the harmonization of the actor's activities (user and automation) in a human-machine-system. To enable this, both the internal (processing and computation) and external (communications and interfaces) design of the automation has to be compatible with human competence. This contribution addresses the key features of cooperative automation. These features have been used for creating a design space, which can be used as method repository in order to develop assistance systems based on the cognitive capabilities of the human. The key elements are represented as dimensions of the design space. Corresponding theories and methods are discussed. The design process for a cognitive and cooperative assistance system based on the dimensions of the design space are described. The developed Cognitive and Cooperative Assistance System (COGAS), has been implemented in the domain of air target identification on German naval ships. An evaluation of COGAS has been conducted with naval operators in order to verify its operability and to optimize and extend the COGAS functionality. The results show that COGAS improves the operator's performance in terms of increasing the amount of correct decisions and accelerating the identification process without increasing the operator's stress level. In addition it was found that COGAS helps to enhance the situational awareness due to the workload optimization.
ER  - 

TY  - JOUR
T1  - A novel approach for the automated segmentation and volume quantification of cardiac fats on computed tomography
AU  - Rodrigues, É.O.
AU  - Morais, F.F.C.
AU  - Morais, N.A.O.S.
AU  - Conci, L.S.
AU  - Neto, L.V.
AU  - Conci, A.
JO  - Computer Methods and Programs in Biomedicine
VL  - 123
SP  - 109
EP  - 128
PY  - 2016
DA  - 2016/01/01/
SN  - 0169-2607
DO  - https://doi.org/10.1016/j.cmpb.2015.09.017
UR  - https://www.sciencedirect.com/science/article/pii/S0169260715002448
KW  - Segmentation
KW  - Image registration
KW  - Atlas
KW  - Computed tomography
KW  - Classification
KW  - Machine learning
AB  - The deposits of fat on the surroundings of the heart are correlated to several health risk factors such as atherosclerosis, carotid stiffness, coronary artery calcification, atrial fibrillation and many others. These deposits vary unrelated to obesity, which reinforces its direct segmentation for further quantification. However, manual segmentation of these fats has not been widely deployed in clinical practice due to the required human workload and consequential high cost of physicians and technicians. In this work, we propose a unified method for an autonomous segmentation and quantification of two types of cardiac fats. The segmented fats are termed epicardial and mediastinal, and stand apart from each other by the pericardium. Much effort was devoted to achieve minimal user intervention. The proposed methodology mainly comprises registration and classification algorithms to perform the desired segmentation. We compare the performance of several classification algorithms on this task, including neural networks, probabilistic models and decision tree algorithms. Experimental results of the proposed methodology have shown that the mean accuracy regarding both epicardial and mediastinal fats is 98.5% (99.5% if the features are normalized), with a mean true positive rate of 98.0%. In average, the Dice similarity index was equal to 97.6%.
ER  - 

TY  - JOUR
T1  - A rule-based expert system for inferring functional annotation
AU  - Xavier, Daniela
AU  - Crespo, Berta
AU  - Fuentes-Fernández, Rubén
JO  - Applied Soft Computing
VL  - 35
SP  - 373
EP  - 385
PY  - 2015
DA  - 2015/10/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2015.05.055
UR  - https://www.sciencedirect.com/science/article/pii/S1568494615004068
KW  - Functional annotation
KW  - Rule-based expert system
KW  - Bioinformatics
AB  - Functional annotation is the process that assigns a biological functionality to a deoxyribonucleic acid (DNA) sequence. It requires searching in huge data sets for candidates, and inferring the most appropriate features based on the information found and expert knowledge. When humans perform most of these tasks, results are of a high quality, but there is a bottleneck in processing; when experts are largely replaced by automated tools, annotation is faster but of poorer quality. Combining the automatic annotation with expert systems (ESs) can enhance the quality of the annotation, while effectively reducing experts’ workload. This paper presents INFAES, a rule-based ES developed for mimicking the human reasoning in the inference stage of the functional annotation. It integrates knowledge on Biology and heuristics about the use of Bioinformatics tools. Its development adopts state-of-the-art methodologies to facilitate the acquisition and integration of new knowledge. INFAES showed a high performance when compared to the systems developed for the first large-scale community-based critical assessment of protein function annotation (CAFA) [1].
ER  - 

TY  - JOUR
T1  - The Desirable Features of Computer Based Emergency Operating Procedure for Nuclear Power Operation
AU  - Suryono, Tulis Jojok
AU  - Gofuku, Akio
JO  - IFAC-PapersOnLine
VL  - 49
IS  - 19
SP  - 403
EP  - 407
PY  - 2016
DA  - 2016/01/01/
T2  - 13th IFAC Symposium on Analysis, Design, and Evaluation ofHuman-Machine Systems HMS 2016
SN  - 2405-8963
DO  - https://doi.org/10.1016/j.ifacol.2016.10.599
UR  - https://www.sciencedirect.com/science/article/pii/S2405896316321905
KW  - emergency operating procedures
KW  - functional information
KW  - remaining time
KW  - dynamic operation permissions
AB  - Abstract:
Operating procedures are guidance for operators to monitor, make decision and take related actions in normal, abnormal and emergency condition of nuclear power plants. The initial form of operating procedures, paper based procedures (PBP), have some drawbacks such as high operators’ workload and necessity of much time to find and execute procedures related to the events. Therefore, computer based procedures (CBP) were developed to overcome the problems. However, some operators are not familiar with the CBP and may refuse to use the CBP because they used to use the PBP without any problems. This research investigates some features to the CBP to make it easier for operator to use and execute procedures and reducing human error. The proposed features are providing functional information of the procedures steps and related components using multilevel flow modeling (MFM), displaying remaining time for operators to complete each step or group of steps and implementing dynamic operation permission to reduce commission error by operators. The features, integrated with operator support systems, will make the CBP more intelligent and easy to use, especially in emergency condition of nuclear power plants
ER  - 

TY  - JOUR
T1  - Automated triaging of very large bug repositories
AU  - Banerjee, Sean
AU  - Syed, Zahid
AU  - Helmick, Jordan
AU  - Culp, Mark
AU  - Ryan, Kenneth
AU  - Cukic, Bojan
JO  - Information and Software Technology
VL  - 89
SP  - 1
EP  - 13
PY  - 2017
DA  - 2017/09/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2016.09.006
UR  - https://www.sciencedirect.com/science/article/pii/S0950584916301653
KW  - Automated triaging
KW  - Bug tracking
KW  - Big data analytics
KW  - Software problem repositories
AB  - Context: Bug tracking systems play an important role in software maintenance. They allow both developers and users to submit problem reports on observed failures. However, by allowing anyone to submit problem reports, it is likely that more than one reporter will report on the same issue. Research in open source repositories has focused on two broad areas: determining the original report associated with each known duplicate, and assigning a developer to fix a particular problem. Objective: Limited research has been done in developing a fully automated triager, one that can first ascertain if a problem report is original or duplicate, and then provide a list of 20 potential matches for a duplicate report. We address this limitation by developing an automated triaging system that can be used to assist human triagers in bug tracking systems. Method: Our automated triaging system automatically assigns a label of original or duplicate to each incoming problem report, and provides a list of 20 suggestions for reports classified as duplicate. The system uses 24 document similarity measures and associated summary statistics, along with a suite of document property and user metrics. We perform our research on a lifetime of problem reports from the Eclipse, Firefox and Open Office repositories. Results: Our system can be used as a filtration aide, with high original recall exceeding 95% and low duplicate recall, or as a triaging guide, with balanced recall of approximately 70% for both originals and duplicates. Furthermore, the system reduces the workload on the triager by over 90%. Conclusions: Our work represents the first full scale effort at automatically triaging problem reports in open source repositories. By utilizing multiple similarity measures, we reduce the potential of false matches caused by the diversity of human language.
ER  - 

TY  - JOUR
T1  - Finite Horizon Degradation Control of Complex Interconnected Systems⁎⁎The research project is financed by the European Commission within the European Regional Development Fund, the Swedish Agency for Economic and Regional Growth, Region Gävleborg and the University of Gävle.
AU  - Björsell, Niclas
AU  - Dadash, Amirhossein Hosseinzadeh
JO  - IFAC-PapersOnLine
VL  - 54
IS  - 1
SP  - 319
EP  - 324
PY  - 2021
DA  - 2021/01/01/
T2  - 17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021
SN  - 2405-8963
DO  - https://doi.org/10.1016/j.ifacol.2021.08.036
UR  - https://www.sciencedirect.com/science/article/pii/S2405896321007485
KW  - Intelligent maintenance systems
KW  - Production planning
KW  - control
KW  - Model-driven systems engineering
KW  - Control of multi-scale systems
KW  - Design of fault tolerant/reliable systems
AB  - In industrial production, it is of great importance to have high availability in its production equipment. Well-functioning maintenance is a significant factor for a high level of availability. This can be achieved by minimizing the number of reactive maintenance stops and optimizing scheduled maintenance. New methods for predictive maintenance provide a good opportunity for this, but most technologies that are available today are designed for individual sub-systems and they are rarely designed for a complex, interconnected machine. In the process industry, raw materials are processed into a finished product in a continuous flow through several subsystems and if one subsystem stops, the entire process flow stops. For these processes, it is more important to optimize the maintenance efforts for subsystems so maintenance can take place synchronized. This paper describes a method of supervised control that includes maintenance aspects; health parameters indicating deterioration are included in a MIMO controller. The method is verified in a simulation of a rolling mill with three rollers. The results show that it is possible to optimize the whole complex process including several sub-processes by using a health parameter as a control parameter and broadening the controllability of the system by dividing the workload in a way that all the subsystems reach the desired degradation level for maintenance in a desired optimum time.
ER  - 

TY  - JOUR
T1  - Passive shoulder exoskeleton support partially mitigates fatigue-induced effects in overhead work
AU  - De Bock, Sander
AU  - Ampe, Toon
AU  - Rossini, Marco
AU  - Tassignon, Bruno
AU  - Lefeber, Dirk
AU  - Rodriguez-Guerrero, Carlos
AU  - Roelands, Bart
AU  - Geeroms, Joost
AU  - Meeusen, Romain
AU  - De Pauw, Kevin
JO  - Applied Ergonomics
VL  - 106
SP  - 103903
PY  - 2023
DA  - 2023/01/01/
SN  - 0003-6870
DO  - https://doi.org/10.1016/j.apergo.2022.103903
UR  - https://www.sciencedirect.com/science/article/pii/S0003687022002265
KW  - Physical fatigue
KW  - Wearable assistive device
KW  - Task analysis
KW  - Device evaluation
AB  - Background
Despite the potential of occupational passive shoulder exoskeletons (PSEs) to relieve overhead work, limited insights in overhead work precision performance impedes large-scale adoption in industry.
Objective
To investigate the effect of PSE support on the reduction in task performance caused by physical fatigue.
Methods
This experiment consisted of a randomized, counterbalanced cross-over design comparing Exo4Work PSE support and no support, in a physically fatigued state and a control condition. Precision performance was determined using execution speed and drilling errors. Muscle activity and shoulder joint kinematics were recorded.
Results
Fatigue altered task performance, shoulder joint kinematics, muscle activity and subjective experience during overhead work. The PSE support mitigated the fatigue-induced changes in shoulder kinematics. Additionally, a part of the fatigue-induced co-activation of shoulder stabilizing muscles was avoided when working with the PSE. The PSE support also reduced the activity of the anterior and medial deltoid.
Conclusion
Physical fatigue provokes compensatory movements and increased co-contraction of muscles when executing overhead work. These fatigue-induced alterations are generally believed to increase the overall musculoskeletal load. The support provided by the PSE reduced muscle activity of muscles working to elevate the arm, but also partially mitigated those fatigue-induced effects.
Significance
This study shows that the effect of PSE support on precision performance is limited, and suggested that, apart from the known effects of PSE support during overhead work, wearing the exoskeleton in a physically fatigued state may provide additional advantages.
ER  - 

TY  - JOUR
T1  - Merging and synchronizing corporate and personal voice agents: Comparison of voice agents acting as a secretary and a housekeeper
AU  - Zhao, Jingyu
AU  - Patrick Rau, Pei-Luen
JO  - Computers in Human Behavior
VL  - 108
SP  - 106334
PY  - 2020
DA  - 2020/07/01/
SN  - 0747-5632
DO  - https://doi.org/10.1016/j.chb.2020.106334
UR  - https://www.sciencedirect.com/science/article/pii/S0747563220300881
KW  - Voice agents
KW  - Human-computer interaction
KW  - Trust in voice agents
KW  - Cooperate network
KW  - Enterprise information system
AB  - People are currently facing a one-to-multiple mode of interaction with voice agents (VAs), which are widely used in their personal and working lives separately owing to the rapid development of artificial intelligence. To explore potential trends in the use of VAs, we designed a merged VA and two either familiar (interconnected) or strange (completely independent) VAs, of which one acted as a secretary for work-related issues and the other acted as a housekeeper for personal issues. Seventy-two people participated in a within-group experiment to experience simulated interactions and complete tasks using the designed VAs in a random order. Objective and subjective evaluation data were collected to analyse user experience. The results show that the merged VA performs best and that participants also preferred it over the others based on the collected data on mental workload, performance, satisfaction, and perceived usefulness. The familiar VAs were the second best-performing VAs. Though there were no significant differences in the trust in the three designed VAs, participants held positive and cautious attitudes towards VAs in general. Additionally, this study highlights the importance of efficiency, the value of entertainment, and the distinction between work and personal life with respect to the personal and corporate functions of VAs.
ER  - 

TY  - JOUR
T1  - Super-resolution reconstruction framework of wind turbine wake: Design and application
AU  - Chen, Meng
AU  - Wang, Longyan
AU  - Luo, Zhaohui
AU  - Xu, Jian
AU  - Zhang, Bowen
AU  - Li, Yan
AU  - Tan, Andy C.C.
JO  - Ocean Engineering
VL  - 288
SP  - 116099
PY  - 2023
DA  - 2023/11/15/
SN  - 0029-8018
DO  - https://doi.org/10.1016/j.oceaneng.2023.116099
UR  - https://www.sciencedirect.com/science/article/pii/S0029801823024836
KW  - Wind turbine
KW  - Wake reconstruction
KW  - Deep learning
KW  - Super-resolution
KW  - Wake model assessment
AB  - Complete and clear global wind turbine wake data is very important for the study of wind turbine wake characteristics in increasingly large offshore wind farms. Existing wake measurement techniques can only obtain local high-resolution (HR) wake flow field, or sacrifice accuracy to obtain larger measurement area, which is insufficient for accurate modeling of wake effect. To overcome this challenge, this paper proposes a novel super-resolution (SR) reconstruction approach that can reconstruct the global HR wake flow field from low-resolution (LR) wake flow field measurement data effectively. The proposed approach utilizes a deep learning framework called down-sampled skip-connection and multi-scale network. The performance of the SR approach is evaluated by enhancing the resolution of the wake flow field at different scale factors, and its potential application is demonstrated by assessing the prediction accuracy of three typical wake models. The results indicate that the resolution of the global wind turbine wake can be improved by 16 times using the SR model, and the reconstructed global SR wake flow fields are consistent with the ground truth in terms of both the spatial distribution and the temporal variation. By comparing the prediction results of three different wake models with the LR or SR wake data, it is shown that the SR flow reconstruction method can be applied to more accurately evaluate the wake model prediction performance, which has the potential to improve wake models. Overall, this study presents an innovative solution to the problem of incomplete and inaccurate wake flow measurement in the wind energy industry, which could reduce the workload of experimental measurements and the cost burden of accurate measuring equipment for engineering applications.
ER  - 

TY  - JOUR
T1  - On the engineering design for systematic integration of agent-orientation in industrial automation
AU  - Yu, Liyong
AU  - Schüller, Andreas
AU  - Epple, Ulrich
JO  - ISA Transactions
VL  - 53
IS  - 5
SP  - 1404
EP  - 1409
PY  - 2014
DA  - 2014/09/01/
T2  - ICCA 2013
SN  - 0019-0578
DO  - https://doi.org/10.1016/j.isatra.2013.12.029
UR  - https://www.sciencedirect.com/science/article/pii/S0019057813002395
KW  - Agent-orientation
KW  - Industrial automation
KW  - IEC 61131-3
AB  - In today's automation industry, agent-oriented development of system functionalities appears to have a great potential for increasing autonomy and flexibility of complex operations, while lowering the workload of users. In this paper, we present a reference model for the harmonious and systematical integration of agent-orientation in industrial automation. Considering compatibility with existing automation systems and best practice, this model combines advantages of function block technology, service orientation and native description methods from the automation standard IEC 61131-3. This approach can be applied as a guideline for the engineering design of future agent-oriented automation systems.
ER  - 

TY  - JOUR
T1  - Musculoskeletal Load Assessment of Farmers during Selected Agricultural Works
AU  - Kuta, Łukasz
AU  - Cież, Józef
AU  - Młotek, Małgorzata
JO  - Procedia Manufacturing
VL  - 3
SP  - 1696
EP  - 1703
PY  - 2015
DA  - 2015/01/01/
T2  - 6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015
SN  - 2351-9789
DO  - https://doi.org/10.1016/j.promfg.2015.07.990
UR  - https://www.sciencedirect.com/science/article/pii/S2351978915009919
KW  - Milking
KW  - Electromyography
KW  - Job Strain Index
KW  - Risk
KW  - Agriculture
AB  - During the last years, as a result of the technological development, farmers started to include a new solution like machinery or other devices but the risk level connected with accidents resulting from their use is still high. Agriculture is described as one of the most dangerous industry in Poland. Based on these circumstances the studies were conducted where the main objective was to investigate a workload during agricultural manual and mechanized tasks. The analysis was conducted on 15 farmers on their own farms during the morning and evening milking in the tethering and carousel systems while lifting and carrying a full bucket or a sack and while the tractor was moving. The analysis of muscle load was conducted with the surface EMG (Electromyography) system and Job Strain Index method. The highest values of muscle tension and force were observed in the forearm muscles during the attachment of teat cups to the udder. It was connected with lifting the equipment in an uncomfortable posture assumed by the milker. For the tractor driver the ergonomics of the seat and steering wheel was measured. It has been demonstrated that unfavourable working conditions increase the musculoskeletal overload. One of the methods of preventing them is to create appropriate working conditions for a specific person and gender. This will allow each worker to properly adjust the work and to apply specific matching equipment.
ER  - 

TY  - JOUR
T1  - Strengthen EEG-based emotion recognition using firefly integrated optimization algorithm
AU  - He, Hong
AU  - Tan, Yonghong
AU  - Ying, Jun
AU  - Zhang, Wuxiong
JO  - Applied Soft Computing
VL  - 94
SP  - 106426
PY  - 2020
DA  - 2020/09/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2020.106426
UR  - https://www.sciencedirect.com/science/article/pii/S1568494620303665
KW  - Emotion recognition
KW  - Feature selection
KW  - Firefly algorithm
KW  - EEG
KW  - Classification
AB  - Emotion recognition is helpful for human to enhance self-awareness and respond appropriately towards the happenings around them. Due to the complexity and diversity of emotions, EEG-based emotion recognition is still a challenging task in pattern recognition. In order to recognize diverse emotions, we propose a novel firefly integrated optimization algorithm (FIOA) in this paper. It can simultaneously accomplish multiple tasks, i.e. the optimal feature selection, parameter setting and classifier selection according to different EEG-based emotion datasets. The FIOA utilizes a ranking probability objection function to guarantee the high accuracy recognition with less features. Moreover, the hybrid encoding expression and the dual updating strategy are developed in the FIOA so as to realize the optimal selection of feature subset and classifier without stagnating in the local optimum. In addition to the public DEAP datasets, we also conducted an EEG-based music emotion experiment involving 20 subjects for the validation of the proposed FIOA. After filtering and segmentation, three categories of features were extracted from every EEG signal. Then FIOA was applied to every subject dataset for two pattern recognition of emotions. The results show that the FIOA can automatically find the optimal features, parameter and classifier for different emotion datasets, which greatly reduces the artificial selection workload. Furthermore, comparing with the binary particle swarm optimization (PSObinary) and the binary firefly (FAbinary), the FIOA can achieve the higher accuracy with less features in the emotion recognition.
ER  - 

TY  - JOUR
T1  - MPI+OpenMP tasking scalability for multi-morphology simulations of the human brain
AU  - Valero-Lara, Pedro
AU  - Sirvent, Raül
AU  - Peña, Antonio J.
AU  - Labarta, Jesús
JO  - Parallel Computing
VL  - 84
SP  - 50
EP  - 61
PY  - 2019
DA  - 2019/05/01/
SN  - 0167-8191
DO  - https://doi.org/10.1016/j.parco.2019.03.006
UR  - https://www.sciencedirect.com/science/article/pii/S016781911830317X
KW  - MPI
KW  - OpenMP
KW  - Tasking
KW  - Simulation
KW  - Human brain
KW  - Human brain project
AB  - The simulation of the behavior of the human brain is one of the most ambitious challenges today with a non-end of important applications. We can find many different initiatives in the USA, Europe and Japan which attempt to achieve such a challenging target. In this work, we focus on the most important European initiative (the Human Brain Project) and on one of the models developed in this project. This tool simulates the spikes triggered in a neural network by computing the voltage capacitance on the neurons’ morphology, being one of the most precise simulators today. In the present work, we have evaluated the use of MPI+OpenMP tasking on top of this framework. We prove that this approach is able to achieve a good scaling even when computing a relatively low workload (number of neurons) per node. One of our targets consists of achieving not only a highly scalable implementation, but also to develop a tool with a high degree of abstraction without losing control and performance by using MPI+OpenMP tasking. The main motivation of this work is the evaluation of this cutting-edge simulation on multi-morphology neural networks. The simulation of a high number of neurons, which are completely different among them, is an important challenge. In fact, in the multi-morphology simulations, we find an important unbalancing between the nodes, mainly due to the differences in the neurons, which causes an important under-utilization of the available resources. In this work, the authors present and evaluate mechanisms to deal with this and reduce the time of this kind of simulations considerably.
ER  - 

TY  - JOUR
T1  - Automatic evaluation of stratum basale and dermal papillae using ultrahigh resolution optical coherence tomography
AU  - Xie, Jun
AU  - Hao, Tian
AU  - Li, Chengxin
AU  - Wang, Xianghong
AU  - Yu, Xiaojun
AU  - Liu, Linbo
JO  - Biomedical Signal Processing and Control
VL  - 53
SP  - 101527
PY  - 2019
DA  - 2019/08/01/
SN  - 1746-8094
DO  - https://doi.org/10.1016/j.bspc.2019.04.004
UR  - https://www.sciencedirect.com/science/article/pii/S1746809419301016
KW  - OCT
KW  - Dermal papillae
KW  - Vitiligo
AB  - Diagnosis of many skin conditions requires evaluation of dermal papillae and stratum basale, such as vitiligo. In clinical practice, imaging dermal papillae structures relies on excisional biopsy followed by histological processing and analysis. As biopsy is invasive and associated with complications, a noninvasive imaging method such as optical coherence tomography (OCT) can complement the existing method by enabling large area scanning. However, because OCT image analysis requires training and it takes time to review OCT images from large skin areas, an automatic evaluation method is preferred to reduce the workload and avoid ‘sampling errors’ during image analysis. Here we report an automatic method to enhance and detect dermal papillae and stratum basale in ultrahigh resolution OCT images. A high detection accuracy is achieved by rejecting image artifacts using a surface flattening algorithm and an artifact recognition algorithm. We further demonstrated the efficacy of this automatic method in detecting vitiligo in human subjects.
ER  - 

TY  - JOUR
T1  - Improvement of human–machine compatibility of upper-limb rehabilitation exoskeleton using passive joints
AU  - Zhang, Leiyu
AU  - Li, Jianfeng
AU  - Su, Peng
AU  - Song, Yanming
AU  - Dong, Mingjie
AU  - Cao, Qiang
JO  - Robotics and Autonomous Systems
VL  - 112
SP  - 22
EP  - 31
PY  - 2019
DA  - 2019/02/01/
SN  - 0921-8890
DO  - https://doi.org/10.1016/j.robot.2018.10.012
UR  - https://www.sciencedirect.com/science/article/pii/S0921889018305001
KW  - Stroke
KW  - Upper-limb rehabilitation exoskeleton
KW  - Configuration synthesis
KW  - Human-machine compatibility
KW  - Passive joint
KW  - Glenohumeral joint
AB  - The upper-limb rehabilitation exoskeleton is a critical piece of equipment for stroke patients to compensate for deficiencies of manual rehabilitation and reduce physical therapists’ workloads. In this paper, configuration synthesis of an exoskeleton is completed using advanced mechanism theory. To adapt glenohumeral (GH) movements and improve exoskeletal compatibility, six passive joints were introduced into the connecting interfaces based on optimal configuration principles. The optimal configuration of the passive joints can effectively reduce the gravitational influences of the exoskeleton device and the upper extremities. A compatible exoskeleton (Co-Exos) with 11 degrees of freedom was developed while retaining a compact volume. A new approach is presented to compensate vertical GH movements. The theoretical displacements of translational joints were calculated by the kinematic model of the shoulder loop Θs. A comparison of the theoretical and measured results confirms that the passive joints exhibited good human–machine compatibility for GH movements. The hysteresis phenomenon of translational joints appeared in all experiments due to the elasticoplasticity of the upper arm and GH. In comparable experiments, the effective torque of the second active joint was reduced by an average of 41.3% when passive joints were released. The wearable comfort of Co-Exos was thus improved significantly.
ER  - 

TY  - JOUR
T1  - Team communication of nuclear fire brigades during routine and non-routine task phases
AU  - Takacs, Veronika Klara
AU  - Juhasz, Marta
JO  - International Journal of Industrial Ergonomics
VL  - 90
SP  - 103300
PY  - 2022
DA  - 2022/07/01/
SN  - 0169-8141
DO  - https://doi.org/10.1016/j.ergon.2022.103300
UR  - https://www.sciencedirect.com/science/article/pii/S0169814122000415
KW  - Nuclear fire brigades
KW  - Simulation exercise
KW  - Team communication
KW  - Team coordination
AB  - The purpose of our experiment was to explore communication patterns that are characteristics of nuclear fire brigades during task phases that include unforeseen, non-routine events. We further aimed to understand how team performance was related to the frequency of intrateam communication during different task phases. Six nuclear fire brigades were video recorded during a simulated scenario and subsequent communication utterances were analysed. According to our results, on the central channel a higher frequency of “Simple answer” was negatively related, while on the lateral channel a higher frequency of “Command” and “Information without request” were positively related to team performance. Our results also indicate that while on the central channel communication frequencies were more balanced across adaptation phases, on the lateral channel there was a significant increase in intrateam communication when the teams entered non-routine phases. Furthermore, our results underline the different functions of the two communication channels: while the central channel supports maintaining contact between geographically dispersed team members with formal, standardised communication formulas, the lateral channel supports the modification of the team's strategy with a simpler, less formal communication mode.
Relevance to industry
The findings can be applied in nuclear firefighters' training and thereby contribute to the operational safety in nuclear power plants. By becoming more aware of the communication categories that support teamwork during adaptation, as well as of how best to utilise different communication channels, teams’ workload may be decreased, and team resources may be spared for team adaptation.
ER  - 

TY  - JOUR
T1  - Forecasting with multivariate temporal aggregation: The case of promotional modelling
AU  - Kourentzes, Nikolaos
AU  - Petropoulos, Fotios
JO  - International Journal of Production Economics
VL  - 181
SP  - 145
EP  - 153
PY  - 2016
DA  - 2016/11/01/
T2  - SI: ISIR 2014
SN  - 0925-5273
DO  - https://doi.org/10.1016/j.ijpe.2015.09.011
UR  - https://www.sciencedirect.com/science/article/pii/S0925527315003382
KW  - Forecasting
KW  - Temporal aggregation
KW  - MAPA
KW  - Exponential smoothing
KW  - Promotional modelling
AB  - Demand forecasting is central to decision making and operations in organisations. As the volume of forecasts increases, for example due to an increased product customisation that leads to more SKUs being traded, or a reduction in the length of the forecasting cycle, there is a pressing need for reliable automated forecasting. Conventionally, companies rely on a statistical baseline forecast that captures only past demand patterns, which is subsequently adjusted by human experts to incorporate additional information such as promotions. Although there is evidence that such process adds value to forecasting, it is questionable how much it can scale up, due to the human element. Instead, in the literature it has been proposed to enhance the baseline forecasts with external well-structured information, such as the promotional plan of the company, and let experts focus on the less structured information, thus reducing their workload and allowing them to focus where they can add most value. This change in forecasting support systems requires reliable multivariate forecasting models that can be automated, accurate and robust. This paper proposes an extension of the recently proposed Multiple Aggregation Prediction Algorithm (MAPA), which uses temporal aggregation to improve upon the established exponential smoothing family of methods. MAPA is attractive as it has been found to increase both the accuracy and robustness of exponential smoothing. The extended multivariate MAPA is evaluated against established benchmarks in modelling a number of heavily promoted products and is found to perform well in terms of forecast bias and accuracy. Furthermore, we demonstrate that modelling time series using multiple temporal aggregation levels makes the final forecast robust to model mis-specification.
ER  - 

TY  - JOUR
T1  - Hot-N-Cold model for energy aware cloud databases
AU  - Guo, Chaopeng
AU  - Pierson, Jean-Marc
AU  - Song, Jie
AU  - Herzog, Christina
JO  - Journal of Parallel and Distributed Computing
VL  - 123
SP  - 130
EP  - 144
PY  - 2019
DA  - 2019/01/01/
SN  - 0743-7315
DO  - https://doi.org/10.1016/j.jpdc.2018.09.012
UR  - https://www.sciencedirect.com/science/article/pii/S0743731518306919
KW  - Energy efficiency
KW  - Hot-N-Cold
KW  - DVFS
KW  - Cloud database
KW  - Bounded problem
AB  - A lot of cloud computing and cloud database techniques are adopted in industry and academia to face the explosion of the arrival of the big data era. Meanwhile, energy efficiency and energy saving become a major concern in data centers, which are in charge of large distributed systems and cloud databases. However, the phenomenon of energy wasting is related to resource provisioning. Hot-N-Cold model is introduced in this paper, which uses workload predictions and DVFS(Dynamic Voltage and Frequency Scaling) to cope with the resource provisioning problem within energy aware cloud database systems. In this model, the resource provisioning problem is considered as two bounded problems. A nonlinear programming algorithm and a multi-phase algorithm are proposed to solve them. The experimental results show that one of the proposed algorithms has great scalability which can be applied to a cloud database system deployed on 70 nodes. Using Hot-N-Cold model can save up to 21.5% of the energy of the running time.
ER  - 

TY  - JOUR
T1  - Comparison of three different techniques for camera and motion control of a teleoperated robot
AU  - Doisy, Guillaume
AU  - Ronen, Adi
AU  - Edan, Yael
JO  - Applied Ergonomics
VL  - 58
SP  - 527
EP  - 534
PY  - 2017
DA  - 2017/01/01/
SN  - 0003-6870
DO  - https://doi.org/10.1016/j.apergo.2016.05.001
UR  - https://www.sciencedirect.com/science/article/pii/S0003687016300886
KW  - Teleoperation
KW  - Human factors
KW  - Interface design
AB  - This research aims to evaluate new methods for robot motion control and camera orientation control through the operator's head orientation in robot teleoperation tasks. Specifically, the use of head-tracking in a non-invasive way, without immersive virtual reality devices was combined and compared with classical control modes for robot movements and camera control. Three control conditions were tested: 1) a condition with classical joystick control of both the movements of the robot and the robot camera, 2) a condition where the robot movements were controlled by a joystick and the robot camera was controlled by the user head orientation, and 3) a condition where the movements of the robot were controlled by hand gestures and the robot camera was controlled by the user head orientation. Performance, workload metrics and their evolution as the participants gained experience with the system were evaluated in a series of experiments: for each participant, the metrics were recorded during four successive similar trials. Results shows that the concept of robot camera control by user head orientation has the potential of improving the intuitiveness of robot teleoperation interfaces, specifically for novice users. However, more development is needed to reach a margin of progression comparable to a classical joystick interface.
ER  - 

TY  - JOUR
T1  - How much is too much on monitoring tasks? Visual scan patterns of single air traffic controller performing multiple remote tower operations
AU  - Li, Wen-Chin
AU  - Kearney, Peter
AU  - Braithwaite, Graham
AU  - Lin, John J.H.
JO  - International Journal of Industrial Ergonomics
VL  - 67
SP  - 135
EP  - 144
PY  - 2018
DA  - 2018/09/01/
SN  - 0169-8141
DO  - https://doi.org/10.1016/j.ergon.2018.05.005
UR  - https://www.sciencedirect.com/science/article/pii/S0169814118301288
KW  - Air traffic management
KW  - Aviation safety
KW  - Cost-efficiency
KW  - Human-computer interactions
KW  - Multiple remote tower operations
KW  - Situation awareness
AB  - The innovative concept of multiple remote tower operation (MRTO) is where a single air traffic controller (ATCO) provides air traffic services to two or more different airports from a geographically separated virtual Tower. Effective visual scanning by the air traffic controller is the main safety concern for human-computer interaction, as the aim of MRTO is a single controller performing air traffic management tasks originally carried out by up to four ATCOs, comprehensively supported by innovative technology. Thirty-two scenarios were recorded and analyzed using an eye tracking device to investigate the above safety concern and the effectiveness of multiple remote tower operations. The results demonstrated that ATCOs' visual scan patterns showed significant task related variation while performing different tasks and interacting with various interfaces on the controller's working position (CWP). ATCOs were supported by new display systems equipped with pan tilt zoom (PTZ) cameras allowing enhanced visual checking of airport surfaces and aircraft positions. Therefore, one ATCO could monitor and provide services for two airports simultaneously. The factors influencing visual attention include how the information is presented, the complexity of that information, and the characteristics of the operating environment. ATCO's attention distribution among display systems is the key human-computer interaction issue in single ATCO performing multiple monitoring tasks.
ER  - 

TY  - JOUR
T1  - Energy Efficient Data Transmission in IoT Platforms
AU  - Izaddoost, Alireza
AU  - Siewierski, Matthew
JO  - Procedia Computer Science
VL  - 175
SP  - 387
EP  - 394
PY  - 2020
DA  - 2020/01/01/
T2  - The 17th International Conference on Mobile Systems and Pervasive Computing (MobiSPC),The 15th International Conference on Future Networks and Communications (FNC),The 10th International Conference on Sustainable Energy Information Technology
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2020.07.055
UR  - https://www.sciencedirect.com/science/article/pii/S1877050920317361
KW  - energy efficient
KW  - Internet of Things(IoT)
KW  - residual energy
KW  - data transmission
AB  - Internet of Things (IoT) as an emerging technology is of interest to academia and industry. An IoT node is a small device and the supplied power is usually provided by batteries. The collected data by IoT nodes will be transferred to a gateway server which may aggregate data and send it to a cloud platform for further data processing. When IoT nodes distribute through a vast area, nodes located far away from the gateway server will need to transfer data through multi-hops to the gateway server. To have a better power consumption and increase node operational time, next forwarding node can be selected with the highest power level among several candidate nodes. In this paper we propose a data transmission model, and develop a next node selection forwarding factor to balance data transmission throughout the network. The proposed model will consider workload in addition to the available power level to select the next forwarding node. Our simulation results show the selected next forwarding node will operate for a longer time even it has a lower power level compared to the other candidate nodes. This improvement may increase network stability and decrease the number of lost packets during the data transmission.
ER  - 

TY  - JOUR
T1  - Satellite IoT Based Road Extraction from VHR Images Through Superpixel-CNN Architecture
AU  - Behera, Tanmay Kumar
AU  - Sa, Pankaj Kumar
AU  - Nappi, Michele
AU  - Bakshi, Sambit
JO  - Big Data Research
VL  - 30
SP  - 100334
PY  - 2022
DA  - 2022/11/28/
SN  - 2214-5796
DO  - https://doi.org/10.1016/j.bdr.2022.100334
UR  - https://www.sciencedirect.com/science/article/pii/S2214579622000284
KW  - IoT
KW  - Big Data
KW  - Deep Learning
KW  - SLIC Superpixel
KW  - CNN
KW  - Remote Sensing
KW  - Road extraction
AB  - In the past few decades, technology has progressively become ineluctable in human lives, primarily due to the growth of certain fields like space technology, Big Data, the Internet of Things (IoT), and machine learning. Space technology has revolutionized communication mechanisms while creating opportunities for various research areas, including remote sensing (RS)-inspired applications. On the other hand, IoT presents a platform to use the power of the internet over a whole range of devices through a phenomenon known as social IoT. These devices generate a humongous amount of data that requires handling and managing by big data technology incorporated with deep learning techniques to reduce the manual workload of an operator. Moreover, deep learning architectures like convolutional neural networks (CNNs) have presented a scope to extract the underlying features from the large-scale input images in providing better solutions for tasks such as automatic road detection that come at the cost of time and memory overhead. In this context, we have proposed a three-layer edge-fog-cloud-based intelligent satellite IoT architecture that uses the superpixel-based CNN approach. At the fog layer, the superpixel-based simple linear iterative cluster (SLIC) algorithm uses the images captured by the satellites of the edge level to produce the smaller-sized superpixel images that can be transferred even in a low bandwidth link. The CNN module at the cloud level is then trained with these superpixel images to predict the road networks from these RS images. Two popular road datasets: the DeepGlobe Road dataset and the Massachusetts Road dataset, have been considered to prove the usefulness of the proposed SLIC-CNN architecture in satellite-based IoT platforms to address the problems like RS image-based road extraction. The proposed architecture achieves better performance accuracy than the classical CNN while reducing the incurred overhead by a noticeable limit.
ER  - 

TY  - JOUR
T1  - COVID-DSNet: A novel deep convolutional neural network for detection of coronavirus (SARS-CoV-2) cases from CT and Chest X-Ray images
AU  - Reis, Hatice Catal
AU  - Turk, Veysel
JO  - Artificial Intelligence in Medicine
VL  - 134
SP  - 102427
PY  - 2022
DA  - 2022/12/01/
SN  - 0933-3657
DO  - https://doi.org/10.1016/j.artmed.2022.102427
UR  - https://www.sciencedirect.com/science/article/pii/S0933365722001798
KW  - Chest CT-scan images
KW  - Chest X-ray images
KW  - COVID-DSNet
KW  - Depthwise separable convolution
KW  - SARS-CoV-2
AB  - COVID-19 (SARS-CoV-2), which causes acute respiratory syndrome, is a contagious and deadly disease that has devastating effects on society and human life. COVID-19 can cause serious complications, especially in patients with pre-existing chronic health problems such as diabetes, hypertension, lung cancer, weakened immune systems, and the elderly. The most critical step in the fight against COVID-19 is the rapid diagnosis of infected patients. Computed Tomography (CT), chest X-ray (CXR), and RT-PCR diagnostic kits are frequently used to diagnose the disease. However, due to difficulties such as the inadequacy of RT-PCR test kits and false negative (FN) results in the early stages of the disease, the time-consuming examination of medical images obtained from CT and CXR imaging techniques by specialists/doctors, and the increasing workload on specialists, it is challenging to detect COVID-19. Therefore, researchers have suggested searching for new methods in COVID- 19 detection. In analysis studies with CT and CXR radiography images, it was determined that COVID-19-infected patients experienced abnormalities related to COVID-19. The anomalies observed here are the primary motivation for artificial intelligence researchers to develop COVID-19 detection applications with deep convolutional neural networks. Here, convolutional neural network-based deep learning algorithms from artificial intelligence technologies with high discrimination capabilities can be considered as an alternative approach in the disease detection process. This study proposes a deep convolutional neural network, COVID-DSNet, to diagnose typical pneumonia (bacterial, viral) and COVID-19 diseases from CT, CXR, hybrid CT + CXR images. In the multi-classification study with the CT dataset, 97.60 % accuracy and 97.60 % sensitivity values were obtained from the COVID-DSNet model, and 100 %, 96.30 %, and 96.58 % sensitivity values were obtained in the detection of typical, common pneumonia and COVID-19, respectively. The proposed model is an economical, practical deep learning network that data scientists can benefit from and develop. Although it is not a definitive solution in disease diagnosis, it may help experts as it produces successful results in detecting pneumonia and COVID-19.
ER  - 

TY  - JOUR
T1  - Ensuring renewable energy utilization with quality of service guarantee for energy-efficient data center operations
AU  - Kwon, Soongeol
JO  - Applied Energy
VL  - 276
SP  - 115424
PY  - 2020
DA  - 2020/10/15/
SN  - 0306-2619
DO  - https://doi.org/10.1016/j.apenergy.2020.115424
UR  - https://www.sciencedirect.com/science/article/pii/S0306261920309363
KW  - Data centers
KW  - Renewable energy
KW  - Quality of service
KW  - Two-stage stochastic program
KW  - Chance constraint
KW  - Expected-value constraint
AB  - The reduction of greenhouse emissions is becoming a major goal of energy-intensive industries, such as data centers, and there have been significant efforts to achieve sustainable operations by meeting electricity consumption using renewable energy generations. Specifically, it has been a common practice for data centers to use renewable energy via on-site solar power generation to directly offset electricity consumption by renewable energy to contribute to environmental sustainability. However, the introduction of intermittent and non-dispatchable renewable energy generations for powering data centers that generally host time-varying workloads presents a significant challenge, and thus, this study mainly focuses on how to improve renewable energy utilization for data center operations considering the integration of co-located solar power generation and battery energy storage. The main objective is to develop a mathematical optimization model for energy-efficient and sustainable data center operations to minimize energy cost while ensuring the desired level of renewable energy utilization and the required quality of service guarantee. In particular, this study proposes a two-stage stochastic program integrated with an expected-value constraint and a chance constraint, and an integer programming and sampling-based approach are adopted to solve the problem to investigate optimal data center operations. The comprehensive numerical experiments are conducted to evaluate the proposed model compared with benchmark models for various parameter settings, and the results show that the proposed model can be successfully implemented to enable data centers to achieve the desired renewable energy utilization while improving energy efficiency.
ER  - 

TY  - JOUR
T1  - Kinematic and EMG analysis of horizontal bimanual climbing in humans
AU  - MacLean, Kathleen F.E.
AU  - Dickerson, Clark R.
JO  - Journal of Biomechanics
VL  - 92
SP  - 11
EP  - 18
PY  - 2019
DA  - 2019/07/19/
SN  - 0021-9290
DO  - https://doi.org/10.1016/j.jbiomech.2019.05.023
UR  - https://www.sciencedirect.com/science/article/pii/S0021929019303550
KW  - Climbing
KW  - Shoulder biomechanics
KW  - Kinematics
KW  - EMG
KW  - Evolutionary biomechanics
AB  - Climbing is an increasingly popular recreational and competitive behavior, engaged in a variety of environments and styles. However, injury rates are high in climbing populations, especially in the upper extremity and shoulder. Despite likely arising from an arboreal, climbing ancestor and being closely related to primates that are highly proficient climbers, the modern human shoulder has devolved a capacity for climbing. Limited biomechanical research exists on manual climbing performance. This study assessed kinematic and muscular demands during a bimanual climbing task that mimicked previous work on climbing primates. Thirty participants were recruited – 15 experienced and 15 inexperienced climbers. Motion capture and electromyography (EMG) measured elbow, thoracohumeral and trunk angles, and activity of twelve shoulder muscles, respectively, of the right-side while participants traversed across a horizontal climbing apparatus. Statistical parametric mapping was used to detect differences between groups in kinematics and muscle activity. Experienced climbers presented different joint motions that more closely mimicked the kinematics of climbing primates, including more elbow flexion (p = 0.0045) and internal rotation (p = 0.021), and less thoracohumeral elevation (p = 0.046). Similarly, like climbing primates, experienced climbers generally activated the shoulder musculature at a lower percentage of maximum, particularly during the exchange from support to swing and swing to support phase. However, high muscle activity was recorded in all muscles in both participant groups. Climbing experience coincided with a positive training effect, but not enough to overcome the high muscular workload of bimanual climbing. Owing to the evolved primary usage of the upper extremity for low-force, below shoulder-height tasks, bimanual climbing may induce high risk of fatigue-related musculoskeletal disorders.
ER  - 

TY  - JOUR
T1  - Heart rate modeling and prediction of construction workers based on physical activity using deep learning
AU  - Ghafoori, Mahdi
AU  - Clevenger, Caroline
AU  - Abdallah, Moatassem
AU  - Rens, Kevin
JO  - Automation in Construction
VL  - 155
SP  - 105077
PY  - 2023
DA  - 2023/11/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2023.105077
UR  - https://www.sciencedirect.com/science/article/pii/S0926580523003370
KW  - Heart rate modeling
KW  - Wearable sensing
KW  - Construction safety
KW  - Physiological monitoring
KW  - Deep learning
AB  - Construction projects require long working hours where workers are subjected to intensive tasks such as hard manual labor, heavy weightlifting, and compulsive working postures. Among the physiological metrics, Heart Rate (HR) is reported to be a good indicator of physical stress and workload. HR forecasting models have been used in various areas including cardiopathy research, heart attack warning indicator, and early physical fatigue detection. However, there are no reported studies on HR modeling and forecasting in the construction field. Modeling and forecasting the HR of construction workers using construction field data is of paramount importance due to the direct relationship between activity level and HR. The objective of this study is to (1) analyze the effect of physiological factors including breathing rate, acceleration of torso movements, torso posture, and impulse load on the HR of construction workers, and (2) model and forecast one-minute ahead HR for construction workers based on their physical activity using deep learning algorithms. To this end, physiological metrics of five bridge maintenance workers performing several construction activities were collected. According to the Pearson correlation and entropy based mutual information analysis, time-lagged variables including acceleration of torso movements, torso posture, and impulse load have significant effect on the HR data. The results of deep learning models indicate that Long Short-Term Memory Network (LSTM), Bidirectional LSTM (BiLSTM), Gated Recurrent Unit (GRU), and Bidirectional GRU (BiGRU) have similar predictive performance. However, LSTM had the best overall performance in HR prediction with Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE) of 5.4, 7.34, and 5.77%, respectively. These models have the potential to facilitate the mitigation of cardiovascular strain and enable proactive prevention of accidents in the construction industry.
ER  - 

TY  - JOUR
T1  - Multinode implementation of an extended Hodgkin–Huxley simulator
AU  - Chatzikonstantis, G.
AU  - Sidiropoulos, H.
AU  - Strydis, C.
AU  - Negrello, M.
AU  - Smaragdos, G.
AU  - De Zeeuw, C.I.
AU  - Soudris, D.J.
JO  - Neurocomputing
VL  - 329
SP  - 370
EP  - 383
PY  - 2019
DA  - 2019/02/15/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2018.10.062
UR  - https://www.sciencedirect.com/science/article/pii/S0925231218312906
KW  - Computational neuroscience
KW  - Intel Xeon Phi Knights Landing
KW  - Simulation
KW  - Multinode
AB  - Mathematical models with varying degrees of complexity have been proposed and simulated in an attempt to represent the intricate mechanisms of the human neuron. One of the most biochemically realistic and analytical models, based on the Hodgkin–Huxley (HH) model, has been selected for study in this paper. In order to satisfy the model’s computational demands, we present a simulator implemented on Intel Xeon Phi Knights Landing manycore processors. This high-performance platform features an x86-based architecture, allowing our implementation to be portable to other common manycore processing machines. This is reinforced by the fact that Phi adopts the popular OpenMP and MPI programming models. The simulator performance is evaluated when calculating neuronal networks of varying sizes, density and network connectivity maps. The evaluation leads to an analysis of the neuronal synaptic patterns and their impact on performance when tackling this type of workload on a multinode system. It will be shown that the simulator can calculate 100 ms of simulated brain activity for up to 2 millions of biophysically-accurate neurons and 2 billion neuronal synapses within one minute of execution time. This level of performance renders the application an efficient solution for large-scale detailed model simulation.
ER  - 
