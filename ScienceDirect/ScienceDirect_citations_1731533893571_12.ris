TY  - JOUR
T1  - An improved stability lobe and turning chatter characteristic investigation
AU  - Qiu, Jian
AU  - Ge, Renpeng
JO  - International Journal of Mechanical Sciences
VL  - 149
SP  - 338
EP  - 348
PY  - 2018
DA  - 2018/12/01/
SN  - 0020-7403
DO  - https://doi.org/10.1016/j.ijmecsci.2018.10.006
UR  - https://www.sciencedirect.com/science/article/pii/S0020740318318290
KW  - Chatter characteristic
KW  - Chatter prediction
KW  - Surface identification
KW  - Variable spindle speed turning
KW  - Width-distance lobe
AB  - A quick chatter identification method using continuous variable speed programing was proposed to solve radial turning chatter. A width-distance lobe (b-d lobe) was presented to improve width-speed lobe (b-n lobe) for turning chatter prediction. The turning dynamic model for chatter prediction considering modal parameters of tool system and workpiece system, tool angles and modal angles was established. And the model verification was carried out by the combination of improved chatter lobe with surface contour, which showed that the improved chatter stability lobe can well corresponds to the machined surface. On this basis, the mechanism of surface formation of turning chatter were analyzed. In addition, the advantages of the improved b-d lobe were discussed compared with the previous b-n lobe no matter in workload, difficulty, skill requirements and time consumption. And, the method was verified useful by an application example of brake disc processing in automotive industry. Another finding is the chatter direction of the radial turning which is expressed by mathematical models of chatter angles.
ER  - 

TY  - JOUR
T1  - Experimental and numerical analysis for potential heat reuse in liquid cooled data centres
AU  - Carbó, Andreu
AU  - Oró, Eduard
AU  - Salom, Jaume
AU  - Canuto, Mauro
AU  - Macías, Mario
AU  - Guitart, Jordi
JO  - Energy Conversion and Management
VL  - 112
SP  - 135
EP  - 145
PY  - 2016
DA  - 2016/03/15/
SN  - 0196-8904
DO  - https://doi.org/10.1016/j.enconman.2016.01.003
UR  - https://www.sciencedirect.com/science/article/pii/S0196890416000194
KW  - Data centre
KW  - Liquid cooling
KW  - IT load
KW  - Experimentation
KW  - Numerical modelling
AB  - The rapid increase of data centre industry has stimulated the interest of both researchers and professionals in order to reduce energy consumption and carbon footprint of these unique infrastructures. The implementation of energy efficiency strategies and the use of renewables play an important role to reduce the overall data centre energy demand. Information Technology (IT) equipment produce vast amount of heat which must be removed and therefore waste heat recovery is a likely energy efficiency strategy to be studied in detail. To evaluate the potential of heat reuse a unique liquid cooled data centre test bench was designed and built. An extensive thermal characterization under different scenarios was performed. The effective liquid cooling capacity is affected by the inlet water temperature. The lower the inlet water temperature the higher the liquid cooling capacity; however, the outlet water temperature will be also low. Therefore, the requirements of the heat reuse application play an important role in the optimization of the cooling configuration. The experimental data was then used to validate a dynamic energy model developed in TRNSYS. This model is able to predict the behaviour of liquid cooling data centres and can be used to study the potential compatibility between large data centres with different heat reuse applications. The model also incorporates normalized power consumption profiles for heterogeneous workloads that have been derived from realistic IT loads.
ER  - 

TY  - JOUR
T1  - Burnout Evaluation and Potential Predictors in a Greek Cohort of Mental Health Nurses
AU  - Konstantinou, Adamos-Konstantinos
AU  - Bonotis, Konstantinos
AU  - Sokratous, Maria
AU  - Siokas, Vasileios
AU  - Dardiotis, Efthimios
JO  - Archives of Psychiatric Nursing
VL  - 32
IS  - 3
SP  - 449
EP  - 456
PY  - 2018
DA  - 2018/06/01/
SN  - 0883-9417
DO  - https://doi.org/10.1016/j.apnu.2018.01.002
UR  - https://www.sciencedirect.com/science/article/pii/S0883941716303740
KW  - Burnout
KW  - Job satisfaction
KW  - Organizational commitment
KW  - Role conflict
KW  - Role ambiguity
AB  - Background
Job burnout is one of the most serious occupational health hazards, especially, among mental health nurses. It has been attributed among others to staff shortages, health service changes, poor morale and insufficient employee participation in decision-making.
Aim
The aim of this study was to measure burnout among mental health nurses, investigate relations between burnout and organizational factors and examine potential predictors of nurses' burnout. Specifically, this study aimed to investigate whether role conflict, role ambiguity, organizational commitment and subsequent job satisfaction could predict each of the three dimensions of burnout.
Design/methodology/approach
During current cross sectional, the survey was administered to 232 mental health nurses, employed in four private psychiatric clinics in the region of Larissa, Thessaly, Greece in May 2015. Our findings were based on the responses to 78 usable questionnaires. Different statistical analyses, such as correlation analyses, regression analyses and analyses of variance were performed in order to explore possible relations.
Findings
High emotional exhaustion (EE) accounted for 53.8% of the sample, while high depersonalization (DP) and high personal accomplishment (PA) accounted for 24.4% and 25.6%, respectively. The best predictors of burnout were found to be role conflict, satisfaction with workload, satisfaction with training, role ambiguity, satisfaction with pay and presence of serious family issues.
Practical implications
These findings have implications for organizational and individual interventions, indicating that mental health nurses' burnout could be reduced, or even prevented by team building strategies, training, application of operation management, clear instructions and psychological support.
ER  - 

TY  - JOUR
T1  - RECALSEEN. Subgroup: Patient care in the clinical nutrition units of the Spanish National Health System
AU  - Cancer Minchot, Emilia
AU  - Elola Somoza, Francisco Javier
AU  - Fernández Pérez, Cristina
AU  - Bernal Sobrino, José Luis
AU  - Bretón Lesmes, Irene
AU  - Botella Romero, Francisco
JO  - Endocrinología, Diabetes y Nutrición (English ed.)
VL  - 68
IS  - 5
SP  - 354
EP  - 362
PY  - 2021
DA  - 2021/05/01/
SN  - 2530-0180
DO  - https://doi.org/10.1016/j.endien.2021.08.002
UR  - https://www.sciencedirect.com/science/article/pii/S2530018021000664
KW  - Clinical nutrition
KW  - Organizational structure
KW  - Endocrinology
KW  - Nutrición clínica
KW  - Estructura organizativa
KW  - Endocrinología
AB  - Introduction
Artificial nutrition (AI) is one of the most representative examples of coordinated therapeutic programs, and therefore requires adequate development and organization. The first clinical nutrition units (CNUs) emerged in the public hospitals of the Spanish National Health System (NHS) in the 80s and have gradually been incorporated into the departments of endocrinology and nutrition (DENs). The purpose of our article is to report on the results found in the RECALSEEN study as regards the professional and organizational aspects relating to CNUs and their structure and operation.
Materials and methods
Data were collected from the RECALSEEN study, a cross-sectional, descriptive study of the DENs in the Spanish NHS in 2016. The survey was compiled from March to September 2017. Qualitative variables were reported as frequency distributions (number of cases and percentages), and quantitative variables as the mean, median, and standard deviation (SD).
Results
A total of 88 (70%) DENs, out of a total of 125 general acute hospitals of the NHS with 200 or more installed beds, completed the survey. CNUs were available in 83% of DENs (98% in hospitals with 500 or more beds). As a median, DENs had one nurse dedicated to nutrition (35% did not have this resource). Fifty-three percent of DENs with nutrition units had dieticians integrated into the unit (median: 1). DENs located in hospitals with 500 or more beds are more complex and have a wide portfolio of monographic unit services (morbid obesity, 78.3%; artificial home nutrition, 87%; chronic diseases, 65.2%) and specific techniques (impedanciometry, 78%). However, only 14% of the centers perform universal screening tests for malnutrition, and a secondary diagnosis of malnutrition only appears in 12.3 reports per 1000 hospital discharges.
Discussion
After the 1997 and 2003 studies, the results of 2017 show a marked growth and consolidation of CNUs within the DENs in most hospitals. Today, the growth of this specialty is largely due to the care demand created by hospital clinical nutrition. CNUs still have an insufficient nursing staff and dietitians/nutritionists, and in the latter case, atypical contracts or grants funded by research projects or the pharmaceutical industry are common. Units for specific nutritional diseases and participation in multidisciplinary groups, quite heterogeneous, are concentrated in hospitals with 500 or more beds and represent an excellent opportunity for CNU development.
Conclusions
Many DENs of Spanish hospitals include CNUs where care is provided by endocrinologists, who devote most of their time to clinical nutrition in more than half of the hospitals. This is most common in large centers with a high workload in relation to staffing. There is considerable heterogeneity between hospitals in terms of both the number and type of activity of the CNUs.
Resumen
Introducción
La nutrición artificial (NA) es uno de los ejemplos más representativos de programas terapéuticos coordinados, lo que hace necesario su desarrollo y adecuada organización. Las primeras Unidades de Nutrición Clínica (UNC) surgen en los hospitales públicos del Sistema Nacional de Salud (SNS) en la década de 1980–1990 y se han ido incorporando progresivamente a los Servicios de Endocrinología y Nutrición (SªEyN). El objeto de nuestro artículo es exponer los resultados obtenidos del estudio RECALSEEN sobre los aspectos profesionales y organizativos relacionados con las UNC, su estructura y funcionamiento.
Material y métodos
Los datos se han obtenido del estudio RECALSEEN, que es un descriptivo transversal entre los SºEyN del SNS español referido a 2016. La encuesta se recogió de marzo a septiembre de 2017. Las variables cualitativas se describen con su distribución de frecuencias (número de casos y porcentajes) y las variables de cuantitativas con la media, mediana y desviación estándar.
Resultados
Se han obtenido 88 (70%) respuestas de SºEyN sobre un total de 125 hospitales generales de agudos del SNS con igual o más de 200 camas instaladas. El 83% de Sº EyN incorporaban una UNC (98% en los hospitales de 500 o más camas). Como mediana, los Sº EyN tienen 1 enfermera dedicada a Nutrición (35% no disponían de este recurso). El 53% de Sº EyN con Unidad de Nutrición tenían dietistas integrados en la unidad (mediana: 1). Los Sº EyN situadas en hospitales de 500 o más camas tienen una mayor complejidad con una amplia cartera de servicios de unidades monográficas (obesidad mórbida —78,3%—, nutrición artificial domiciliaria —87%—, enfermedades crónicas —65,2%—) y de técnicas específicas (impedanciometría —78%—). Sin embargo, sólo se realiza un test de cribado universal de desnutrición en el 14% de los centros y, el diagnóstico secundario de desnutrición, únicamente aparece en 12,3 informes por cada 1.000 altas hospitalarias.
Discusión
Tras los estudios de 1997 y 2003, los resultados de 2017 arrojan un notable crecimiento y consolidación de las UNC dentro de los SºEyN de la mayoría de los hospitales. Actualmente, el crecimiento de la especialidad pasa en buena medida por la demanda asistencial que crea la Nutrición Clínica hospitalaria. La dotación de personal de enfermería y de dietistas-nutricionistas en las UNC sigue siendo insuficiente y, en este último caso, son frecuentes los contratos atípicos, o becas financiadas por proyectos de investigación o por la industria farmacéutica. La presencia de unidades para patologías nutricionales específicas y la participación en grupos multidisciplinares, bastante heterogénea, se concentra en hospitales de 500 o más camas y constituye una excelente oportunidad de desarrollo para las UNC.
Conclusiones
La incorporación de UNC en los S◦EyN es amplia en los hospitales de España, y la asistencia se realiza por endocrinólogos que dedican la mayor parte de su tiempo a la nutrición clínica en más de la mitad de los hospitales. Esta circunstancia es más común en centros grandes, con elevadas cargas de trabajo en relación con las dotaciones de personal. Se observa una considerable heterogeneidad entre los hospitales, tanto en términos de número como de tipo de actividad de las UNC.
ER  - 

TY  - JOUR
T1  - De novo discovery of metabolic heterogeneity with immunophenotype-guided imaging mass spectrometry
AU  - Prade, Verena M.
AU  - Kunzke, Thomas
AU  - Feuchtinger, Annette
AU  - Rohm, Maria
AU  - Luber, Birgit
AU  - Lordick, Florian
AU  - Buck, Achim
AU  - Walch, Axel
JO  - Molecular Metabolism
VL  - 36
SP  - 100953
PY  - 2020
DA  - 2020/06/01/
SN  - 2212-8778
DO  - https://doi.org/10.1016/j.molmet.2020.01.017
UR  - https://www.sciencedirect.com/science/article/pii/S2212877820300259
KW  - Imaging mass spectrometry
KW  - Multiplex immunohistochemistry
KW  -  metabolomics
KW  - Tissue annotation
KW  - Pixel-accurate analysis
AB  - Background
Imaging mass spectrometry enables in situ label-free detection of thousands of metabolites from intact tissue samples. However, automated steps for multi-omics analyses and interpretation of histological images have not yet been implemented in mass spectrometry data analysis workflows. The characterization of molecular properties within cellular and histological features is done via time-consuming, non-objective, and irreproducible definitions of regions of interest, which are often accompanied by a loss of spatial resolution due to mass spectra averaging. Methods: We developed a new imaging pipeline called Spatial Correlation Image Analysis (SPACiAL), which is a computational multimodal workflow designed to combine molecular imaging data with multiplex immunohistochemistry (IHC). SPACiAL allows comprehensive and spatially resolved in situ correlation analyses on a cellular resolution. To demonstrate the method, matrix-assisted laser desorption-ionization (MALDI) Fourier-transform ion cyclotron resonance (FTICR) imaging mass spectrometry of metabolites and multiplex IHC staining were performed on the very same tissue section of mouse pancreatic islets and on human gastric cancer tissue specimens. The SPACiAL pipeline was used to perform an automatic, semantic-based, functional tissue annotation of histological and cellular features to identify metabolic profiles. Spatial correlation networks were generated to analyze metabolic heterogeneity associated with cellular features. Results: To demonstrate the new method, the SPACiAL pipeline was used to identify metabolic signatures of alpha and beta cells within islets of Langerhans, which are cell types that are not distinguishable via morphology alone. The semantic-based, functional tissue annotation allows an unprecedented analysis of metabolic heterogeneity via the generation of spatial correlation networks. Additionally, we demonstrated intra- and intertumoral metabolic heterogeneity within HER2/neu-positive and -negative gastric tumor cells. Conclusions: We developed the SPACiAL workflow to provide IHC-guided in situ metabolomics on intact tissue sections. Diminishing the workload by automated recognition of histological and functional features, the pipeline allows comprehensive analyses of metabolic heterogeneity. The multimodality of immunohistochemical staining and extensive molecular information from imaging mass spectrometry has the advantage of increasing both the efficiency and precision for spatially resolved analyses of specific cell types. The SPACiAL method is a stepping stone for the objective analysis of high-throughput, multi-omics data from clinical research and practice that is required for diagnostics, biomarker discovery, or therapy response prediction.
ER  - 

TY  - JOUR
T1  - Wristband-type wearable health devices to measure construction workers' physical demands
AU  - Hwang, Sungjoo
AU  - Lee, SangHyun
JO  - Automation in Construction
VL  - 83
SP  - 330
EP  - 340
PY  - 2017
DA  - 2017/11/01/
SN  - 0926-5805
DO  - https://doi.org/10.1016/j.autcon.2017.06.003
UR  - https://www.sciencedirect.com/science/article/pii/S0926580517305010
KW  - Physical demands
KW  - Occupational health and safety
KW  - Wearable devices
KW  - Heart rate reserve
KW  - Activity analysis
KW  - Work physiology
AB  - Recent advancements in wearable health devices equipped with biosensor systems (e.g., heart rate (HR) sensor) have provided an ample opportunity to continuously measure and understand workers' physical demands from construction work. Specifically, a relative measurement of physical demands, which is a percentage of HR reserve (%HRR), is convenient and useful by normalizing individual differences of HR. Since affordable HR monitoring using wearable devices (particularly, a comfortable wristband-type device: wristband hereafter) becomes available, %HRR-based physical demand measurement, which can be continuously calculated without interfering with workers' ongoing work, provides an enormous potential to protect workers' safety and health and to sustain expected productivity. This research investigates the usefulness of affordable %HRR-based physical demand measurement using a wristband from a case study of 19 workers in construction sites. The aim of the analysis is to examine the potential of this continuous measurement in capturing any significant physical demand variations, by investigating in-depth information on factors affecting physical demands (e.g., work tasks, individual and environmental factors). The results show that workers' physical demands are highly variable according to their working patterns (i.e., direct work, and indirect work including tool/equipment/material handling, traveling, and preparatory work), combined influences of work tasks, as well as individual and environmental factors (e.g., age and heat stress). These results demonstrate the need for continuous physical measurement during workers' ongoing work so that any significant high physical demands, which need to be avoided if possible, can be captured. The findings of this paper show that the continuous measurement of physical demands using a wristband provides rich information to understand, manage, and design physically demanding construction work (e.g., flexible work-rest cycle and managing demanding indirect work) by balancing workloads throughout a day and/or reducing unnecessary physical demands beyond direct work. By anticipating potential health and safety problems from excessive physical demands, as well as productivity loss before they occur, this research will have an ameliorative impact across the construction industry.
ER  - 

TY  - JOUR
T1  - A data-driven method to detect adverse drug events from prescription data
AU  - Zhan, Chen
AU  - Roughead, Elizabeth
AU  - Liu, Lin
AU  - Pratt, Nicole
AU  - Li, Jiuyong
JO  - Journal of Biomedical Informatics
VL  - 85
SP  - 10
EP  - 20
PY  - 2018
DA  - 2018/09/01/
SN  - 1532-0464
DO  - https://doi.org/10.1016/j.jbi.2018.07.013
UR  - https://www.sciencedirect.com/science/article/pii/S1532046418301394
KW  - Adverse Drug Events (ADEs)
KW  - Prescription data
KW  - Sequential pattern mining
KW  - Self-Controlled Case Series (SCCS)
KW  - 00-01
KW  - 99-00
AB  - Drug safety issues such as Adverse Drug Events (ADEs) can cause serious consequences for the public. The clinical trials that are undertaken to assess medicine efficacy and safety prior to marketing, generally, may provide sufficient samples for discovering common ADEs. However, more samples are needed to detect infrequent and rare events. Additionally, clinical trials may not include all subgroups of patients. For these reasons, post-marketing surveillance of medicines is necessary for identifying drug safety issues. Most regulatory agencies use the Spontaneous Reporting Systems to identify associations between medicines and suspected ADEs. Data mining with effective analytical frameworks and large-scale medical data is potentially an alternative method to discover and monitor ADEs. In the present paper, we aim to detect potential ADEs from prescription data by discovering ADE associated prescription sequences. In an ADE associated prescription sequence 〈Dp→Ds〉, the prior medicine Dp leads to an ADE for which the succeeding medicine Ds is dispensed to treat. We propose a data-driven method which integrates (1) a constrained sequential pattern mining to uncover prescription sequences as potential signals of ADEs, (2) domain constraints to eliminate interference signals and (3) an adapted Self-Controlled Case Series model to evaluate the potential signals of ADEs. Despite ample prior works using Electronic Health Records (EHRs), our method utilises pure prescription data which does not contain additional information, e.g. symptoms or diagnoses as included in EHRs. To assess the performance of the proposed method, we apply it to a real-world dataset from the Pharmaceutical Benefits Scheme of Australia. The dataset contains over 50 million records covering approximately 2 million patients. The results demonstrate the effectiveness of our method in identifying both known ADEs and unknown yet suspicious ADEs with limited detection of false positive signals. Comparing to a recognised gold standard, our method successfully detects 67.4% of the positive adverse events while only 8.78% false positives exist.
ER  - 

TY  - JOUR
T1  - Transitions to manual control from highly automated driving in non-critical truck platooning scenarios
AU  - Zhang, Bo
AU  - Wilschut, Ellen S.
AU  - Willemsen, Dehlia M.C.
AU  - Martens, Marieke H.
JO  - Transportation Research Part F: Traffic Psychology and Behaviour
VL  - 64
SP  - 84
EP  - 97
PY  - 2019
DA  - 2019/07/01/
SN  - 1369-8478
DO  - https://doi.org/10.1016/j.trf.2019.04.006
UR  - https://www.sciencedirect.com/science/article/pii/S1369847818301347
KW  - Highly automated driving
KW  - Truck platooning
KW  - Transition of control
KW  - Take-over response time
KW  - Perception-response time
KW  - Non-driving task
AB  - Automated truck platooning is getting an increasing interest for its potentially beneficial effects on fuel consumption, driver workload, traffic flow efficiency, and safety. Nevertheless, one major challenge lies in the safe and comfortable transitions of control from the automated system back to the human drivers, especially when they have been inattentive during highly automated driving. In this study, we investigated truck drivers’ take-over response times after a system initiated request to take back control in non-critical truck platooning scenarios. 22 professional truck drivers participated in the truck driving simulator experiment and everyone was instructed to drive under three task conditions during highly automated driving: Driver monitoring condition (drivers were instructed to monitor the surroundings), Driver not-monitoring condition (drivers were provided with a hand-held tablet and were asked to use this), and Eyes-closed condition (drivers were not allowed to open their eyes). The total take-over response time was divided into the perception response time and the movement response time by manual video annotation. Results showed significantly longer total take-over times with high variability in both Driver not-monitoring and Eyes-closed conditions compared to the Driver monitoring condition. Hand movement response time was found to be the dominant component of the total take-over time, being influenced by the motoric manoeuvres to resume physical readiness before taking over control (e.g., putting away the hand-held tablet, or adjusting seating position). These results suggest the importance of a personalized driver readiness predictor as an input parameter for a safe and comfortable transition of control.
ER  - 

TY  - JOUR
T1  - Evaluating secondary input devices to support an automotive touchscreen HMI: A cross-cultural simulator study conducted in the UK and China
AU  - Large, David R.
AU  - Burnett, Gary
AU  - Crundall, Elizabeth
AU  - Lawson, Glyn
AU  - Skrypchuk, Lee
AU  - Mouzakitis, Alex
JO  - Applied Ergonomics
VL  - 78
SP  - 184
EP  - 196
PY  - 2019
DA  - 2019/07/01/
SN  - 0003-6870
DO  - https://doi.org/10.1016/j.apergo.2019.03.005
UR  - https://www.sciencedirect.com/science/article/pii/S0003687019300584
KW  - Touchscreen
KW  - Rotary controller
KW  - Steering wheel control
KW  - Touchpad
KW  - Visual demand
KW  - Preferences
KW  - Driving performance
KW  - Workload
KW  - Character recognition
KW  - Culture
KW  - HMI
KW  - UK
KW  - China
KW  - Driver acceptance
AB  - Touchscreen Human-Machine Interfaces (HMIs) are a well-established and popular choice to provide the primary control interface between driver and vehicle, yet inherently demand some visual attention. Employing a secondary device with the touchscreen may reduce the demand but there is some debate about which device is most suitable, with current manufacturers favouring different solutions and applying these internationally. We present an empirical driving simulator study, conducted in the UK and China, in which 48 participants undertook typical in-vehicle tasks utilising either a touchscreen, rotary-controller, steering-wheel-controls or touchpad. In both the UK and China, the touchscreen was the most preferred/least demanding to use, and the touchpad least preferred/most demanding, whereas the rotary-controller was generally favoured by UK drivers and steering-wheel-controls were more popular in China. Chinese drivers were more excited by the novelty of the technology, and spent more time attending to the devices while driving, leading to an increase in off-road glance time and a corresponding detriment to vehicle control. Even so, Chinese drivers rated devices as easier-to-use while driving, and felt that they interfered less with their driving performance, compared to their UK counterparts. Results suggest that the most effective solution (to maximise performance/acceptance, while minimising visual demand) is to maintain the touchscreen as the primary control interface (e.g. for top-level tasks), and supplement this with a secondary device that is only enabled for certain actions; moreover, different devices may be employed in different cultural markets. Further work is required to explore these recommendations in greater depth (e.g. during extended or real-world testing), and to validate the findings and approach in other cultural contexts.
ER  - 

TY  - JOUR
T1  - Performance optimizations for scalable implicit RANS calculations with SU2
AU  - Economon, Thomas D.
AU  - Mudigere, Dheevatsa
AU  - Bansal, Gaurav
AU  - Heinecke, Alexander
AU  - Palacios, Francisco
AU  - Park, Jongsoo
AU  - Smelyanskiy, Mikhail
AU  - Alonso, Juan J.
AU  - Dubey, Pradeep
JO  - Computers & Fluids
VL  - 129
SP  - 146
EP  - 158
PY  - 2016
DA  - 2016/04/28/
SN  - 0045-7930
DO  - https://doi.org/10.1016/j.compfluid.2016.02.003
UR  - https://www.sciencedirect.com/science/article/pii/S0045793016300214
KW  - CFD
KW  - Multigrid
KW  - Parallel algorithms
KW  - High performance computing
AB  - In this paper, we present single- and multi-node optimizations of SU2, a widely-used, open-source Computational Fluid Dynamics application, aimed at improving performance and scalability for implicit Reynolds-averaged Navier–Stokes calculations on unstructured grids. Typical industry-standard implementations are currently limited by unstructured accesses, variable degrees of parallelism, as well as the global synchronizations inherent in traditionally used Krylov linear solvers. Therefore, we rely on aggressive single-node optimizations, such as hierarchical parallelism, dynamic threading, compacted memory layout, and vectorization, along with a communication-friendly agglomeration (geometric) linear multigrid solver. Based on results with the well-known ONERA M6 geometry, our single core and shared memory optimizations result in a speedup of 2.6X on the latest 14-core Intel® Xeon™ 11Intel, Xeon, and Intel Xeon Phi are trademarks of Intel Corporation in the U.S. and/or other countries. Software and workloads used in performance tests may have been optimized for performance only on Intel microprocessors. Performance tests, such as SYSmark and MobileMark, are measured using specific computer systems, components, software, operations and functions. Any change to any of those factors may cause the results to vary. You should consult other information and performance tests to assist you in fully evaluating your contemplated purchases, including the performance of that product when combined with other products. For more information go to http://www.intel.com/performance E5-2697v3 processor when compared to the baseline SU2 implementation with 14 MPI ranks. In multi-node settings, the hybrid OpenMP+MPI multigrid implementation achieves 2X higher parallel efficiency on 256 nodes over conventional Krylov-based (GMRES) methods.
ER  - 

TY  - JOUR
T1  - Relevance- and interface-driven clustering for visual information retrieval
AU  - Bouadjenek, Mohamed Reda
AU  - Sanner, Scott
AU  - Du, Yihao
JO  - Information Systems
VL  - 94
SP  - 101592
PY  - 2020
DA  - 2020/12/01/
SN  - 0306-4379
DO  - https://doi.org/10.1016/j.is.2020.101592
UR  - https://www.sciencedirect.com/science/article/pii/S0306437920300752
KW  - Visual information retrieval
KW  - Relevance-driven Clustering
KW  - Visual search user study
KW  - Clustering via filter optimization
AB  - Search results of spatio-temporal data are often displayed on a map, but when the number of matching search results is large, it can be time-consuming to individually examine all results, even when using methods such as filtered search to narrow the content focus. This suggests the need to aggregate results via a clustering method. However, standard unsupervised clustering algorithms like K-means (i) ignore relevance scores that can help with the extraction of highly relevant clusters, and (ii) do not necessarily optimize search results for purposes of visual presentation. In this article, we address both deficiencies by framing the clustering problem for search-driven user interfaces in a novel optimization framework that (i) aims to maximize the relevance of aggregated content according to cluster-based extensions of standard information retrieval metrics and (ii) defines clusters via constraints that naturally reflect interface-driven desiderata of spatial, temporal, and keyword coherence that do not require complex ad-hoc distance metric specifications as in K-means. After comparatively benchmarking algorithmic variants of our proposed approach – RadiCAL – in offline experiments, we undertake a user study with 24 subjects to evaluate whether RadiCAL improves human performance on visual search tasks in comparison to K-means clustering and a filtered search baseline. Our results show that (a) our binary partitioning search (BPS) variant of RadiCAL is fast, near-optimal, and extracts higher-relevance clusters than K-means, and (b) clusters optimized via RadiCAL result in faster search task completion with higher accuracy while requiring a minimum workload leading to high effectiveness, efficiency, and user satisfaction among alternatives.
ER  - 

TY  - JOUR
T1  - Lexicographic extension of the reference point method applied in radiation therapy treatment planning
AU  - van Haveren, Rens
AU  - Breedveld, Sebastiaan
AU  - Keijzer, Marleen
AU  - Voet, Peter
AU  - Heijmen, Ben
AU  - Ogryczak, Włodzimierz
JO  - European Journal of Operational Research
VL  - 263
IS  - 1
SP  - 247
EP  - 257
PY  - 2017
DA  - 2017/11/16/
SN  - 0377-2217
DO  - https://doi.org/10.1016/j.ejor.2017.04.062
UR  - https://www.sciencedirect.com/science/article/pii/S0377221717304095
KW  - OR in medicine
KW  - Multiple objective programming
KW  - Radiation therapy treatment planning
KW  - Lexicographic reference point method
KW  - Partial trade-offs
AB  - In radiation therapy treatment planning, generating a treatment plan is a multi-objective optimisation problem. The decision-making strategy is uniform for each group of cancer patients, e.g. prostate cancer, and can thus be automated. Predefined priorities and aspiration levels are assigned to each objective, and the strategy is to attain these levels in order of priority. Therefore, a straightforward lexicographic approach is sequential ϵ-constraint programming where objectives are sequentially optimised and constrained according to predefined rules, mimicking human decision-making. The clinically applied 2-phase ϵ-constraint (2pϵc) method captures this approach and generates clinically acceptable treatment plans. However, the number of optimisation problems to be solved for the 2pϵc method, and hence the computation time, scales linearly with the number of objectives. To improve the daily planning workload and to further enhance radiation therapy, it is extremely important to reduce this time. Therefore, we developed the lexicographic reference point method (LRPM), a lexicographic extension of the reference point method, for generating a treatment plan by solving a single optimisation problem. The LRPM processes multiple a priori defined reference points into modified partial achievement functions. In addition, a priori bounds on a subset of the partial trade-offs can be imposed using a weighted sum component. The LRPM was validated for 30 randomly selected prostate cancer patients. While the treatment plans generated using the LRPM were of similar clinical quality to those generated using the 2pϵc method, the LRPM decreased the average computation time from 12.4 to 1.2 minutes, a speed-up factor of 10.
ER  - 

TY  - JOUR
T1  - SLAM-aided forest plot mapping combining terrestrial and mobile laser scanning
AU  - Shao, Jie
AU  - Zhang, Wuming
AU  - Mellado, Nicolas
AU  - Wang, Nan
AU  - Jin, Shuangna
AU  - Cai, Shangshu
AU  - Luo, Lei
AU  - Lejemble, Thibault
AU  - Yan, Guangjian
JO  - ISPRS Journal of Photogrammetry and Remote Sensing
VL  - 163
SP  - 214
EP  - 230
PY  - 2020
DA  - 2020/05/01/
SN  - 0924-2716
DO  - https://doi.org/10.1016/j.isprsjprs.2020.03.008
UR  - https://www.sciencedirect.com/science/article/pii/S0924271620300782
KW  - Forest mapping
KW  - LiDAR
KW  - SLAM
KW  - Single-scan TLS
KW  - MLS
AB  - Precise structural information collected from plots is significant in the management of and decision-making regarding forest resources. Currently, laser scanning is widely used in forestry inventories to acquire three-dimensional (3D) structural information. There are three main data-acquisition modes in ground-based forest measurements: single-scan terrestrial laser scanning (TLS), multi-scan TLS and multi-single-scan TLS. Nevertheless, each of these modes causes specific difficulties for forest measurements. Due to occlusion effects, the single-scan TLS mode provides scans for only one side of the tree. The multi-scan TLS mode overcomes occlusion problems, however, at the cost of longer acquisition times, more human labor and more effort in data preprocessing. The multi-single-scan TLS mode decreases the workload and occlusion effects but lacks the complete 3D reconstruction of forests. These problems in TLS methods are largely avoided with mobile laser scanning (MLS); however, the geometrical peculiarity of forests (e.g., similarity between tree shapes, placements, and occlusion) complicates the motion estimation and reduces mapping accuracy. Therefore, this paper proposes a novel method combining single-scan TLS and MLS for forest 3D data acquisition. We use single-scan TLS data as a reference, onto which we register MLS point clouds, so they fill in the omission of the single-scan TLS data. To register MLS point clouds on the reference, we extract virtual feature points that are sampling the centerlines of tree stems and propose a new optimization-based registration framework. In contrast to previous MLS-based studies, the proposed method sufficiently exploits the natural geometric characteristics of trees. We demonstrate the effectiveness, robustness, and accuracy of the proposed method on three datasets, from which we extract structural information. The experimental results show that the omission of tree stem data caused by one scan can be compensated for by the MLS data, and the time of the field measurement is much less than that of the multi-scan TLS mode. In addition, single-scan TLS data provide strong global constraints for MLS-based forest mapping, which allows low mapping errors to be achieved, e.g., less than 2.0 cm mean errors in both the horizontal and vertical directions.
ER  - 

TY  - JOUR
T1  - Automatic segmentation and automatic seed point selection of nasopharyngeal carcinoma from microscopy images using region growing based approach
AU  - Mohammed, Mazin Abed
AU  - Ghani, Mohd Khanapi Abd
AU  - Hamed, Raed Ibraheem
AU  - Abdullah, Mohamad Khir
AU  - Ibrahim, Dheyaa Ahmed
JO  - Journal of Computational Science
VL  - 20
SP  - 61
EP  - 69
PY  - 2017
DA  - 2017/05/01/
SN  - 1877-7503
DO  - https://doi.org/10.1016/j.jocs.2017.03.009
UR  - https://www.sciencedirect.com/science/article/pii/S1877750317302892
KW  - Nasopharyngeal carcinoma
KW  - Image segmentation
KW  - Automatic segmentation
KW  - Automatic seed point selection
KW  - Microscopy images
KW  - Region growing based technique
AB  - Context
Nasopharyngeal carcinoma (NPC) is a type of cancer in the head and neck, and this cancer presents in the throat region between the pharynx and nasal cavity. NPC is frequently detected in Southeast Asia, particularly in the southern part of China, Malaysia, Singapore, Hong Kong, Taiwan, Vietnam, and Thailand.
Problem
The diagnostic procedure of NPC entirely depends on the Physicians experience and involves multiple subjective decisions. Subjective decision-making can result in inter and intra observer variations. Inter-observer variation is the total difference obtained from the results of two and above observers when scrutinizing similar materials. Variation amongst the observers is the total difference an observer experience when spotting the same material many times. Tradition diagnostic of NPC has many limitations such as the time consuming for doctors to identify and recognize the tumor area slice by slice and reduce radiologists’ workloads. In addition, another challenge lies in the appearance of doctors used the observation of human eyes (human errors) in NPC cases can be missed detailed information.
Approach
A novel approach to automatic segmentation plus initial seed generated without human intervention of nasopharyngeal carcinoma using region growing based technique from microscopy images is presented in this study by take advantage of geometric features to detection of NPC images. In order to get accurate region of NPC image, the proposed results utilize wavelet transform for image enhancement by reduce the noise by remove the high ratio sub-bands and predestine a developed NPC image. Segmentation steps including many phases. Firstly, the thresholding is mean value used to binarise the image and secondly, filtering or remove unwanted objects in the images.
Finding
The findings outcome from this study have shown that: (1) a new adaptive threshold is used as a post-processing to at long last detect the NPC; (2) identified and established an evaluation criterion for automatic segmentation of NPC cases; (3) highlight the methods, based on region growing based technique and active contour operation, for selecting the best region; (4) assessed the performance of the proposed results by comparing the manual measurements and automatic NPC segmentation. The NPC segmentation rate in the technique used is about 83.89%. Comparably, this amount expanded to 92.04% once a line presumption (NPC approximation) was utilized in one of the stage in the technique here.
ER  - 

TY  - JOUR
T1  - Care interrupted: Poverty, in-migration, and primary care in rural resource towns
AU  - Rice, Kathleen
AU  - Webster, Fiona
JO  - Social Science & Medicine
VL  - 191
SP  - 77
EP  - 83
PY  - 2017
DA  - 2017/10/01/
SN  - 0277-9536
DO  - https://doi.org/10.1016/j.socscimed.2017.08.044
UR  - https://www.sciencedirect.com/science/article/pii/S0277953617305257
KW  - Rural health
KW  - Resource towns
KW  - Complex care
KW  - In-migration
KW  - Housing
KW  - Poverty
KW  - Chronic pain
AB  - Internationally, rural people have poorer health outcomes relative to their urban counterparts, and primary care providers face particular challenges in rural and remote regions. Drawing on ethnographic fieldnotes and 14 open-ended qualitative interviews with care providers and chronic pain patients in two remote resource communities in Northern Ontario, Canada, this article examines the challenges involved in providing and receiving primary care for complex chronic conditions in these communities. Both towns struggle with high unemployment in the aftermath of industry closure, and are characterized by an abundance of affordable housing. Many of the challenges that care providers face and that patients experience are well-documented in Canadian and international literature on rural and remote health, and health care in resource towns (e.g. lack of specialized care, difficulty with recruitment and retention of care providers, heavy workload for existing care providers). However, our study also documents the recent in-migration of low-income, largely working-age people with complex chronic conditions who are drawn to the region by the low cost of housing. We discuss the ways in which the needs of these in-migrants compound existing challenges to rural primary care provision. To our knowledge, our study is the first to document both this migration trend, and the implications of this for primary care. In the interest of patient health and care provider well-being, existing health and social services will likely need to be expanded to meet the needs of these in-migrants.
ER  - 

TY  - JOUR
T1  - Copernicus, a hybrid dataflow and peer-to-peer scientific computing platform for efficient large-scale ensemble sampling
AU  - Pouya, Iman
AU  - Pronk, Sander
AU  - Lundborg, Magnus
AU  - Lindahl, Erik
JO  - Future Generation Computer Systems
VL  - 71
SP  - 18
EP  - 31
PY  - 2017
DA  - 2017/06/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2016.11.004
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X16305337
KW  - Peer-too-peer
KW  - Distributed computing
KW  - Dataflow programming
KW  - Scientific computing
KW  - Job resiliency
AB  - Compute-intensive applications have gradually changed focus from massively parallel supercomputers to capacity as a resource obtained on-demand. This is particularly true for the large-scale adoption of cloud computing and MapReduce in industry, while it has been difficult for traditional high-performance computing (HPC) usage in scientific and engineering computing to exploit this type of resources. However, with the strong trend of increasing parallelism rather than faster processors, a growing number of applications target parallelism already on the algorithm level with loosely coupled approaches based on sampling and ensembles. While these cannot trivially be formulated as MapReduce, they are highly amenable to throughput computing. There are many general and powerful frameworks, but in particular for sampling-based algorithms in scientific computing there are some clear advantages from having a platform and scheduler that are highly aware of the underlying physical problem. Here, we present how these challenges are addressed with combinations of dataflow programming, peer-to-peer techniques and peer-to-peer networks in the Copernicus platform. This allows automation of sampling-focused workflows, task generation, dependency tracking, and not least distributing these to a diverse set of compute resources ranging from supercomputers to clouds and distributed computing (across firewalls and fragile networks). Workflows are defined from modules using existing programs, which makes them reusable without programming requirements. The system achieves resiliency by handling node failures transparently with minimal loss of computing time due to checkpointing, and a single server can manage hundreds of thousands of cores e.g. for computational chemistry applications.
ER  - 

TY  - JOUR
T1  - Diagnosis of retinal health in digital fundus images using continuous wavelet transform (CWT) and entropies
AU  - Koh, Joel E.W.
AU  - Acharya, U. Rajendra
AU  - Hagiwara, Yuki
AU  - Raghavendra, U.
AU  - Tan, Jen Hong
AU  - Sree, S. Vinitha
AU  - Bhandary, Sulatha V.
AU  - Rao, A. Krishna
AU  - Sivaprasad, Sobha
AU  - Chua, Kuang Chua
AU  - Laude, Augustinus
AU  - Tong, Louis
JO  - Computers in Biology and Medicine
VL  - 84
SP  - 89
EP  - 97
PY  - 2017
DA  - 2017/05/01/
SN  - 0010-4825
DO  - https://doi.org/10.1016/j.compbiomed.2017.03.008
UR  - https://www.sciencedirect.com/science/article/pii/S0010482517300574
KW  - Continuous wavelet transform
KW  - Age-related macular degeneration
KW  - Diabetic retinopathy
KW  - Fundus
KW  - Glaucoma
AB  - Vision is paramount to humans to lead an active personal and professional life. The prevalence of ocular diseases is rising, and diseases such as glaucoma, Diabetic Retinopathy (DR) and Age-related Macular Degeneration (AMD) are the leading causes of blindness in developed countries. Identifying these diseases in mass screening programmes is time-consuming, labor-intensive and the diagnosis can be subjective. The use of an automated computer aided diagnosis system will reduce the time taken for analysis and will also reduce the inter-observer subjective variabilities in image interpretation. In this work, we propose one such system for the automatic classification of normal from abnormal (DR, AMD, glaucoma) images. We had a total of 404 normal and 1082 abnormal fundus images in our database. As the first step, 2D-Continuous Wavelet Transform (CWT) decomposition on the fundus images of two classes was performed. Subsequently, energy features and various entropies namely Yager, Renyi, Kapoor, Shannon, and Fuzzy were extracted from the decomposed images. Then, adaptive synthetic sampling approach was applied to balance the normal and abnormal datasets. Next, the extracted features were ranked according to the significances using Particle Swarm Optimization (PSO). Thereupon, the ranked and selected features were used to train the random forest classifier using stratified 10-fold cross validation. Overall, the proposed system presented a performance rate of 92.48%, and a sensitivity and specificity of 89.37% and 95.58% respectively using 15 features. This novel system shows promise in detecting abnormal fundus images, and hence, could be a valuable adjunct eye health screening tool that could be employed in polyclinics, and thereby reduce the workload of specialists at hospitals.
ER  - 

TY  - JOUR
T1  - Managing workflow of customer requirements using machine learning
AU  - Lyutov, Alexey
AU  - Uygun, Yilmaz
AU  - Hütt, Marc-Thorsten
JO  - Computers in Industry
VL  - 109
SP  - 215
EP  - 225
PY  - 2019
DA  - 2019/08/01/
SN  - 0166-3615
DO  - https://doi.org/10.1016/j.compind.2019.04.010
UR  - https://www.sciencedirect.com/science/article/pii/S0166361519300636
KW  - Documents management
KW  - Automation
KW  - Classification
KW  - Machine learning
AB  - Customer requirements – product specifications issued by the customer – organize the dialog between suppliers and customers and, hence, affect the dynamics of supply networks. These large and complex documents are frequently updated over time, while changes are seldom marked by the customers who issue the requirements. The lack of structure and defined responsibilities, thus, demands an expert to manually process the requirements. Here, the possibility to improve the usual workflow with machine learning algorithms is explored. The whole requirements management process has two major bottlenecks, which can be automatized. The first one, detecting changes, can be accomplished via a document comparison tool. The second one, recognizing the responsibilities and assigning them to the right department, can be solved with standard machine learning algorithms. Here, such algorithms are applied to a dataset obtained from a global automotive industry supplier. The proposed method improves the requirements management process by reducing an expert’s workload and thus decreasing the time for processing one document was reduced from 2 weeks to 1 h. Moreover, the method gives a high accuracy of department assignment and can self-improve once implemented into a requirements management system. Although the machine learning methods are very popular nowadays, they are seldom used to improve business processes in real companies, especially in the case of processes that did not require digitalization in the past. Here we show, how such methods can solve some of the management problems and improve their workflow.
ER  - 

TY  - JOUR
T1  - Adaptive neuro-fuzzy inference systems with k-fold cross-validation for energy expenditure predictions based on heart rate
AU  - Kolus, Ahmet
AU  - Imbeau, Daniel
AU  - Dubé, Philippe-Antoine
AU  - Dubeau, Denise
JO  - Applied Ergonomics
VL  - 50
SP  - 68
EP  - 78
PY  - 2015
DA  - 2015/09/01/
SN  - 0003-6870
DO  - https://doi.org/10.1016/j.apergo.2015.03.001
UR  - https://www.sciencedirect.com/science/article/pii/S0003687015000344
KW  - Flex–HR method
KW  - Physical workload
KW  - Adaptive neuro-fuzzy inference system (ANFIS)
AB  - This paper presents a new model based on adaptive neuro-fuzzy inference systems (ANFIS) to predict oxygen consumption (V˙O2) from easily measured variables. The ANFIS prediction model consists of three ANFIS modules for estimating the Flex–HR parameters. Each module was developed based on clustering a training set of data samples relevant to that module and then the ANFIS prediction model was tested against a validation data set. Fifty-eight participants performed the Meyer and Flenghi step-test, during which heart rate (HR) and V˙O2 were measured. Results indicated no significant difference between observed and estimated Flex–HR parameters and between measured and estimated V˙O2 in the overall HR range, and separately in different HR ranges. The ANFIS prediction model (MAE = 3 ml kg−1 min−1) demonstrated better performance than Rennie et al.'s (MAE = 7 ml kg−1 min−1) and Keytel et al.'s (MAE = 6 ml kg−1 min−1) models, and comparable performance with the standard Flex–HR method (MAE = 2.3 ml kg−1 min−1) throughout the HR range. The ANFIS model thus provides practitioners with a practical, cost- and time-efficient method for V˙O2 estimation without the need for individual calibration.
ER  - 

TY  - JOUR
T1  - Effect of safety shoes type, lifting frequency, and ambient temperature on subject's MAWL and physiological responses
AU  - Al-Ashaik, Riyad A.
AU  - Ramadan, Mohamed Z.
AU  - Al-Saleh, Khalid S.
AU  - Khalaf, Tamer M.
JO  - International Journal of Industrial Ergonomics
VL  - 50
SP  - 43
EP  - 51
PY  - 2015
DA  - 2015/11/01/
SN  - 0169-8141
DO  - https://doi.org/10.1016/j.ergon.2015.09.002
UR  - https://www.sciencedirect.com/science/article/pii/S0169814115300202
KW  - Manual materials handling
KW  - Manual lifting
KW  - Lifting capabilities
KW  - Maximum permissible limits of lift
KW  - Safety shoes
KW  - Working in a hot environment
AB  - Objective
The purpose of this paper is to evaluate the lifting capabilities of individuals while wearing safety shoes in a hot environment and to investigate the behavior of the physiological responses induced by the lifting process associated with those variables.
Methods
In order to achieve the objectives of this research, two sequential studies were conducted. The first part was an acclimatization and training program followed by a psychophysical experiment. Seven male workers participated in this experiment from the university. A three-way repeated measures design, with three independent variables and seven response variables, was utilized in this study. The independent variables studied in the psychophysical experiment were: 1) environmental temperature (20 and 30 °C WBGT), 2) lifting frequency (1 and 5 lifts/min), and 3) safety shoes (light-duty, medium-duty and heavy-duty). The response variables for this experiment were: 1) maximum acceptable weight of lift (MAWL), 2) heart rate, 3) aural-canal temperature, 4) muscle electromyography (EMG) of four muscle groups (biceps brachii, anterior deltoid, trapezius, and erector spinae), 5) rating of perceived exertion, 6) rating of thermal sensation and7) safety shoes discomfort rating.
Results
The psychophysical experiment results showed that the weights selected by participants at higher levels of the independent variables were significantly less than those selected at lower levels of the independent variables. Some of the interaction effects were also significant.
Conclusion
This study found evidence that – in addition to lifting frequency, which is well reported in the literature – heat stress increases the workload intensity in manual lifting tasks influencing the psychophysical selection of MAWL and the physiological responses of the human body represented in aural-canal temperature, heart rate and muscular activities. The study findings demonstrated the necessity of accounting for work environmental temperature and type of worn safety shoes, which is a safety requirement by most employers, when calculating the recommended weight limits.
Practitioner summary
Most of the manual materials handling studies had investigated worker's capacity to perform lifting tasks in different environmental conditions not considering the effect of wearing safety shoes. This research fills the gap by presenting safety guidelines regarding lifting tasks in a hot environment while wearing safety shoes.
ER  - 

TY  - JOUR
T1  - Skeletal bone age prediction based on a deep residual network with spatial transformer
AU  - Han, Yaxin
AU  - Wang, Guangbin
JO  - Computer Methods and Programs in Biomedicine
VL  - 197
SP  - 105754
PY  - 2020
DA  - 2020/12/01/
SN  - 0169-2607
DO  - https://doi.org/10.1016/j.cmpb.2020.105754
UR  - https://www.sciencedirect.com/science/article/pii/S016926072031587X
KW  - X-ray bone image
KW  - Image processing
KW  - Deep learning
KW  - Automatic bone age prediction
KW  - Convolutional neural network
AB  - Objective
Bone age prediction can be performed by medical experts manually assessment of X-ray images of the hand bone. In practice, the workload is huge, resource consumption is large, measurement takes a long time, and it is easily influenced by human factors. As such, manual estimation of bone age takes a long time and the results fluctuate greatly depending on the proficiency of the radiologist.
Methods
The left-hand X-ray image data was identified and pre-processed. X-ray image analysis method using on deep neural network was used to automatically extract the key features of the left-hand joint bone age, and evaluation performance of the model was implemented.
Results
In this paper, the deep learning method can be used to obtain the X-ray bone image features, and the convolutional neural network is used to automatically assess the age of bone. The feature region extraction method based on deep learning can extract feature information with superior performance compared to the traditional image analysis technique. Based on the residual network (ResNet) model in the deep learning algorithm, the average absolute error of the age of bones detected by the bone age assessment model is 0.455 better than traditional methods and only end-to-end deep learning methods. When the learning rate is greater than 0.0005, the MAE of Inception Resnet v2 model is higher than most models. Accuracy of bone age prediction is as high as 97.6%.
Conclusion
In comparison with the traditional machine learning feature extraction technique, the convolutional neural network based on feature extraction has better performance in the bone age regression model, and further improves the accuracy of image-based age of bone assessment.
ER  - 

TY  - JOUR
T1  - A hybrid circuits-cloud: Development of a low-cost secure cloud-based collaborative platform for A/D circuits in virtual hardware E-lab
AU  - Mayoof, Shaffee
AU  - Alaswad, Hasan
AU  - Aljeshi, Sameer
AU  - Tarafa, Ahmed
AU  - Elmedany, Wael
JO  - Ain Shams Engineering Journal
VL  - 12
IS  - 2
SP  - 1197
EP  - 1209
PY  - 2021
DA  - 2021/06/01/
SN  - 2090-4479
DO  - https://doi.org/10.1016/j.asej.2020.09.012
UR  - https://www.sciencedirect.com/science/article/pii/S2090447920302070
KW  - Circuits-cloud
KW  - Electronic design automation
KW  - Circuit simulation
KW  - Analog and digital circuits
AB  - The development and use of cloud based tools in virtual learning has been increasing in recent years. Electronic Design Automation (EDA) or Electronic Computer-Aided Design (ECAD) is one of the most important tools that are used for electronic circuit design and simulation. There is a number of available cloud based EDA tools that are used in industry and educational institutions. This paper introduces a hybrid-circuits cloud-based platform that enables students to design, simulate, and model both analog and digital electronic systems. Circuits-cloud became one of the top best electronic circuit cloud tools, it is ranked as number one in Google search for the “top list of electronic circuit cloud tools”. It integrates the Internet of Things (IoT) and cloud based tools by adding sensors, actuators, and interact with the physical design in the laboratory in the real time. This platform acts as a comprehensive laboratory device to capture components, draw circuits, integrate different components, apply different inputs, simulate, measure, and detect any defect or heated elements. This cloud-based platform introduces an integrated environment for digital, analog and IoT modeling. The platform has a laboratory device that can be integrated into circuits level with the cloud system to test the physical circuits in real-time remotely. This enables in-browser cloud platform for schematic capture, circuit simulation, and emulation. As a testimony of the platform of the modeling and simulation discipline, a list of about 100 types of equipment?s were included and tested. The cloud service is provided by Amazon Web Services (AWS) with high data protection service, AWS also provides encryption, key management, and threat detection that continuously monitors and protects user accounts and workloads. It is estimated to be able to serve approximately 2000 active students and tutors on a monthly average. This platform can be used in distance and blended learning as well.
ER  - 

TY  - JOUR
T1  - Gear pitting fault diagnosis with mixed operating conditions based on adaptive 1D separable convolution with residual connection
AU  - Li, Xueyi
AU  - Li, Jialin
AU  - Zhao, Chengying
AU  - Qu, Yongzhi
AU  - He, David
JO  - Mechanical Systems and Signal Processing
VL  - 142
SP  - 106740
PY  - 2020
DA  - 2020/08/01/
SN  - 0888-3270
DO  - https://doi.org/10.1016/j.ymssp.2020.106740
UR  - https://www.sciencedirect.com/science/article/pii/S0888327020301266
KW  - Gear pitting fault diagnosis
KW  - Depthwise separable convolution
KW  - Residual connection
KW  - Vibration signals
AB  - Gear pitting fault diagnosis has always been an important subject to industry and research community. In the past, the diagnosis of early gear pitting faults has usually been carried out under single gear health state. In order to diagnose the early gear pitting faults with mixed operating conditions and reduce the number of training parameters, a new method is proposed in this paper. The proposed method uses an adaptive 1D separable convolution with residual connection network to classify gear pitting faults with mixed operating conditions. Compared to the traditional convolutional neural network, the separable convolution with residual connection network can carry out the channel convolution with point-by-point convolution to effectively reduce the number of network parameters. The residual connection can solve the representational bottleneck problem of the features in the model. Moreover, the method proposed in this paper applies the search algorithm to select better hyperparameters of the model. The raw vibration signals of the gear pitting faults at different speeds collected in a gear test rig are used to validate the effectiveness of the proposed method. The results show that the proposed method can accurately diagnose the early gear pitting faults with mixed speeds. In comparison with other machine learning models, the proposed method has provided a better diagnostic accuracy with fewer model parameters.
ER  - 

TY  - JOUR
T1  - A generic multi-level framework for microscopic traffic simulation—Theory and an example case in modelling driver distraction
AU  - van Lint, J.W.C.
AU  - Calvert, S.C.
JO  - Transportation Research Part B: Methodological
VL  - 117
SP  - 63
EP  - 86
PY  - 2018
DA  - 2018/11/01/
SN  - 0191-2615
DO  - https://doi.org/10.1016/j.trb.2018.08.009
UR  - https://www.sciencedirect.com/science/article/pii/S0191261518302704
KW  - Human factors
KW  - Traffic simulation framework
KW  - Workload
KW  - Task-Capacity-Interface model
KW  - Distraction
AB  - Incorporation of more sophisticated human factors (HF) in mathematical models for driving behavior has become an increasingly popular and important research direction in the last few years. Such models enable us to simulate under which conditions perception errors and risk-taking lead to interactions that result in unsafe traffic conditions and ultimately accidents. In this paper, we present a generic multi-level microscopic traffic modelling and simulation framework that supports this important line of research. In this framework, the driving task is modeled in a multi-layered fashion. At the highest level, we have idealized (collision-free) models for car following and other driving tasks. These models typically contain HF parameters that exogenously “govern the human factor”, such as reaction time, sensitivities to stimuli, desired speed, etc. At the lowest level, we define HF variables (task demand and capacity, awareness) with which we maintain what the information processing costs are of performing driving tasks as well as non-driving related tasks such as distractions. We model these costs using so-called fundamental diagrams of task demand. In between, we define functions that govern the dynamics of the high-level HF parameters with these HF variables as inputs. When total task demand increases beyond task capacity, first awareness may deteriorate, where we use Endsley's three-level awareness construct to differentiate between effects on perception, comprehension, anticipation and reaction time. Secondly, drivers may adapt their response in line with Fullers risk allostasis theory to reduce risk to acceptable levels. This framework can be viewed as a meta model, that provides the analyst possibilities to combine and mix a wide variety of microscopic models for driving behavior at different levels of sophistication, depending on which HF are studied, and which phenomena need to be reproduced. We illustrate the framework with a distraction (rubbernecking) case. Our results show that the framework results in endogenous mechanisms for inter- and intra-driver differences in driving behavior and can generate multiple plausible HF mechanisms to explain the same observable traffic phenomena and congestion patterns that arise due to the distraction. We believe our framework can serve as a valuable tool in testing hypotheses related to the effects of HF on traffic efficiency and traffic safety in a systematic way for both the traffic flow and HF community.
ER  - 

TY  - JOUR
T1  - Can our phones keep us safe? A content analysis of smartphone applications to prevent mobile phone distracted driving
AU  - Oviedo-Trespalacios, Oscar
AU  - King, Mark
AU  - Vaezipour, Atiyeh
AU  - Truelove, Verity
JO  - Transportation Research Part F: Traffic Psychology and Behaviour
VL  - 60
SP  - 657
EP  - 668
PY  - 2019
DA  - 2019/01/01/
SN  - 1369-8478
DO  - https://doi.org/10.1016/j.trf.2018.11.017
UR  - https://www.sciencedirect.com/science/article/pii/S1369847818303991
KW  - Texting
KW  - Human-computer interaction
KW  - Cell phone
KW  - Distraction
KW  - Dual-task
KW  - Inattention
KW  - Apple
AB  - Mobile phone use while driving is a pervasive problem that continues to increase, notwithstanding the large crash risk this behaviour constitutes. A number of phone applications have been developed with the intention of utilising the technology to prevent dangerous phone behaviours while driving. Despite the potential these applications have in preventing crashes associated with distracted driving, research is yet to explore these emergent applications. Therefore, this study provided a review of the current smartphone applications developed to prevent distracted driving. A content analysis was conducted to identify the smartphone applications targeted at stopping, preventing or reducing phone use behaviour while driving. Their functionality was determined based on the ecosystem of smartphone applications: application-mobile phone interaction, application-driver interaction, and application-context interaction. A total of 29 relevant applications in English language were identified. Most of these applications focused on blocking specific phone functions (e.g. texting or calling) while allowing more desirable driving phone functions to be accessed (e.g. music applications and GPS functions). The specific functions which are blocked or allowed varied greatly between applications. Out of the different application interactions, the function which sends an automatic text message to a contact who texts the driver (associated with external communicator interactions) was the most common feature. A major limitation of the applications was their reliance on blocking specific phone functions as opposed to managing workload while driving or simplifying specific phone tasks to be more compatible with driving. Simply blocking phone functions may not be attractive to drivers who view their phone as a necessity. As such, these drivers are unlikely to use these voluntary applications at all while driving. Smartphone applications designed to prevent phone use while driving show potential for playing a large role in a systemic intervention to prevent mobile phone distracted driving, yet there is a substantial need for further development of these applications.
ER  - 

TY  - JOUR
T1  - Family workers, stress, and the limits of self-care
AU  - Mavridis, Caroline
AU  - Harkness, Sara
AU  - Super, Charles M.
AU  - Liu, Jia Li
JO  - Children and Youth Services Review
VL  - 103
SP  - 236
EP  - 246
PY  - 2019
DA  - 2019/08/01/
SN  - 0190-7409
DO  - https://doi.org/10.1016/j.childyouth.2019.06.011
UR  - https://www.sciencedirect.com/science/article/pii/S0190740919300775
KW  - Family workers
KW  - Occupational stress
KW  - Self-care practices
KW  - Human service agencies
AB  - High levels of work-related stress have been frequently documented among front-line family service providers including social workers, home visitors, and agency staff members. Left unaddressed, such stress contributes to burn-out and job turnover, with negative effects on client families as well as agencies and the workers themselves. In response to this problem, some child and family service organizations have encouraged the use of self-care practices to counteract the inherent stresses of these jobs. The present study reports on descriptions of stress and self-care contained in written portfolios of 99 family workers enrolled in a strength-based training program, the Family Development Credential®. As found in other research, virtually all study participants reported an over-arching sense of stress and anxiety, with specific issues of workload, client problems, and work/family imbalance most frequently mentioned. To deal with their stress, workers described a variety of self-care practices: most common were mindfulness, exercise, social connections, changing self-expectations, and time management. Results show a significant curvilinear relationship between the number of stresses and the number of self-care practices mentioned, such that workers discussing both the lowest and the highest number of stresses discussed fewer self-care practices than workers naming a moderate number of stresses. Although a similar relationship between the level of stress and individuals' ability to take advantage of available resources has been demonstrated for low-income families, to our knowledge the present study is the first empirical demonstration of this principle for people who serve such families. These findings illustrate the limits of individual self-care for dealing with high levels of stress, and suggest the importance of strengthening worker support at the agency level, as well as tailoring stress management programs to the needs of individual workers.
ER  - 

TY  - JOUR
T1  - Personalized change awareness: Reducing information overload in loosely-coupled teamwork
AU  - Amir, Ofra
AU  - Grosz, Barbara J.
AU  - Gajos, Krzysztof Z.
AU  - Gultchin, Limor
JO  - Artificial Intelligence
VL  - 275
SP  - 204
EP  - 233
PY  - 2019
DA  - 2019/10/01/
SN  - 0004-3702
DO  - https://doi.org/10.1016/j.artint.2019.05.005
UR  - https://www.sciencedirect.com/science/article/pii/S000437021930133X
KW  - Information sharing
KW  - Teamwork support
AB  - Complex tasks such as treating patients with chronic conditions and developing software products are typically accomplished by teams that collaborate over an extended time duration. To remain coordinated, team members need to be aware of others' activities if those activities are likely to affect their own actions. However, identifying such interactions and sharing information appropriately is challenging, especially when the activities of team members are loosely-coupled. In practice, team members often either lack important information about others' activities, or are overwhelmed by the need to review too much information. This paper presents Personalized Change Awareness, a new approach for supporting team coordination which aims to automatically identify and share the subset of information about others' activities that is most relevant to each of the team members. The paper formally defines the computational problem of information sharing in loosely-coupled teamwork, which underlies the personalized change awareness approach. It defines a new representation, Mutual Influence Potential Networks (MIP-Nets) and an algorithm, MIP-DOI, that uses this representation to determine the information that is most relevant to each team member. In contrast to existing information sharing algorithms in multi-agent teams, MIP-DOI does not assume the availability of a priori knowledge of a team's possible plans, because human teams rarely explicitly define detailed long-term plans in advance. We demonstrate the ability of MIP-DOI to identify relevant information using simulations of collaborative activities. We further evaluated the contribution of personalized change awareness to team performance in a controlled user study. To this end, we developed a personalized change awareness mechanism for collaborative writing, which used MIP-DOI to determine which changes to share with each author. This evaluation demonstrates that the Personalized Change Awareness approach resulted in higher productivity and lower perceived workload without any change in final quality compared to the currently prevalent approach of sharing all change information. Our results also demonstrate that merely reducing the amount of information shared with co-authors is not enough: sharing a random subset of changes resulted in significantly lower quality of work than sharing a personalized subset of changes.
ER  - 

TY  - JOUR
T1  - LabPush: A pilot study of providing remote clinics with laboratory results via short message service (SMS) in Swaziland, Africa – A qualitative study
AU  - Hao, Wen-Rui
AU  - Hsu, Yi-Hsin
AU  - Chen, Kuan-Chen
AU  - Li, Hsien-Chang
AU  - Iqbal, Usman
AU  - Nguyen, Phung-Anh
AU  - Huang, Chih-Wei
AU  - Yang, Hsuan-Chia
AU  - Lee, Peisan
AU  - Li, Mei-Hsuan
AU  - Hlatshwayo, Sharoon Lungile
AU  - Li, Yu-Chuan (Jack)
AU  - Jian, Wen-Shan
JO  - Computer Methods and Programs in Biomedicine
VL  - 118
IS  - 1
SP  - 77
EP  - 83
PY  - 2015
DA  - 2015/01/01/
SN  - 0169-2607
DO  - https://doi.org/10.1016/j.cmpb.2014.10.005
UR  - https://www.sciencedirect.com/science/article/pii/S0169260714003502
KW  - Qualitative study
KW  - Remote clinics
KW  - Laboratory results via short message service (SMS)
KW  - Swazi healthcare
KW  - Turnaround time (TAT)
KW  - LabPush
KW  - mhealth
AB  - Background
Developing countries are confronting a steady growth in the prevalence of the infectious diseases. Mobile technologies are widely available and can play an important role in health care at the regional, community, and individual levels. Although labs usually able to accomplish the requested blood test and produce the results within two days after receiving the samples, but the time for the results to be delivered back to clinics is quite variable depending on how often the motorbike transport makes trips between the clinic and the lab.
Objective
In this study, we seek to assess factors facilitating as well as factors hindering the adoption of mobile devices in the Swazi healthcare through evaluating the end-users of the LabPush system.
Methods
A qualitative study with semi-structured and in-depth one on one interviews were conducted over two month period July–August 2012. Purposive sampling was used; participants were those operating and using the LabPush system at the remote clinics, at the national laboratory and the supervisors of users at Swaziland. Interview questions were focused on perceived of ease of use and usefulness of the system. All interviews were recorded and then transcribed.
Results
This study had aimed its primary focus on reducing TAT, prompt patient care, reducing bouncing of patients and defaulting of patients which were challenges that the clinicians have always had. Therefore, the results revealed several barriers and facilitators to the adoption of mobile device by healthcare providers in the Swaziland. The themes Shortens TAT, Technical support, Patient-centered care, Mindset, Improved communication, Missing Reports, Workload, Workflow, Security of smart phone, Human error and Ownership are sorted by facilitators to barriers.
Conclusion
Thus the end-users perspective, prompt patient care, reduced bouncing of patients, technical support, better communication, willing participant and social influence were facilitators of the adoption m-health in the Swazi healthcare.
ER  - 

TY  - JOUR
T1  - A toolkit for the analysis of biomechanical overload and prevention of WMSDs: Criteria, procedures and tool selection in a step-by-step approach
AU  - Occhipinti, E.
AU  - Colombini, D.
JO  - International Journal of Industrial Ergonomics
VL  - 52
SP  - 18
EP  - 28
PY  - 2016
DA  - 2016/03/01/
T2  - New Approaches and Interventions to Prevent Work Related Musculoskeletal Disorders
SN  - 0169-8141
DO  - https://doi.org/10.1016/j.ergon.2015.08.001
UR  - https://www.sciencedirect.com/science/article/pii/S0169814115300093
KW  - WMSDs
KW  - Biomechanics
KW  - Risk assessment
KW  - Toolkit
KW  - Workload
AB  - Background
When studying work related musculoskeletal disorders (WMSDs), various factors (mechanical, organizational, psychophysical, individual) and their interrelationships have been considered to be important in general models for epidemiologic surveys and risk assessment and management. Hence the need for a “holistic” approach towards MSD prevention. On the other hand, considering the widespread presence of these factors and of WMSDs in many work places located in both developed and developing countries, there is a strong demand from OSH agencies and operators for “simple” risk assessment and management tools that can also be used by non-experts.
Objectives
This paper is one of the main contributions towards a WHO/IEA project for developing a “Toolkit for WMSD prevention” by the TC on MSD of the IEA. The paper focuses on selecting tools at different levels for hazard identification, risk estimation and management. The proposals were primarily developed in this context but they also derive from other converging issues such as the ISO TR 12295 – published in 2014.
Methods and criteria
Proposals are based on two essential criteria: 1) adoption of a step-by-step approach starting with basic tools and moving to more complex tools only when necessary; 2) factoring in complexity and the presence of multiple influencing factors at every step (although with different degrees of in-depth analysis).
Results
The proposals include: Step one: identification of preliminary occupational hazards and priority setting via “key-enter” questions (at this step, all potential hazards affecting WMSDs should be considered). Step two: identification of risk factors for WMSDs, consisting of a “quick assessment” and substantially aimed at identifying three possible conditions: acceptable/no consequences; critical/redesign urgently needed; more detailed analysis required. Step three: recognized tools for estimating risk (of WMSDs) are used depending on the outcomes of step two. Examples of such tools include “adaptations” of the Revised NIOSH Lifting Equation, Liberty Mutual Psychophysical Tables, OCRA Checklist, etc. These tools should adequately cover most of the influencing factors.
Relevance to industry
The use of a step-by-step approach and validated risk estimation tools, in accordance with international standards, makes it possible to tackle the challenge of simplifying complexity in the assessment of biomechanical overload conditions and in the prevention of WMSDs in enterprises of all sizes, small businesses, agriculture, and in developing countries.
ER  - 

TY  - JOUR
T1  - Accessing quality early care and education for children in child welfare: Stakeholders' perspectives on barriers and opportunities for interagency collaboration
AU  - Lee, Sei-Young
AU  - Benson, Stephanie M.
AU  - Klein, Sacha M.
AU  - Franke, Todd M.
JO  - Children and Youth Services Review
VL  - 55
SP  - 170
EP  - 181
PY  - 2015
DA  - 2015/08/01/
SN  - 0190-7409
DO  - https://doi.org/10.1016/j.childyouth.2015.06.003
UR  - https://www.sciencedirect.com/science/article/pii/S019074091500184X
KW  - Child welfare
KW  - Child care early education
KW  - Collaboration
KW  - Barriers
KW  - Child maltreatment
AB  - Emerging evidence suggests that high quality early care and education (ECE) programs can improve children's developmental outcomes, particularly for at-risk children. Yet, ECE remains under-utilized by children in the child welfare system. This study illuminates some of the reasons for this by presenting findings from a series of ten focus groups with child welfare workers, ECE providers, and parents/caregivers of young children involved with the child welfare system (N=78). Fourteen themes emerged regarding organizational and system-level barriers to enrolling children involved with the child welfare system in ECE. These include generic barriers to inter-agency collaboration in human services, such as challenging work climates characterized by limited resources, high workloads and staff turnover, and lack of guidelines for collaborative infrastructure. Findings more specific to inter-agency collaboration between child welfare and ECE include the disruptive effect of foster placement changes and case closures on ECE stability, policies restricting ECE eligibility and availability for birth and/or foster parents, and child welfare workers' limited understanding of the value of high quality, learning based ECE programs versus custodial child care, particularly for infants and toddlers. Policy and practice recommendations to improve ECE utilization and service coordination among child welfare and ECE organizations are discussed.
ER  - 

TY  - JOUR
T1  - A case study evaluation of a Critical Care Information System adoption using the socio-technical and fit approach
AU  - Yusof, Maryati Mohd.
JO  - International Journal of Medical Informatics
VL  - 84
IS  - 7
SP  - 486
EP  - 499
PY  - 2015
DA  - 2015/07/01/
SN  - 1386-5056
DO  - https://doi.org/10.1016/j.ijmedinf.2015.03.001
UR  - https://www.sciencedirect.com/science/article/pii/S1386505615000611
KW  - Evaluation
KW  - Evaluation framework
KW  - Critical Care Information Systems
KW  - Health Information Systems
KW  - Socio-technical factors
KW  - Fit
AB  - Background
Clinical information systems have long been used in intensive care units but reports on their adoption and benefits are limited. This study evaluated a Critical Care Information System implementation.
Methods
A case study summative evaluation was conducted, employing observation, interview, and document analysis in operating theatres and 16-bed adult intensive care units in a 400-bed Malaysian tertiary referral centre from the perspectives of users (nurses and physicians), management, and information technology staff. System implementation, factors influencing adoption, fit between these factors, and the impact of the Critical Care Information System were evaluated after eight months of operation.
Results
Positive influences on system adoption were associated with technical factors, including system ease of use, usefulness, and information relevancy; human factors, particularly user attitude; and organisational factors, namely clinical process-technology alignment and champions. Organisational factors such as planning, project management, training, technology support, turnover rate, clinical workload, and communication were barriers to system implementation and use. Recommendations to improve the current system problems were discussed. Most nursing staff positively perceived the system's reduction of documentation and data access time, giving them more time with patients. System acceptance varied among doctors. System use also had positive impacts on timesaving, data quality, and clinical workflow.
Conclusions
Critical Care Information Systems is crucial and has great potentials in enhancing and delivering critical care. However, the case study findings showed that the system faced complex challenges and was underutilised despite its potential. The role of socio-technical factors and their fit in realizing the potential of Critical Care Information Systems requires continuous, in-depth evaluation and stakeholder understanding and acknowledgement. The comprehensive and specific evaluation measures of the Human–Organisation–Technology Fit framework can flexibly evaluate Critical Care Information Systems.
ER  - 

TY  - JOUR
T1  - A multi-agent system for the classification of gender and age from images
AU  - González-Briones, Alfonso
AU  - Villarrubia, Gabriel
AU  - De Paz, Juan F.
AU  - Corchado, Juan M.
JO  - Computer Vision and Image Understanding
VL  - 172
SP  - 98
EP  - 106
PY  - 2018
DA  - 2018/07/01/
SN  - 1077-3142
DO  - https://doi.org/10.1016/j.cviu.2018.01.012
UR  - https://www.sciencedirect.com/science/article/pii/S1077314218300122
KW  - Facial recognition
KW  - Automatic age estimation
KW  - Automatic gender estimation
KW  - Preprocessing of images
KW  - Multi-agent system
AB  - The automatic classification of human images on the basis of age range and gender can be used in audiovisual content adaptation for Smart TVs or marquee advertising. Knowledge about users is used by publishing agencies and departments regulating TV content; on the basis of this information (age, gender) they are able to provide content that suits the interests of users. To this end, the creation of a highly precise image pattern recognition system is necessary, this may be one of the greatest challenges faced by computer technology in the last decades. These recognition systems must apply different pattern recognition techniques, in order to distinct gender and age in the images. In this work, we propose a multi-agent system that integrates different techniques for the acquisition, preprocessing and processing of images for the classification of age and gender. The system has been tested in an office building. Thanks to the use of a multi-agent system which allows to apply different workflows simultaneously, the performance of different methods could be compared (each flow with a different configuration). Experimental results have confirmed that a good preprocessing stage is necessary if we want the classification methods to perform well (Fisherfaces, Eigenfaces, Local Binary Patterns, Multilayer perceptron). The Fisherfaces method has proved to be more effective than MLP and the training time was shorter. In terms of the classification of age, Fisherfaces offers the best results in comparison to the rest of the system’s classifiers. The use of filters has allowed to reduce dimensionality, as a result the workload was reduced, a great advantage in a system that performs classification in real time.
ER  - 

TY  - JOUR
T1  - M3 - A hybrid measurement-modeling approach for CPU-bound applications on cross-platform architectures
AU  - Duttagupta, Subhasri
AU  - Apte, Varsha
AU  - Gawali, Devidas
JO  - Journal of Systems and Software
VL  - 156
SP  - 232
EP  - 245
PY  - 2019
DA  - 2019/10/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2019.07.001
UR  - https://www.sciencedirect.com/science/article/pii/S016412121930144X
KW  - Benchmark
KW  - Performance
KW  - Prediction
KW  - Multi-tier
KW  - Modeling
KW  - Cross-platform
AB  - Predicting performance of CPU intensive applications for a target platform is of significant importance to IT industries. However, the target hardware platform for which we want to predict the performance is often different from the testbed on which the application performance measurements are done, and may not be unavailable for deployment for various practical reasons. This paper presents M3, a Measure-Measure-Model method, which uses a pipeline of three steps to address this problem. The methodology starts with measuring CPU service demands of the application on the testbed. Then, it builds clones that mimic the application code in terms of the type of operations, the number and size of network calls with external servers and API calls made at different layers of the technology stack. The clones are simple and easy to deploy, yet demonstrate the same speedup factor between the source and the target as the original application. The clones are then deployed on the testbed and on the target to estimate the application CPU service demand under light load generation. In the final step, this estimated CPU service demand is fed into specific performance modeling tools that are capable of predicting application performance on the target under arbitrary higher workload. Predictions made using this approach are validated against direct measurements made on five applications in Java and PHP, and on a number of combinations of testbed and target platforms (Intel and AMD servers) and the prediction error is always less than 20%.
ER  - 

TY  - JOUR
T1  - An intelligent situation awareness support system for safety-critical environments
AU  - Naderpour, Mohsen
AU  - Lu, Jie
AU  - Zhang, Guangquan
JO  - Decision Support Systems
VL  - 59
SP  - 325
EP  - 340
PY  - 2014
DA  - 2014/03/01/
SN  - 0167-9236
DO  - https://doi.org/10.1016/j.dss.2014.01.004
UR  - https://www.sciencedirect.com/science/article/pii/S0167923614000050
KW  - Decision support systems
KW  - Cognition-driven decision support
KW  - Situation awareness
KW  - Situation assessment
KW  - Risk assessment
KW  - Bayesian networks
AB  - Operators handling abnormal situations in safety-critical environments need to be supported from a cognitive perspective to reduce their workload, stress, and consequent error rate. Of the various cognitive activities, a correct understanding of the situation, i.e. situation awareness (SA), is a crucial factor in improving performance and reducing error. However, existing system safety researches focus mainly on technical issues and often neglect SA. This study presents an innovative cognition-driven decision support system called the situation awareness support system (SASS) to manage abnormal situations in safety-critical environments in which the effect of situational complexity on human decision-makers is a concern. To achieve this objective, a situational network modeling process and a situation assessment model that exploits the specific capabilities of dynamic Bayesian networks and risk indicators are first proposed. The SASS is then developed and consists of four major elements: 1) a situation data collection component that provides the current state of the observable variables based on online conditions and monitoring systems, 2) a situation assessment component based on dynamic Bayesian networks (DBN) to model the hazardous situations in a situational network and a fuzzy risk estimation method to generate the assessment result, 3) a situation recovery component that provides a basis for decision-making to reduce the risk level of situations to an acceptable level, and 4) a human-computer interface. The SASS is partially evaluated by a sensitivity analysis, which is carried out to validate DBN-based situational networks, and SA measurements are suggested for a full evaluation of the proposed system. The performance of the SASS is demonstrated by a case taken from US Chemical Safety Board reports, and the results demonstrate that the SASS provides a useful graphical, mathematically consistent system for dealing with incomplete and uncertain information to help operators maintain the risk of dynamic situations at an acceptable level.
ER  - 

TY  - JOUR
T1  - An application framework for development of a maintenance management system based on building information modeling and radio-frequency identification: case study of a stadium building
AU  - Kameli, Mohsen
AU  - Majrouhi Sardroud, Javad
AU  - Hosseinalipour, Mojtaba
AU  - Behruyan, Manuchehr
AU  - Ahmed, Syed M.
JO  - Canadian Journal of Civil Engineering
VL  - 47
IS  - 6
SP  - 736
EP  - 748
PY  - 2019
DA  - 2019/08/20/
SN  - 0315-1468
DO  - https://doi.org/10.1139/cjce-2019-0107
UR  - https://www.sciencedirect.com/science/article/pii/S0315146819001871
KW  - building information modeling (BIM)
KW  - radio-frequency identification (RFID)
KW  - facility management (FM)
KW  - modélisation des données du bâtiment (MDB)
KW  - identification par radiofréquence (IRF)
KW  - gestion des installations (GI)
AB  - Identifying, tracking, controlling, and managing facilities and the associated problems are critical tasks in facility management. In addition, the facility maintenance information needs to be constantly updated, which leads to an extra workload for staff using paper and two-dimensional drawings. To overcome these challenges, a system based on building information modeling (BIM) and radio-frequency identification (RFID) is developed for managing and maintaining facilities. The proposed system simultaneously connects the BIM model using industry foundation class (IFC) data structures, the facility maintenance database, and the RFID reader and shows the accessible data through the internet on a handheld screen. This approach provides a general framework for maintenance information management of building facilities. The framework invokes the proposed system to be for preventive maintenance and the reports based on it. The system is implemented in the case study of the building maintenance of a soccer stadium to validate the proposed system and demonstrate the system’s effectiveness for maintenance management.
La détermination, le suivi, le contrôle et la gestion des installations et les problèmes connexes sont des tâches essentielles de la gestion des installations. De plus, l’information sur les besoins d’entretien des installations doit être constamment mise à jour, ce qui entraîne une charge de travail supplémentaire pour le personnel qui utilise du papier et des dessins bidimensionnels. Pour surmonter ces difficultés, un système basé sur la modélisation des données du bâtiment (MDB) et l’identification par radiofréquence (IRF) est développé pour gérer et entretenir les installations. Le système proposé relie simultanément le modèle MDB en utilisant les structures de données de « industry foundation classes », la base de données d’entretien des installations et le lecteur d’IRF, et montre les données accessibles par internet sur un écran portable. Cette approche fournit un cadre général pour la gestion de l’information sur l’entretien des bâtiments. Le cadre fait appel au système proposé pour l’entretien préventif et aux rapports qui en découlent. Le système est mis en œuvre dans l’étude de cas de l’entretien d’un stade de soccer pour valider le système proposé et démontrer l’efficacité du système en matière de gestion de l’entretien. [Traduit par la Rédaction]
ER  - 

TY  - JOUR
T1  - Beyond mere take-over requests: The effects of monitoring requests on driver attention, take-over performance, and acceptance
AU  - Lu, Z.
AU  - Zhang, B.
AU  - Feldhütter, A.
AU  - Happee, R.
AU  - Martens, M.
AU  - De Winter, J.C.F.
JO  - Transportation Research Part F: Traffic Psychology and Behaviour
VL  - 63
SP  - 22
EP  - 37
PY  - 2019
DA  - 2019/05/01/
SN  - 1369-8478
DO  - https://doi.org/10.1016/j.trf.2019.03.018
UR  - https://www.sciencedirect.com/science/article/pii/S1369847818304686
AB  - In conditionally automated driving, drivers do not have to monitor the road, whereas in partially automated driving, drivers have to monitor the road permanently. We evaluated a dynamic allocation of monitoring tasks to human and automation by providing a monitoring request (MR) before a possible take-over request (TOR), with the aim to better prepare drivers to take over safely and efficiently. In a simulator-based study, an MR + TOR condition was compared with a TOR-only condition using a within-subject design with 41 participants. In the MR + TOR condition, an MR was triggered 12 s before a zebra crossing, and a TOR was provided 7 s after the MR onset if pedestrians crossing the road were detected. In the TOR-only condition, a TOR was provided 5 s before the vehicle would collide with a pedestrian if the participant did not intervene. Participants were instructed to perform a self-paced visual-motor non-driving task during automated driving. Eye tracking results showed that participants in the MR + TOR condition responded to the MR by looking at the driving environment. They also exhibited better take-over performance, with a shorter response time to the TOR and a longer minimum time to collision as compared to the TOR-only condition. Subjective evaluations also showed advantages of the MR: participants reported lower workload, higher acceptance, and higher trust in the MR + TOR condition as compared to the TOR-only condition. Participants’ reliance on automation was tested in a third drive (MR-only condition), where automation failed to provide a TOR after an MR. The MR-only condition resulted in later responses (and errors of omission) as compared to the MR + TOR condition. It is concluded that MRs have the potential to increase safety and acceptance of automated driving as compared to systems that provide only TORs. Drivers’ trust calibration and reliance on automation need further investigation.
ER  - 

TY  - JOUR
T1  - Impacts of mobile tablet computing on provider productivity, communications, and the process of care
AU  - Schooley, Benjamin
AU  - Walczak, Steven
AU  - Hikmet, Neset
AU  - Patel, Nitin
JO  - International Journal of Medical Informatics
VL  - 88
SP  - 62
EP  - 70
PY  - 2016
DA  - 2016/04/01/
SN  - 1386-5056
DO  - https://doi.org/10.1016/j.ijmedinf.2016.01.010
UR  - https://www.sciencedirect.com/science/article/pii/S1386505616300107
KW  - Mobile computing
KW  - Provider productivity
KW  - Provider-patient Communications
KW  - Usability
KW  - Electronic health record
KW  - Technology acceptanc
KW  - eHealth
KW  - Evaluation and assessment
KW  - Health service research
KW  - Human-computer interaction
KW  - Mobile applications
KW  - Mobile health
AB  - Objective
Health information technology investments continue to increase while the value derived from their implementation and use is mixed. Mobile device adoption into practice is a recent trend that has increased dramatically and formal studies are needed to investigate consequent benefits and challenges. The objective of this study is to evaluate practitioner perceptions of improvements in productivity, provider-patient communications, care provision, technology usability and other outcomes following the adoption and use of a tablet computer connected to electronic health information resources.
Methods
A pilot program was initiated in June 2013 to evaluate the effect of mobile tablet computers at one health provider organization in the southeast United States. Providers were asked to volunteer for the evaluation and were each given a mobile tablet computer. A total of 42 inpatient and outpatient providers were interviewed in 2015 using a survey style questionnaire that utilized yes/no, Likert-style, and open ended questions. Each had previously used an electronic health record (EHR) system a minimum of one year outside of residency, and were regular users of personal mobile devices. Each used a mobile tablet computer in the context of their practice connected to the health system EHR.
Results
The survey results indicate that more than half of providers perceive the use of the tablet device as having a positive effect on patient communications, patient education, patient's perception of the provider, time spent interacting with patients, provider productivity, process of care, satisfaction with EHR when used together with the device, and care provision. Providers also reported feeling comfortable using the device (82.9%), would recommend the device to colleagues (69.2%), did not experience increased information security and privacy concerns (95%), and noted significant reductions in EHR login times (64.1%). Less than 25% of participants reported negative impacts on any of these areas as well as on time spent on order submission, note completion time, overall workload, patient satisfaction with care experience and patient outcomes. Gender, number of years in practice, practice type (general practitioner vs. specialist), and service type (inpatient/outpatient) were found to have a significant effect on perceptions of patient satisfaction, care process, and provider productivity.
Conclusions
Providers found positive gains from utilizing mobile devices in overall productivity, improved communications with their patients, the process of care, and technology efficiencies when used in combination with EHR and other health information resources. Demographic and health care work environment play a role in how mobile technologies are integrated into practice by providers.
ER  - 

TY  - JOUR
T1  - Automatic trial eligibility surveillance based on unstructured clinical data
AU  - Meystre, Stéphane M.
AU  - Heider, Paul M.
AU  - Kim, Youngjun
AU  - Aruch, Daniel B.
AU  - Britten, Carolyn D.
JO  - International Journal of Medical Informatics
VL  - 129
SP  - 13
EP  - 19
PY  - 2019
DA  - 2019/09/01/
SN  - 1386-5056
DO  - https://doi.org/10.1016/j.ijmedinf.2019.05.018
UR  - https://www.sciencedirect.com/science/article/pii/S1386505618310529
KW  - Clinical trial
KW  - Eligibility criteria
KW  - Natural language processing
KW  - Machine learning
AB  - Introduction
Insufficient patient enrollment in clinical trials remains a serious and costly problem and is often considered the most critical issue to solve for the clinical trials community. In this project, we assessed the feasibility of automatically detecting a patient's eligibility for a sample of breast cancer clinical trials by mapping coded clinical trial eligibility criteria to the corresponding clinical information automatically extracted from text in the EHR.
Methods
Three open breast cancer clinical trials were selected by oncologists. Their eligibility criteria were manually abstracted from trial descriptions using the OHDSI ATLAS web application. Patients enrolled or screened for these trials were selected as ‘positive’ or ‘possible’ cases. Other patients diagnosed with breast cancer were selected as ‘negative’ cases. A selection of the clinical data and all clinical notes of these 229 selected patients was extracted from the MUSC clinical data warehouse and stored in a database implementing the OMOP common data model. Eligibility criteria were extracted from clinical notes using either manually crafted pattern matching (regular expressions) or a new natural language processing (NLP) application. These extracted criteria were then compared with reference criteria from trial descriptions. This comparison was realized with three different versions of a new application: rule-based, cosine similarity-based, and machine learning-based.
Results
For eligibility criteria extraction from clinical notes, the machine learning-based NLP application allowed for the highest accuracy with a micro-averaged recall of 90.9% and precision of 89.7%. For trial eligibility determination, the highest accuracy was reached by the machine learning-based approach with a per-trial AUC between 75.5% and 89.8%.
Conclusion
NLP can be used to extract eligibility criteria from EHR clinical notes and automatically discover patients possibly eligible for a clinical trial with good accuracy, which could be leveraged to reduce the workload of humans screening patients for trials.
ER  - 

TY  - JOUR
T1  - Decision support system for triage management: A hybrid approach using rule-based reasoning and fuzzy logic
AU  - Dehghani Soufi, Mahsa
AU  - Samad-Soltani, Taha
AU  - Shams Vahdati, Samad
AU  - Rezaei-Hachesu, Peyman
JO  - International Journal of Medical Informatics
VL  - 114
SP  - 35
EP  - 44
PY  - 2018
DA  - 2018/06/01/
SN  - 1386-5056
DO  - https://doi.org/10.1016/j.ijmedinf.2018.03.008
UR  - https://www.sciencedirect.com/science/article/pii/S1386505618302156
KW  - Decision support system
KW  - Documentation
KW  - Emergencies
KW  - Fuzzy logic
KW  - Triage
KW  - Knowledge
AB  - Objectives
Fast and accurate patient triage for the response process is a critical first step in emergency situations. This process is often performed using a paper-based mode, which intensifies workload and difficulty, wastes time, and is at risk of human errors. This study aims to design and evaluate a decision support system (DSS) to determine the triage level.
Methods
A combination of the Rule-Based Reasoning (RBR) and Fuzzy Logic Classifier (FLC) approaches were used to predict the triage level of patients according to the triage specialist’s opinions and Emergency Severity Index (ESI) guidelines. RBR was applied for modeling the first to fourth decision points of the ESI algorithm. The data relating to vital signs were used as input variables and modeled using fuzzy logic. Narrative knowledge was converted to If-Then rules using XML. The extracted rules were then used to create the rule-based engine and predict the triage levels.
Results
Fourteen RBR and 27 fuzzy rules were extracted and used in the rule-based engine. The performance of the system was evaluated using three methods with real triage data. The accuracy of the clinical decision support systems (CDSSs; in the test data) was 99.44%. The evaluation of the error rate revealed that, when using the traditional method, 13.4% of the patients were miss-triaged, which is statically significant. The completeness of the documentation also improved from 76.72% to 98.5%.
Conclusions
Designed system was effective in determining the triage level of patients and it proved helpful for nurses as they made decisions, generated nursing diagnoses based on triage guidelines. The hybrid approach can reduce triage misdiagnosis in a highly accurate manner and improve the triage outcomes.
ER  - 

TY  - JOUR
T1  - A semi-supervised approach using label propagation to support citation screening
AU  - Kontonatsios, Georgios
AU  - Brockmeier, Austin J.
AU  - Przybyła, Piotr
AU  - McNaught, John
AU  - Mu, Tingting
AU  - Goulermas, John Y.
AU  - Ananiadou, Sophia
JO  - Journal of Biomedical Informatics
VL  - 72
SP  - 67
EP  - 76
PY  - 2017
DA  - 2017/08/01/
SN  - 1532-0464
DO  - https://doi.org/10.1016/j.jbi.2017.06.018
UR  - https://www.sciencedirect.com/science/article/pii/S1532046417301454
KW  - Active learning
KW  - Label propagation
KW  - Citation screening
KW  - Semi-supervised learning
KW  - Text classification
AB  - Citation screening, an integral process within systematic reviews that identifies citations relevant to the underlying research question, is a time-consuming and resource-intensive task. During the screening task, analysts manually assign a label to each citation, to designate whether a citation is eligible for inclusion in the review. Recently, several studies have explored the use of active learning in text classification to reduce the human workload involved in the screening task. However, existing approaches require a significant amount of manually labelled citations for the text classification to achieve a robust performance. In this paper, we propose a semi-supervised method that identifies relevant citations as early as possible in the screening process by exploiting the pairwise similarities between labelled and unlabelled citations to improve the classification performance without additional manual labelling effort. Our approach is based on the hypothesis that similar citations share the same label (e.g., if one citation should be included, then other similar citations should be included also). To calculate the similarity between labelled and unlabelled citations we investigate two different feature spaces, namely a bag-of-words and a spectral embedding based on the bag-of-words. The semi-supervised method propagates the classification codes of manually labelled citations to neighbouring unlabelled citations in the feature space. The automatically labelled citations are combined with the manually labelled citations to form an augmented training set. For evaluation purposes, we apply our method to reviews from clinical and public health. The results show that our semi-supervised method with label propagation achieves statistically significant improvements over two state-of-the-art active learning approaches across both clinical and public health reviews.
ER  - 

TY  - JOUR
T1  - Resource provisioning in scalable cloud using bio-inspired artificial neural network model
AU  - Rawat, Pradeep Singh
AU  - Dimri, Priti
AU  - Gupta, Punit
AU  - Saroha, G.P.
JO  - Applied Soft Computing
VL  - 99
SP  - 106876
PY  - 2021
DA  - 2021/02/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2020.106876
UR  - https://www.sciencedirect.com/science/article/pii/S1568494620308140
KW  - AFs
KW  - ANN (Artificial Neural Network)
KW  - ACS (Artificial Task Scheduler)
KW  - BB–BC​ (Big-Bang Big-Crunch)
KW  - GA
KW  - Scheduling
KW  - Task
AB  - Resource assignment is one of the emerging research area in the cloud scenario. Cloud computing provides a shared pool of resources in a distributed environment. It supports the features of utility-based computing. Efficient task provisioning on virtual machines is the major concern in an extensible cloud computing environment. The task provisioning minimizes the performance metrics total completion time (ms), average start time, average finish time, average execution time, scheduling time, and simulation time respectively. The scheduling is an important problem which becomes more complicated when various parameters consider. The key issue in virtual machine level scheduling is execution time overhead and scalability in a real-time scenario. Our objective is to make an optimal schedule of tasks on a virtual machine inside the datacenter using neural-bio inspired GA-ANN technique. This work presents a scheduler based on a genetic approach and an artificial neural network. The presented approach performs optimal scheduling of tasks on an appropriate virtual machine. The reliability of the system improves by reducing the number of tasks failed. The presented work uses a genetic algorithm to generated huge data sets and trains the neural model using the data set generated by using a genetic approach. The accuracy of the model is improved using back propagation with 98% accuracy. The set of experiments are performed using a scalable cloud computing environment. The presented bio-inspired technique is compared against nature-inspired, bio-inspired cost-aware BB–BC, GA-Cost, and GA-Exe based efficient task scheduling techniques. The results are obtained using real workload logs and synthetic data sets. Results indicate that the proposed GA-ANN bio-inspired predictive approach outperforms the considered nature-inspired scheduling approaches. The proposed algorithm is compared using various performance metrics total completion time, average start time, average finish time, and the fault rate, execution time, and scheduling time respectively. The proposed model reduces the fault rate by 82.63%, successfully completed tasks count improves by 26.81% and execution time improves by 10.66% and scheduling time improves by 69.94%. The scheduling time improves by 85.76% with an increasing number of iterations and constant numbers of tasks. Hence the presented GA-ANN scheduling technique outperformed the GA cost, GA EXE, and BB–BC COST scheduling approaches.
ER  - 

TY  - JOUR
T1  - PHash: A memory-efficient, high-performance key-value store for large-scale data-intensive applications
AU  - Shim, Hyotaek
JO  - Journal of Systems and Software
VL  - 123
SP  - 33
EP  - 44
PY  - 2017
DA  - 2017/01/01/
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2016.09.047
UR  - https://www.sciencedirect.com/science/article/pii/S0164121216301959
KW  - Distributed storage
KW  - Key-value store
KW  - NoSQL
KW  - Datastore
KW  - Solid state drives
AB  - Large-scale data-intensive web services are evolving faster than ever, accelerating global growth in data usage and traffic at a rapid rate. This rapid growth is demanding the expansion of high-cost data infrastructures, which also underscores the industry’s need for cost-effective, high-performance distributed key-value stores. Designing key-value stores often involves a trade-off between performance and memory usage. For example, many previous studies focusing on minimizing the memory usage have developed on-disk indexing schemes, leading to lower performance. An alternative design based on in-memory indexing allows better performance, but at the expense of greater memory usage. This paper proposes a novel key-value store called PHash (Packed Hash) based on an advanced design of index and data structures that ensures both high performance and small memory usage. These advantages make the proposed scheme a better fit for processing demanding workloads in large-scale data-intensive applications. Compared to the best-performing competitor, FAWN-DS, the proposed scheme significantly reduces the memory consumption (bytes per key-value) by 83% and improves the GET throughput by up to 27.3% while the PUT throughput decreases by 12.6%. In particular, the GET performance of the proposed scheme reaches up to 99.4% of the optimal performance of the raw SSD (Solid State Drive).
ER  - 

TY  - JOUR
T1  - On the scalability of CFD tool for supersonic jet flow configurations
AU  - Junqueira-Junior, Carlos
AU  - Azevedo, João Luiz F.
AU  - Panetta, Jairo
AU  - Wolf, William R.
AU  - Yamouni, Sami
JO  - Parallel Computing
VL  - 93
SP  - 102620
PY  - 2020
DA  - 2020/05/01/
SN  - 0167-8191
DO  - https://doi.org/10.1016/j.parco.2020.102620
UR  - https://www.sciencedirect.com/science/article/pii/S0167819120300132
KW  - Computational fluid dynamics
KW  - Large eddy simulation
KW  - Scalability
KW  - Supersonic jet flow
AB  - New regulations are imposing noise emissions limitations for the aviation industry which are pushing researchers and engineers to invest efforts in studying the aeroacoustics phenomena. Following this trend, an in-house computational fluid dynamics tool is build to reproduce high fidelity results of supersonic jet flows for aeroacoustic analogy applications. The solver is written using the large eddy simulation formulation that is discretized using a finite difference approach and an explicit time integration. Numerical simulations of supersonic jet flows are very expensive and demand efficient high-performance computing. Therefore, non-blocking message passage interface protocols and parallel Input/Output features are implemented into the code in order to perform simulations which demand up to one billion grid points. The present work addresses the evaluation of code improvements along with the computational performance of the solver running on a computer with maximum theoretical peak of 2.727 PFlops. Different mesh configurations, whose size varies from a few hundred thousand to approximately one billion grid points, are evaluated in the present paper. Calculations are performed using different workloads in order to assess the strong and weak scalability of the parallel computational tool. Moreover, validation results of a realistic flow condition are also presented in the current work.
ER  - 

TY  - JOUR
T1  - Multi-objective resource allocation for Edge Cloud based robotic workflow in smart factory
AU  - Afrin, Mahbuba
AU  - Jin, Jiong
AU  - Rahman, Ashfaqur
AU  - Tian, Yu-Chu
AU  - Kulkarni, Ambarish
JO  - Future Generation Computer Systems
VL  - 97
SP  - 119
EP  - 130
PY  - 2019
DA  - 2019/08/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2019.02.062
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X18326785
KW  - Resource allocation
KW  - Multi-robot system
KW  - Edge cloud
KW  - Workflow management
KW  - Smart factory
KW  - Multi-objective evolutionary algorithm
AB  - Multi-robotic services are widely used to enhance the efficiency of Industry 4.0 applications including emergency management in smart factory. The workflow of these robotic services consists of data hungry, delay sensitive and compute intensive tasks. Generally, robots are not enriched in computational power and storage capabilities. It is thus beneficial to leverage the available Cloud resources to complement robots for executing robotic workflows. When multiple robots and Cloud instances work in a collaborative manner, optimal resource allocation for the tasks of a robotic workflow becomes a challenging problem. The diverse energy consumption rate of both robot and Cloud instances, and the cost of executing robotic workflow in such a distributed manner further intensify the resource allocation problem. Since the tasks are inter-dependent, inconvenience in data exchange between local robots and remote Cloud also degrade the service quality. Therefore, in this paper, we address simultaneous optimization of makespan, energy consumption and cost while allocating resources for the tasks of a robotic workflow. As a use case, we consider resource allocation for the robotic workflow of emergency management service in smart factory. We design an Edge Cloud based multi-robot system to overcome the limitations of remote Cloud based system in exchanging delay sensitive data. The resource allocation for robotic workflow is modelled as a constrained multi-objective optimization problem and it is solved through a multi-objective evolutionary approach, namely, NSGA-II algorithm. We have redesigned the NSGA-II algorithm by defining a new chromosome structure, pre-sorted initial population and mutation operator. It is further augmented by selecting the minimum distant solution from the non-dominated front to the origin while crossing over the chromosomes. The experimental results based on synthetic workload demonstrate that our augmented NSGA-II algorithm outperforms the state-of-the-art works by at least 18% in optimizing makespan, energy and cost attributes on various scenarios.
ER  - 

TY  - JOUR
T1  - Operant Social Reward Decreases Incubation of Heroin Craving in Male and Female Rats
AU  - Venniro, Marco
AU  - Russell, Trinity I.
AU  - Zhang, Michelle
AU  - Shaham, Yavin
JO  - Biological Psychiatry
VL  - 86
IS  - 11
SP  - 848
EP  - 856
PY  - 2019
DA  - 2019/12/01/
T2  - Striatal Mechanisms in Addiction
SN  - 0006-3223
DO  - https://doi.org/10.1016/j.biopsych.2019.05.018
UR  - https://www.sciencedirect.com/science/article/pii/S0006322319314088
KW  - Addiction
KW  - Animal models
KW  - Choice
KW  - Incubation
KW  - Motivation
KW  - Operant
KW  - Opioid
KW  - Rats
KW  - Reward
KW  - Self-administration
KW  - Social
KW  - Voluntary abstinence
AB  - Background
We recently reported that operant social choice–induced voluntary abstinence prevents incubation of methamphetamine craving. Here, we determined whether social choice–induced voluntary abstinence would prevent incubation of heroin craving. We also introduce a fully automatic social reward self-administration model that eliminates the intense workload and rat–human interaction of the original semiautomatic model.
Methods
In experiment 1, we trained male and female rats for social self-administration (6 days) and then for heroin self-administration (12 days). Next, we assessed relapse to heroin seeking after 1 and 15 abstinence days. Between tests, the rats underwent either forced or social choice–induced abstinence. In experiment 2, we developed a fully automatic social self-administration procedure by introducing a screen between the self-administration chamber and the social-peer chamber; the screen allows physical contact but prevents rats from crossing chambers. Next, we compared incubation of craving in rats with a history of standard (no-screen) or automatic (screen) social self-administration and social choice–induced abstinence.
Results
The time-dependent increase in heroin seeking after cessation of drug self-administration (incubation of craving) was lower after social choice–induced abstinence than after forced abstinence. There were no differences in social self-administration, social choice–induced abstinence, and incubation of craving in rats trained in the standard semiautomatic procedure versus the novel fully automatic procedure.
Conclusions
Our study demonstrates the protective effect of rewarding social interaction on heroin self-administration and incubation of heroin craving and introduces a fully automatic social self-administration and choice procedure to investigate the role of volitional social interaction in drug addiction and other psychiatric disorders.
ER  - 

TY  - JOUR
T1  - Fog computing enabled cost-effective distributed summarization of surveillance videos for smart cities
AU  - Nasir, Mansoor
AU  - Muhammad, Khan
AU  - Lloret, Jaime
AU  - Sangaiah, Arun Kumar
AU  - Sajjad, Muhammad
JO  - Journal of Parallel and Distributed Computing
VL  - 126
SP  - 161
EP  - 170
PY  - 2019
DA  - 2019/04/01/
SN  - 0743-7315
DO  - https://doi.org/10.1016/j.jpdc.2018.11.004
UR  - https://www.sciencedirect.com/science/article/pii/S0743731518308402
KW  - Fog computing
KW  - Video summarization
KW  - Internet of things (IoT)
KW  - Energy-efficient cloud computing
KW  - Surveillance videos
KW  - And computational efficiency
AB  - Fog computing is emerging an attractive paradigm for both academics and industry alike. Fog computing holds potential for new breeds of services and user experience. However, Fog computing is still nascent and requires strong groundwork to adopt as practically feasible, cost-effective, efficient and easily deployable alternate to currently ubiquitous cloud. Fog computing promises to introduce cloud-like services on local network while reducing the cost. In this paper, we present a novel resource efficient framework for distributed video summarization over a multi-region fog computing paradigm. The nodes of the Fog network is based on resource constrained device Raspberry Pi. Surveillance videos are distributed on different nodes and a summary is generated over the Fog network, which is periodically pushed to the cloud to reduce bandwidth consumption. Different realistic workload in the form of a surveillance videos are used to evaluate the proposed system. Experimental results suggest that even by using an extremely limited resource, single board computer, the proposed framework has very little overhead with good scalability over off-the-shelf costly cloud solutions, validating its effectiveness for IoT-assisted smart cities.
ER  - 

TY  - JOUR
T1  - The effects of time pressure on driver performance and physiological activity: A driving simulator study
AU  - Rendon-Velez, E.
AU  - van Leeuwen, P. M .
AU  - Happee, R.
AU  - Horváth, I.
AU  - van der Vegte, W.F.
AU  - de Winter, J.C.F.
JO  - Transportation Research Part F: Traffic Psychology and Behaviour
VL  - 41
SP  - 150
EP  - 169
PY  - 2016
DA  - 2016/08/01/
SN  - 1369-8478
DO  - https://doi.org/10.1016/j.trf.2016.06.013
UR  - https://www.sciencedirect.com/science/article/pii/S1369847816301036
KW  - Simulation
KW  - Virtual reality
KW  - Workload
KW  - Psychophysiology
AB  - Speeding because of time pressure is a leading contributor to traffic accidents. Previous research indicates that people respond to time pressure through increased physiological activity and by adapting their task strategy in order to mitigate task demands. In the present driving simulator study, we investigated effects of time pressure on measures of eye movement, pupil diameter, cardiovascular and respiratory activity, driving performance, vehicle control, limb movement, head position, and self-reported state. Based on existing theories of human behavior under time pressure, we distinguished three categories of results: (1) driving speed, (2) physiological measures, and (3) driving strategies. Fifty-four participants drove a 6.9-km urban track with overtaking, car following, and intersection scenarios, first with no time pressure (NTP) and subsequently with time pressure (TP) induced by a time constraint and a virtual passenger urging to hurry up. The results showed that under TP in comparison to NTP, participants (1) drove significantly faster, an effect that was also reflected in auxiliary measures such as maximum brake position, throttle activity, and lane keeping precision, (2) exhibited increased physiological activity, such as increased heart rate, increased respiration rate, increased pupil diameter, and reduced blink rate, and (3) adopted scenario-specific strategies for effective task completion, such as driving to the left of the lane during car following, and early visual lookout when approaching intersections. The effects of TP relative to NTP were generally large and statistically significant. However, individual differences in absolute values were large. Hence, we recommend that real-time driver feedback technologies use relative instead of absolute criteria for assessing the driver’s state.
ER  - 
